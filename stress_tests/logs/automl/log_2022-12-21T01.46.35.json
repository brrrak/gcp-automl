[{"experiment": "regression_1", "max_runtime_secs": 3600, "max_models": null, "include_algos": null, "start_time": "2022-12-21 01:46:37.743367", "end_time": "2022-12-21 02:46:48.416639", "elapsed_time": "1:00:10.673272", "leaderboard": {"model_id": {"0": "StackedEnsemble_AllModels_5_AutoML_8_20221220_224639", "1": "StackedEnsemble_BestOfFamily_5_AutoML_8_20221220_224639", "2": "GBM_grid_1_AutoML_8_20221220_224639_model_47", "3": "GBM_grid_1_AutoML_8_20221220_224639_model_16", "4": "GBM_4_AutoML_8_20221220_224639", "5": "XGBoost_grid_1_AutoML_8_20221220_224639_model_9", "6": "GBM_grid_1_AutoML_8_20221220_224639_model_12", "7": "GBM_grid_1_AutoML_8_20221220_224639_model_15", "8": "GBM_grid_1_AutoML_8_20221220_224639_model_54", "9": "GBM_grid_1_AutoML_8_20221220_224639_model_51", "10": "XGBoost_grid_1_AutoML_8_20221220_224639_model_14", "11": "GBM_grid_1_AutoML_8_20221220_224639_model_14", "12": "GBM_3_AutoML_8_20221220_224639", "13": "XGBoost_grid_1_AutoML_8_20221220_224639_model_16", "14": "XGBoost_grid_1_AutoML_8_20221220_224639_model_13", "15": "GBM_grid_1_AutoML_8_20221220_224639_model_19", "16": "GBM_2_AutoML_8_20221220_224639", "17": "GBM_grid_1_AutoML_8_20221220_224639_model_57", "18": "GBM_grid_1_AutoML_8_20221220_224639_model_49", "19": "XGBoost_grid_1_AutoML_8_20221220_224639_model_25", "20": "XGBoost_grid_1_AutoML_8_20221220_224639_model_1", "21": "GBM_grid_1_AutoML_8_20221220_224639_model_10", "22": "GBM_5_AutoML_8_20221220_224639", "23": "XGBoost_grid_1_AutoML_8_20221220_224639_model_28", "24": "XGBoost_grid_1_AutoML_8_20221220_224639_model_20", "25": "XGBoost_grid_1_AutoML_8_20221220_224639_model_4", "26": "XGBoost_grid_1_AutoML_8_20221220_224639_model_10", "27": "DRF_1_AutoML_8_20221220_224639", "28": "GBM_grid_1_AutoML_8_20221220_224639_model_37", "29": "GBM_grid_1_AutoML_8_20221220_224639_model_2", "30": "XGBoost_grid_1_AutoML_8_20221220_224639_model_2", "31": "GBM_grid_1_AutoML_8_20221220_224639_model_48", "32": "GBM_grid_1_AutoML_8_20221220_224639_model_7", "33": "XRT_1_AutoML_8_20221220_224639", "34": "GBM_grid_1_AutoML_8_20221220_224639_model_9", "35": "GBM_grid_1_AutoML_8_20221220_224639_model_28", "36": "XGBoost_1_AutoML_8_20221220_224639", "37": "XGBoost_grid_1_AutoML_8_20221220_224639_model_21", "38": "GBM_grid_1_AutoML_8_20221220_224639_model_6", "39": "XGBoost_grid_1_AutoML_8_20221220_224639_model_29", "40": "XGBoost_3_AutoML_8_20221220_224639", "41": "XGBoost_grid_1_AutoML_8_20221220_224639_model_24", "42": "GBM_grid_1_AutoML_8_20221220_224639_model_4", "43": "GBM_grid_1_AutoML_8_20221220_224639_model_38", "44": "GBM_grid_1_AutoML_8_20221220_224639_model_59", "45": "GBM_grid_1_AutoML_8_20221220_224639_model_40", "46": "XGBoost_2_AutoML_8_20221220_224639", "47": "XGBoost_grid_1_AutoML_8_20221220_224639_model_7", "48": "XGBoost_grid_1_AutoML_8_20221220_224639_model_6", "49": "XGBoost_grid_1_AutoML_8_20221220_224639_model_23", "50": "GBM_grid_1_AutoML_8_20221220_224639_model_39", "51": "GBM_1_AutoML_8_20221220_224639", "52": "XGBoost_grid_1_AutoML_8_20221220_224639_model_19", "53": "GBM_grid_1_AutoML_8_20221220_224639_model_58", "54": "GBM_grid_1_AutoML_8_20221220_224639_model_22", "55": "GBM_grid_1_AutoML_8_20221220_224639_model_25", "56": "GBM_grid_1_AutoML_8_20221220_224639_model_43", "57": "XGBoost_grid_1_AutoML_8_20221220_224639_model_27", "58": "GBM_grid_1_AutoML_8_20221220_224639_model_26", "59": "GBM_grid_1_AutoML_8_20221220_224639_model_35", "60": "GBM_grid_1_AutoML_8_20221220_224639_model_53", "61": "GBM_grid_1_AutoML_8_20221220_224639_model_8", "62": "GBM_grid_1_AutoML_8_20221220_224639_model_13", "63": "XGBoost_grid_1_AutoML_8_20221220_224639_model_12", "64": "XGBoost_grid_1_AutoML_8_20221220_224639_model_18", "65": "GBM_grid_1_AutoML_8_20221220_224639_model_27", "66": "XGBoost_grid_1_AutoML_8_20221220_224639_model_5", "67": "GBM_grid_1_AutoML_8_20221220_224639_model_33", "68": "XGBoost_grid_1_AutoML_8_20221220_224639_model_22", "69": "XGBoost_grid_1_AutoML_8_20221220_224639_model_17", "70": "XGBoost_grid_1_AutoML_8_20221220_224639_model_11", "71": "XGBoost_grid_1_AutoML_8_20221220_224639_model_15", "72": "GBM_grid_1_AutoML_8_20221220_224639_model_32", "73": "GBM_grid_1_AutoML_8_20221220_224639_model_1", "74": "XGBoost_grid_1_AutoML_8_20221220_224639_model_3", "75": "GBM_grid_1_AutoML_8_20221220_224639_model_42", "76": "XGBoost_grid_1_AutoML_8_20221220_224639_model_26", "77": "GBM_grid_1_AutoML_8_20221220_224639_model_20", "78": "XGBoost_grid_1_AutoML_8_20221220_224639_model_8", "79": "GBM_grid_1_AutoML_8_20221220_224639_model_52", "80": "GBM_grid_1_AutoML_8_20221220_224639_model_46", "81": "GBM_grid_1_AutoML_8_20221220_224639_model_30", "82": "GBM_grid_1_AutoML_8_20221220_224639_model_11", "83": "GBM_grid_1_AutoML_8_20221220_224639_model_29", "84": "GBM_grid_1_AutoML_8_20221220_224639_model_50", "85": "GBM_grid_1_AutoML_8_20221220_224639_model_24", "86": "GBM_grid_1_AutoML_8_20221220_224639_model_18", "87": "GBM_grid_1_AutoML_8_20221220_224639_model_45", "88": "GBM_grid_1_AutoML_8_20221220_224639_model_3", "89": "GBM_grid_1_AutoML_8_20221220_224639_model_23", "90": "GBM_grid_1_AutoML_8_20221220_224639_model_17", "91": "GBM_grid_1_AutoML_8_20221220_224639_model_21", "92": "GBM_grid_1_AutoML_8_20221220_224639_model_56", "93": "GBM_grid_1_AutoML_8_20221220_224639_model_5", "94": "DeepLearning_1_AutoML_8_20221220_224639", "95": "DeepLearning_grid_3_AutoML_8_20221220_224639_model_1", "96": "GBM_grid_1_AutoML_8_20221220_224639_model_41", "97": "GBM_grid_1_AutoML_8_20221220_224639_model_36", "98": "DeepLearning_grid_1_AutoML_8_20221220_224639_model_4", "99": "GBM_grid_1_AutoML_8_20221220_224639_model_44", "100": "GBM_grid_1_AutoML_8_20221220_224639_model_34", "101": "GLM_1_AutoML_8_20221220_224639", "102": "GBM_grid_1_AutoML_8_20221220_224639_model_55", "103": "DeepLearning_grid_1_AutoML_8_20221220_224639_model_3", "104": "DeepLearning_grid_1_AutoML_8_20221220_224639_model_1", "105": "DeepLearning_grid_1_AutoML_8_20221220_224639_model_2", "106": "DeepLearning_grid_3_AutoML_8_20221220_224639_model_3", "107": "GBM_grid_1_AutoML_8_20221220_224639_model_31", "108": "DeepLearning_grid_3_AutoML_8_20221220_224639_model_2", "109": "DeepLearning_grid_2_AutoML_8_20221220_224639_model_1", "110": "StackedEnsemble_AllModels_3_AutoML_8_20221220_224639", "111": "StackedEnsemble_AllModels_4_AutoML_8_20221220_224639", "112": "StackedEnsemble_BestOfFamily_4_AutoML_8_20221220_224639", "113": "StackedEnsemble_BestOfFamily_2_AutoML_8_20221220_224639", "114": "StackedEnsemble_BestOfFamily_3_AutoML_8_20221220_224639", "115": "StackedEnsemble_AllModels_1_AutoML_8_20221220_224639", "116": "StackedEnsemble_AllModels_2_AutoML_8_20221220_224639", "117": "StackedEnsemble_BestOfFamily_1_AutoML_8_20221220_224639", "118": "DeepLearning_grid_2_AutoML_8_20221220_224639_model_2", "119": "GBM_grid_1_AutoML_8_20221220_224639_model_60", "120": "XGBoost_grid_1_AutoML_8_20221220_224639_model_30"}, "rmse": {"0": 3.173814102887965, "1": 3.181906884080173, "2": 3.2446535575222497, "3": 3.275107009813093, "4": 3.2762492225987234, "5": 3.2843110893701173, "6": 3.287383091639727, "7": 3.294067909950147, "8": 3.3054820400648444, "9": 3.3081503494332223, "10": 3.311242978947785, "11": 3.3179484943582853, "12": 3.320138329408794, "13": 3.3204874592840583, "14": 3.336934992485261, "15": 3.347834941212982, "16": 3.34902834633315, "17": 3.376823620797534, "18": 3.3813302448317364, "19": 3.393785837532837, "20": 3.397796205369975, "21": 3.39969919549436, "22": 3.405210051389025, "23": 3.407064715775275, "24": 3.416946613427547, "25": 3.42859892050341, "26": 3.4296904599361357, "27": 3.451273202552005, "28": 3.4639420844901565, "29": 3.467888914157266, "30": 3.472443905145693, "31": 3.472749652013203, "32": 3.474077267184516, "33": 3.4742682596316263, "34": 3.487503963826064, "35": 3.495780772385417, "36": 3.495983155277368, "37": 3.498505826289535, "38": 3.506274283923799, "39": 3.511351282319582, "40": 3.528898622467638, "41": 3.538637453973484, "42": 3.5501448319598503, "43": 3.556865233117408, "44": 3.558822333438479, "45": 3.5699393621827897, "46": 3.5746235777811366, "47": 3.5812929347935403, "48": 3.617778553336521, "49": 3.6217628232359806, "50": 3.6390000690293984, "51": 3.646182238531869, "52": 3.649598512257752, "53": 3.6749890990200025, "54": 3.680400188441172, "55": 3.6945752233322, "56": 3.710823518028387, "57": 3.7145183199040703, "58": 3.7151511626673455, "59": 3.728618665435219, "60": 3.761131907340839, "61": 3.7669811785062737, "62": 3.782287806779415, "63": 3.7900354500450906, "64": 3.794129273063786, "65": 3.800614540888309, "66": 3.8222101537889257, "67": 3.830160302092793, "68": 3.841802145089363, "69": 3.859516228781652, "70": 3.873659446716629, "71": 3.8765243853943994, "72": 3.882064888937768, "73": 3.909206156661292, "74": 3.91832441859428, "75": 3.929006198308711, "76": 3.931733241041353, "77": 3.949190506239467, "78": 3.9629150915288407, "79": 3.9821195370799938, "80": 3.995386124749523, "81": 4.001505634422444, "82": 4.039463905131224, "83": 4.051792342232333, "84": 4.052103070887679, "85": 4.061478200074863, "86": 4.069730105898989, "87": 4.078907712480414, "88": 4.1340892283771264, "89": 4.136152528535725, "90": 4.147264847941456, "91": 4.155415580538735, "92": 4.168530043924212, "93": 4.249826779992898, "94": 4.261929316942883, "95": 4.285113354123362, "96": 4.3104785566995, "97": 4.3321105224395255, "98": 4.348129305817575, "99": 4.44374575732897, "100": 4.533949341138618, "101": 4.58722948209088, "102": 4.630832471658804, "103": 4.6322379704717225, "104": 4.649096471252716, "105": 4.676549950197834, "106": 5.59367578103071, "107": 5.758707400243849, "108": 6.23980402364498, "109": 7.631739477336032, "110": 9.07005392287756, "111": 9.07005392287756, "112": 9.081898994649617, "113": 9.102010346794732, "114": 9.102010346794732, "115": 9.102016549323714, "116": 9.102021103363926, "117": 9.144483128341896, "118": 11.44682528298872, "119": 11.49576813478271, "120": 13.274121935502595}, "mse": {"0": 10.073095959690535, "1": 10.124531418956796, "2": 10.52777670834179, "3": 10.72632592572686, "4": 10.73380896857874, "5": 10.786699331759529, "6": 10.80688759119877, "7": 10.850883395363327, "8": 10.926211517191245, "9": 10.943858734455151, "10": 10.964330065631003, "11": 11.008782211214411, "12": 11.023318526409415, "13": 11.0256369672627, "14": 11.135135144072608, "15": 11.207998793606532, "16": 11.21599086454295, "17": 11.40293776597617, "18": 11.433394224613853, "19": 11.51778231103846, "20": 11.5450190532266, "21": 11.557954619845, "22": 11.595455494080849, "23": 11.608089977480857, "24": 11.67552415901398, "25": 11.755290557677148, "26": 11.76277665097694, "27": 11.911286718653574, "28": 11.99889476470201, "29": 12.026253520934862, "30": 12.05786667438347, "31": 12.05999014555782, "32": 12.069212858368235, "33": 12.070539939883773, "34": 12.162683897702506, "35": 12.22048320857958, "36": 12.2218982219831, "37": 12.239543016581823, "38": 12.293959354105349, "39": 12.329587827847371, "40": 12.453125487653995, "41": 12.52195503066394, "42": 12.603528327891231, "43": 12.65129028655935, "44": 12.665216400980505, "45": 12.744467049662063, "46": 12.777933722828816, "47": 12.82565908480213, "48": 13.088321660981686, "49": 13.11716594777426, "50": 13.242321502395964, "51": 13.294644916585275, "52": 13.319569300674, "53": 13.50554487791585, "54": 13.545345547077815, "55": 13.649886080860172, "56": 13.770211181952574, "57": 13.797646348902957, "58": 13.802348161468537, "59": 13.902597152231913, "60": 14.146113224417338, "61": 14.190147199220512, "62": 14.30570105331224, "63": 14.364368712598491, "64": 14.395416940719535, "65": 14.444670888411654, "66": 14.609290459727164, "67": 14.670127939727552, "68": 14.759443722013236, "69": 14.895865520228948, "70": 15.005237509136984, "71": 15.027441310557418, "72": 15.0704278019234, "73": 15.281892775278548, "74": 15.3532662493522, "75": 15.437089706348274, "76": 15.458526278709543, "77": 15.596105654571936, "78": 15.704696022667038, "79": 15.857276007594184, "80": 15.963110285841012, "81": 16.012047342314567, "82": 16.317268640858, "83": 16.417021184572576, "84": 16.419539297097355, "85": 16.495605169683344, "86": 16.562703134860595, "87": 16.637488126932208, "88": 17.090693748183785, "89": 17.107757739312465, "90": 17.19980571897087, "91": 17.26747864698407, "92": 17.376642727098798, "93": 18.06102765994481, "94": 18.16404150261723, "95": 18.36219645768637, "96": 18.580225387766205, "97": 18.76718157863126, "98": 18.906228460109627, "99": 19.746876355779225, "100": 20.556696628011306, "101": 21.04267432136376, "102": 21.444609380569588, "103": 21.45762861507998, "104": 21.61409799901445, "105": 21.87011943669536, "106": 31.28920874328952, "107": 33.162710921623265, "108": 38.93515425349608, "109": 58.24344744992926, "110": 82.26587816390663, "111": 82.26587816390663, "112": 82.48088934901767, "113": 82.84659235315839, "114": 82.84659235315839, "115": 82.84670526416276, "116": 82.84678816608226, "117": 83.6215716845296, "118": 131.02980905926975, "119": 132.15268500868552, "120": 176.20231315859118}, "mae": {"0": 2.2242011329769404, "1": 2.201441310391276, "2": 2.2411546381497685, "3": 2.268276262847809, "4": 2.2951796021464763, "5": 2.276578841670867, "6": 2.277565382778745, "7": 2.29849565889579, "8": 2.275903201678395, "9": 2.336927103661475, "10": 2.2881490060855696, "11": 2.255155130115904, "12": 2.3443269677531005, "13": 2.349567479900681, "14": 2.310165962045751, "15": 2.246996318914204, "16": 2.365742625800513, "17": 2.3981019203687164, "18": 2.369187469269391, "19": 2.4239236961780306, "20": 2.329219678922156, "21": 2.4291410925311747, "22": 2.4171774047911887, "23": 2.404964953361523, "24": 2.4033434548622585, "25": 2.4271963876999605, "26": 2.423200569979921, "27": 2.4240642768299057, "28": 2.4359972637008878, "29": 2.488845111829902, "30": 2.394805375638303, "31": 2.438699032984715, "32": 2.489200163327299, "33": 2.4552321997685724, "34": 2.488899222728182, "35": 2.479687465399512, "36": 2.4827408167749785, "37": 2.478027844038166, "38": 2.523033353605208, "39": 2.51439195105413, "40": 2.5278296911924496, "41": 2.5499593088199446, "42": 2.5868057051992204, "43": 2.5594866758737536, "44": 2.5547727925798145, "45": 2.5197714687530035, "46": 2.5450415245633096, "47": 2.581955561241985, "48": 2.603639341421949, "49": 2.590148667568003, "50": 2.638613882881369, "51": 2.627636210794446, "52": 2.4952252497438523, "53": 2.6816455321922774, "54": 2.6797561674636365, "55": 2.718914222738835, "56": 2.684752091187301, "57": 2.698898856063673, "58": 2.695816629173852, "59": 2.7073207231271166, "60": 2.751029470513378, "61": 2.7348653481294383, "62": 2.7706178530708088, "63": 2.808805162095948, "64": 2.7823966281997787, "65": 2.802808995815918, "66": 2.833734828035142, "67": 2.823669261649803, "68": 2.823438009971163, "69": 2.8710395574947944, "70": 2.808047451461074, "71": 2.882811999711834, "72": 2.869220809410503, "73": 2.8767192047826766, "74": 2.930585404289645, "75": 2.8965125401312566, "76": 2.946920458442128, "77": 2.9130753710313235, "78": 2.8997046653711247, "79": 2.950591415821756, "80": 2.9393034435101297, "81": 2.975631297834444, "82": 3.0099004243435785, "83": 3.0044049527280925, "84": 2.9807254867011137, "85": 3.0174076155082368, "86": 3.015271332848045, "87": 3.04701811541494, "88": 3.1107299598152207, "89": 3.1344652563401354, "90": 3.0706404265377407, "91": 3.1192582160922644, "92": 3.134098837859123, "93": 3.2134874549811494, "94": 3.23910504684175, "95": 3.198274379350054, "96": 3.258420999380814, "97": 3.2923799679121224, "98": 3.305150945198573, "99": 3.350767220296373, "100": 3.464826171289439, "101": 3.602982963649685, "102": 3.5229353505569887, "103": 3.647158351742856, "104": 3.5035397447167016, "105": 3.690631117196795, "106": 4.398442085457386, "107": 4.363903885299094, "108": 5.028785402869547, "109": 6.492652648107304, "110": 7.723337884827596, "111": 7.723337884827596, "112": 7.733856762023582, "113": 7.740458767854676, "114": 7.740458767854676, "115": 7.740463872456806, "116": 7.740466659637872, "117": 7.780408465896881, "118": 9.708166560921454, "119": 9.858841641371225, "120": 12.810140156859385}, "rmsle": {"0": 0.0069892084020981, "1": 0.0070175014209308, "2": 0.0071388976631809, "3": 0.0072140350285905, "4": 0.0072176058078604, "5": 0.007256112821669, "6": 0.0072368413527212, "7": 0.0072501218420477, "8": 0.0072823305089644, "9": 0.0072844534753379, "10": 0.0073095653098565, "11": 0.0073112947272123, "12": 0.0073094786256889, "13": 0.0073325061060385, "14": 0.0073452833881808, "15": 0.007353115487911, "16": 0.0073780914151984, "17": 0.0074401095010609, "18": 0.0074454793906598, "19": 0.0074812890938925, "20": 0.0074990106252676, "21": 0.0074766495657033, "22": 0.00749181140624, "23": 0.0075162585378414, "24": 0.0075359401337861, "25": 0.0075632700202933, "26": 0.007572420944649, "27": 0.0076167206897817, "28": 0.0076407721286161, "29": 0.0076316092135894, "30": 0.0076444121564001, "31": 0.0076601547402547, "32": 0.0076473046770306, "33": 0.007657353863434, "34": 0.0076781384673107, "35": 0.0077067499676107, "36": 0.0077174938514112, "37": 0.0077088800521729, "38": 0.0077247716671159, "39": 0.0077332814600245, "40": 0.0077792109898138, "41": 0.0077963112120651, "42": 0.0078177366830544, "43": 0.0078346878091308, "44": 0.0078344657307497, "45": 0.0078606282156211, "46": 0.0078765519036054, "47": 0.0078894947192614, "48": 0.0079770006208738, "49": 0.0079793581427209, "50": 0.0080039646714717, "51": 0.008018093250027, "52": 0.0080461672157143, "53": 0.0080855695684597, "54": 0.0081043645134255, "55": 0.0081286103675814, "56": 0.0081697150188489, "57": 0.0081684666654973, "58": 0.0081717218047507, "59": 0.0082002829527744, "60": 0.0082815153130622, "61": 0.0082912678928155, "62": 0.0083256161056844, "63": 0.0083352593863767, "64": 0.0083484905938571, "65": 0.0083507803182336, "66": 0.008415258322552, "67": 0.0084344711168775, "68": 0.0084475279325608, "69": 0.0084911359551794, "70": 0.0085231005399762, "71": 0.0085244682088732, "72": 0.00854162916182, "73": 0.0085991462528407, "74": 0.0086281286531933, "75": 0.0086381594936059, "76": 0.0086456363472866, "77": 0.008698067523959, "78": 0.0087153155416291, "79": 0.0087698977202256, "80": 0.0087711448409545, "81": 0.0087948270587082, "82": 0.0089058247482056, "83": 0.0089228716901134, "84": 0.0089076889426555, "85": 0.0089272586203861, "86": 0.0089687190071654, "87": 0.0089723477999736, "88": 0.0090702186456557, "89": 0.0091070054702208, "90": 0.0091062871613914, "91": 0.0091545908379717, "92": 0.0091773845245469, "93": 0.0093565862309537, "94": 0.0093667218381259, "95": 0.0094168520621356, "96": 0.0094939281380576, "97": 0.0095421286319896, "98": 0.0095527128843228, "99": 0.0097570447487315, "100": 0.0099779553741205, "101": 0.0100938067210332, "102": 0.0101948865485267, "103": 0.0101478011586295, "104": 0.0102165562403619, "105": 0.0102516213327286, "106": 0.012178914471144, "107": 0.0125903569950115, "108": 0.0139015650548867, "109": 0.0167915993753824, "110": 0.0198025930207916, "111": 0.0198025930207916, "112": 0.0198284453613591, "113": 0.019875860119596, "114": 0.019875860119596, "115": 0.0198758737853778, "116": 0.0198758836415034, "117": 0.0199703068910706, "118": 0.0248674147422649, "119": 0.0251031741152351, "120": 0.0294798732133163}, "mean_residual_deviance": {"0": 10.073095959690535, "1": 10.124531418956796, "2": 10.52777670834179, "3": 10.72632592572686, "4": 10.73380896857874, "5": 10.786699331759529, "6": 10.80688759119877, "7": 10.850883395363327, "8": 10.926211517191245, "9": 10.943858734455151, "10": 10.964330065631003, "11": 11.008782211214411, "12": 11.023318526409415, "13": 11.0256369672627, "14": 11.135135144072608, "15": 11.207998793606532, "16": 11.21599086454295, "17": 11.40293776597617, "18": 11.433394224613853, "19": 11.51778231103846, "20": 11.5450190532266, "21": 11.557954619845, "22": 11.595455494080849, "23": 11.608089977480857, "24": 11.67552415901398, "25": 11.755290557677148, "26": 11.76277665097694, "27": 11.911286718653574, "28": 11.99889476470201, "29": 12.026253520934862, "30": 12.05786667438347, "31": 12.05999014555782, "32": 12.069212858368235, "33": 12.070539939883773, "34": 12.162683897702506, "35": 12.22048320857958, "36": 12.2218982219831, "37": 12.239543016581823, "38": 12.293959354105349, "39": 12.329587827847371, "40": 12.453125487653995, "41": 12.52195503066394, "42": 12.603528327891231, "43": 12.65129028655935, "44": 12.665216400980505, "45": 12.744467049662063, "46": 12.777933722828816, "47": 12.82565908480213, "48": 13.088321660981686, "49": 13.11716594777426, "50": 13.242321502395964, "51": 13.294644916585275, "52": 13.319569300674, "53": 13.50554487791585, "54": 13.545345547077815, "55": 13.649886080860172, "56": 13.770211181952574, "57": 13.797646348902957, "58": 13.802348161468537, "59": 13.902597152231913, "60": 14.146113224417338, "61": 14.190147199220512, "62": 14.30570105331224, "63": 14.364368712598491, "64": 14.395416940719535, "65": 14.444670888411654, "66": 14.609290459727164, "67": 14.670127939727552, "68": 14.759443722013236, "69": 14.895865520228948, "70": 15.005237509136984, "71": 15.027441310557418, "72": 15.0704278019234, "73": 15.281892775278548, "74": 15.3532662493522, "75": 15.437089706348274, "76": 15.458526278709543, "77": 15.596105654571936, "78": 15.704696022667038, "79": 15.857276007594184, "80": 15.963110285841012, "81": 16.012047342314567, "82": 16.317268640858, "83": 16.417021184572576, "84": 16.419539297097355, "85": 16.495605169683344, "86": 16.562703134860595, "87": 16.637488126932208, "88": 17.090693748183785, "89": 17.107757739312465, "90": 17.19980571897087, "91": 17.26747864698407, "92": 17.376642727098798, "93": 18.06102765994481, "94": 18.16404150261723, "95": 18.36219645768637, "96": 18.580225387766205, "97": 18.76718157863126, "98": 18.906228460109627, "99": 19.746876355779225, "100": 20.556696628011306, "101": 21.04267432136376, "102": 21.444609380569588, "103": 21.45762861507998, "104": 21.61409799901445, "105": 21.87011943669536, "106": 31.28920874328952, "107": 33.162710921623265, "108": 38.93515425349608, "109": 58.24344744992926, "110": 82.26587816390663, "111": 82.26587816390663, "112": 82.48088934901767, "113": 82.84659235315839, "114": 82.84659235315839, "115": 82.84670526416276, "116": 82.84678816608226, "117": 83.6215716845296, "118": 131.02980905926975, "119": 132.15268500868552, "120": 176.20231315859118}}, "event_log": {"timestamp": {"0": "22:46:39.178", "1": "22:46:39.178", "2": "22:46:39.179", "3": "22:46:39.179", "4": "22:46:39.179", "5": "22:46:39.179", "6": "22:46:39.179", "7": "22:46:39.179", "8": "22:46:39.179", "9": "22:46:39.179", "10": "22:46:39.179", "11": "22:46:39.179", "12": "22:46:39.180", "13": "22:46:39.180", "14": "22:46:39.180", "15": "22:46:39.182", "16": "22:46:39.185", "17": "22:46:39.185", "18": "22:46:39.187", "19": "22:47:12.176", "20": "22:47:12.176", "21": "22:47:12.204", "22": "22:47:12.206", "23": "22:47:12.206", "24": "22:47:12.209", "25": "22:47:13.353", "26": "22:47:13.353", "27": "22:47:13.373", "28": "22:47:13.374", "29": "22:47:13.377", "30": "22:47:28.279", "31": "22:47:28.279", "32": "22:47:28.370", "33": "22:47:28.370", "34": "22:47:28.373", "35": "22:47:28.796", "36": "22:47:28.796", "37": "22:47:28.856", "38": "22:47:28.856", "39": "22:47:28.860", "40": "22:47:59.224", "41": "22:47:59.224", "42": "22:47:59.249", "43": "22:47:59.249", "44": "22:47:59.252", "45": "22:48:30.561", "46": "22:48:30.561", "47": "22:48:30.604", "48": "22:48:30.606", "49": "22:48:30.606", "50": "22:48:30.609", "51": "22:48:43.187", "52": "22:48:43.187", "53": "22:48:43.262", "54": "22:48:43.263", "55": "22:48:43.263", "56": "22:48:43.266", "57": "22:48:56.687", "58": "22:48:56.687", "59": "22:48:56.763", "60": "22:48:56.764", "61": "22:48:56.765", "62": "22:48:56.767", "63": "22:49:10.699", "64": "22:49:10.699", "65": "22:49:10.758", "66": "22:49:10.759", "67": "22:49:10.759", "68": "22:49:10.762", "69": "22:49:11.211", "70": "22:49:11.212", "71": "22:49:11.276", "72": "22:49:11.276", "73": "22:49:11.279", "74": "22:49:11.801", "75": "22:49:11.801", "76": "22:49:11.909", "77": "22:49:11.909", "78": "22:49:11.912", "79": "22:50:12.182", "80": "22:50:12.182", "81": "22:50:12.207", "82": "22:50:12.207", "83": "22:50:12.209", "84": "22:50:41.604", "85": "22:50:41.604", "86": "22:50:41.651", "87": "22:50:41.651", "88": "22:50:41.654", "89": "22:50:58.417", "90": "22:50:58.417", "91": "22:50:58.510", "92": "22:50:58.510", "93": "22:50:58.512", "94": "22:50:59.743", "95": "22:50:59.743", "96": "22:50:59.755", "97": "22:50:59.755", "98": "22:50:59.757", "99": "22:51:00.215", "100": "22:51:00.215", "101": "22:51:00.287", "102": "22:51:00.287", "103": "22:51:00.290", "104": "22:51:00.912", "105": "22:51:00.912", "106": "22:51:01.27", "107": "22:51:01.27", "108": "22:51:01.32", "109": "22:51:25.38", "110": "22:51:25.38", "111": "22:51:55.71", "112": "22:51:55.72", "113": "22:53:13.115", "114": "22:53:13.115", "115": "22:53:45.138", "116": "22:53:45.138", "117": "22:54:53.168", "118": "22:54:53.168", "119": "22:56:06.200", "120": "22:56:06.200", "121": "22:56:52.553", "122": "22:56:52.553", "123": "22:57:18.582", "124": "22:57:18.582", "125": "22:58:44.628", "126": "22:58:44.628", "127": "22:59:11.692", "128": "22:59:11.692", "129": "22:59:35.726", "130": "22:59:35.726", "131": "23:00:52.785", "132": "23:00:52.785", "133": "23:01:21.876", "134": "23:01:21.876", "135": "23:02:32.919", "136": "23:02:32.919", "137": "23:03:32.22", "138": "23:03:32.22", "139": "23:04:13.53", "140": "23:04:13.53", "141": "23:05:51.115", "142": "23:05:51.115", "143": "23:07:07.273", "144": "23:07:07.273", "145": "23:07:34.295", "146": "23:07:34.295", "147": "23:08:24.363", "148": "23:08:24.363", "149": "23:09:07.401", "150": "23:09:07.401", "151": "23:10:21.433", "152": "23:10:21.434", "153": "23:10:52.455", "154": "23:10:52.455", "155": "23:11:54.501", "156": "23:11:54.501", "157": "23:12:44.530", "158": "23:12:44.531", "159": "23:13:49.565", "160": "23:13:49.565", "161": "23:14:31.591", "162": "23:14:31.592", "163": "23:15:43.625", "164": "23:15:43.625", "165": "23:16:36.999", "166": "23:16:36.999", "167": "23:16:41.858", "168": "23:16:41.858", "169": "23:16:41.858", "170": "23:16:41.874", "171": "23:16:41.875", "172": "23:16:41.877", "173": "23:16:48.878", "174": "23:16:48.878", "175": "23:17:00.948", "176": "23:17:00.948", "177": "23:17:32.53", "178": "23:17:32.53", "179": "23:17:47.144", "180": "23:17:47.144", "181": "23:18:04.249", "182": "23:18:04.249", "183": "23:18:20.397", "184": "23:18:20.397", "185": "23:18:33.497", "186": "23:18:33.497", "187": "23:18:54.584", "188": "23:18:54.584", "189": "23:19:09.702", "190": "23:19:09.702", "191": "23:19:22.800", "192": "23:19:22.800", "193": "23:19:47.888", "194": "23:19:47.888", "195": "23:20:00.60", "196": "23:20:00.60", "197": "23:20:13.133", "198": "23:20:13.133", "199": "23:20:33.235", "200": "23:20:33.235", "201": "23:20:47.312", "202": "23:20:47.313", "203": "23:21:09.399", "204": "23:21:09.399", "205": "23:21:09.474", "206": "23:21:40.491", "207": "23:21:40.492", "208": "23:22:12.630", "209": "23:22:12.630", "210": "23:22:26.787", "211": "23:22:26.787", "212": "23:22:47.855", "213": "23:22:47.855", "214": "23:23:05.48", "215": "23:23:05.48", "216": "23:23:25.178", "217": "23:23:25.178", "218": "23:23:38.268", "219": "23:23:38.268", "220": "23:23:57.398", "221": "23:23:57.398", "222": "23:24:11.545", "223": "23:24:11.545", "224": "23:24:19.608", "225": "23:24:19.609", "226": "23:24:33.685", "227": "23:24:33.686", "228": "23:24:43.792", "229": "23:24:43.792", "230": "23:25:01.866", "231": "23:25:01.866", "232": "23:25:16.991", "233": "23:25:16.992", "234": "23:25:48.123", "235": "23:25:48.124", "236": "23:25:56.199", "237": "23:25:56.199", "238": "23:26:09.300", "239": "23:26:09.300", "240": "23:26:20.394", "241": "23:26:20.395", "242": "23:26:40.511", "243": "23:26:40.511", "244": "23:26:55.597", "245": "23:26:55.598", "246": "23:27:11.743", "247": "23:27:11.744", "248": "23:27:34.857", "249": "23:27:34.858", "250": "23:27:50.990", "251": "23:27:50.991", "252": "23:28:07.111", "253": "23:28:07.111", "254": "23:28:33.205", "255": "23:28:33.206", "256": "23:28:43.349", "257": "23:28:43.349", "258": "23:28:55.451", "259": "23:28:55.452", "260": "23:29:22.545", "261": "23:29:22.545", "262": "23:29:31.665", "263": "23:29:31.665", "264": "23:29:53.889", "265": "23:29:53.889", "266": "23:30:13.34", "267": "23:30:13.35", "268": "23:30:13.118", "269": "23:30:26.126", "270": "23:30:26.127", "271": "23:30:39.197", "272": "23:30:39.197", "273": "23:31:16.278", "274": "23:31:16.278", "275": "23:31:30.420", "276": "23:31:30.420", "277": "23:31:53.519", "278": "23:31:53.519", "279": "23:32:08.681", "280": "23:32:08.682", "281": "23:32:23.804", "282": "23:32:23.804", "283": "23:32:35.881", "284": "23:32:35.881", "285": "23:32:54.987", "286": "23:32:54.987", "287": "23:33:16.160", "288": "23:33:16.161", "289": "23:33:29.248", "290": "23:33:29.249", "291": "23:33:48.348", "292": "23:33:48.348", "293": "23:33:49.286", "294": "23:33:49.286", "295": "23:33:49.286", "296": "23:33:49.306", "297": "23:33:49.306", "298": "23:33:49.310", "299": "23:36:54.346", "300": "23:36:54.346", "301": "23:39:28.506", "302": "23:39:28.506", "303": "23:41:50.685", "304": "23:41:50.685", "305": "23:42:24.130", "306": "23:42:24.130", "307": "23:42:24.130", "308": "23:42:24.154", "309": "23:42:24.154", "310": "23:42:24.157", "311": "23:42:24.665", "312": "23:42:24.665", "313": "23:42:24.801", "314": "23:42:24.801", "315": "23:42:24.804", "316": "23:42:26.925", "317": "23:42:26.925", "318": "23:42:27.780", "319": "23:42:27.780", "320": "23:42:27.784", "321": "23:43:49.798", "322": "23:43:49.798", "323": "23:44:08.860", "324": "23:44:08.860", "325": "23:44:08.860", "326": "23:44:08.888", "327": "23:44:08.888", "328": "23:44:08.892", "329": "23:45:36.908", "330": "23:45:36.908", "331": "23:45:48.1", "332": "23:45:48.1", "333": "23:45:51.659", "334": "23:45:51.659", "335": "23:45:51.659", "336": "23:45:51.708", "337": "23:45:51.708", "338": "23:45:51.711", "339": "23:45:53.630", "340": "23:45:53.630", "341": "23:45:54.264", "342": "23:45:54.272", "343": "23:45:54.273", "344": "23:45:54.273", "345": "23:46:01.408", "346": "23:46:01.409", "347": "23:46:01.412", "348": "23:46:01.413", "349": "23:46:01.413", "350": "23:46:05.531", "351": "23:46:05.531", "352": "23:46:05.534", "353": "23:46:05.534", "354": "23:46:05.536", "355": "23:46:11.812", "356": "23:46:11.812", "357": "23:46:12.21", "358": "23:46:12.24", "359": "23:46:12.24", "360": "23:46:12.29", "361": "23:46:40.32", "362": "23:46:41.34", "363": "23:46:42.34", "364": "23:46:42.992", "365": "23:46:42.992", "366": "23:46:44.349", "367": "23:46:44.349", "368": "23:46:44.349", "369": "23:46:44.349", "370": "23:46:44.349", "371": "23:46:44.349", "372": "23:46:44.349", "373": "23:46:44.349", "374": "23:46:44.349", "375": "23:46:44.349", "376": "23:46:44.371", "377": "23:46:44.371"}, "level": {"0": "INFO", "1": "INFO", "2": "INFO", "3": "INFO", "4": "INFO", "5": "INFO", "6": "INFO", "7": "INFO", "8": "INFO", "9": "INFO", "10": "INFO", "11": "INFO", "12": "DEBUG", "13": "DEBUG", "14": "INFO", "15": "INFO", "16": "DEBUG", "17": "INFO", "18": "DEBUG", "19": "DEBUG", "20": "DEBUG", "21": "INFO", "22": "DEBUG", "23": "INFO", "24": "DEBUG", "25": "DEBUG", "26": "DEBUG", "27": "DEBUG", "28": "INFO", "29": "DEBUG", "30": "DEBUG", "31": "DEBUG", "32": "DEBUG", "33": "INFO", "34": "DEBUG", "35": "DEBUG", "36": "DEBUG", "37": "DEBUG", "38": "INFO", "39": "DEBUG", "40": "DEBUG", "41": "DEBUG", "42": "DEBUG", "43": "INFO", "44": "DEBUG", "45": "DEBUG", "46": "DEBUG", "47": "INFO", "48": "DEBUG", "49": "INFO", "50": "DEBUG", "51": "DEBUG", "52": "DEBUG", "53": "INFO", "54": "DEBUG", "55": "INFO", "56": "DEBUG", "57": "DEBUG", "58": "DEBUG", "59": "INFO", "60": "DEBUG", "61": "INFO", "62": "DEBUG", "63": "DEBUG", "64": "DEBUG", "65": "INFO", "66": "DEBUG", "67": "INFO", "68": "DEBUG", "69": "DEBUG", "70": "DEBUG", "71": "DEBUG", "72": "INFO", "73": "DEBUG", "74": "DEBUG", "75": "DEBUG", "76": "DEBUG", "77": "INFO", "78": "DEBUG", "79": "DEBUG", "80": "DEBUG", "81": "DEBUG", "82": "INFO", "83": "DEBUG", "84": "DEBUG", "85": "DEBUG", "86": "DEBUG", "87": "INFO", "88": "DEBUG", "89": "DEBUG", "90": "DEBUG", "91": "DEBUG", "92": "INFO", "93": "DEBUG", "94": "DEBUG", "95": "DEBUG", "96": "DEBUG", "97": "INFO", "98": "DEBUG", "99": "DEBUG", "100": "DEBUG", "101": "DEBUG", "102": "INFO", "103": "DEBUG", "104": "DEBUG", "105": "DEBUG", "106": "DEBUG", "107": "INFO", "108": "DEBUG", "109": "DEBUG", "110": "DEBUG", "111": "DEBUG", "112": "DEBUG", "113": "DEBUG", "114": "DEBUG", "115": "DEBUG", "116": "DEBUG", "117": "DEBUG", "118": "DEBUG", "119": "DEBUG", "120": "DEBUG", "121": "DEBUG", "122": "DEBUG", "123": "DEBUG", "124": "DEBUG", "125": "DEBUG", "126": "DEBUG", "127": "DEBUG", "128": "DEBUG", "129": "DEBUG", "130": "DEBUG", "131": "DEBUG", "132": "DEBUG", "133": "DEBUG", "134": "DEBUG", "135": "DEBUG", "136": "DEBUG", "137": "DEBUG", "138": "DEBUG", "139": "DEBUG", "140": "DEBUG", "141": "DEBUG", "142": "DEBUG", "143": "DEBUG", "144": "DEBUG", "145": "DEBUG", "146": "DEBUG", "147": "DEBUG", "148": "DEBUG", "149": "DEBUG", "150": "DEBUG", "151": "DEBUG", "152": "DEBUG", "153": "DEBUG", "154": "DEBUG", "155": "DEBUG", "156": "DEBUG", "157": "DEBUG", "158": "DEBUG", "159": "DEBUG", "160": "DEBUG", "161": "DEBUG", "162": "DEBUG", "163": "DEBUG", "164": "DEBUG", "165": "DEBUG", "166": "DEBUG", "167": "DEBUG", "168": "DEBUG", "169": "DEBUG", "170": "DEBUG", "171": "INFO", "172": "DEBUG", "173": "DEBUG", "174": "DEBUG", "175": "DEBUG", "176": "DEBUG", "177": "DEBUG", "178": "DEBUG", "179": "DEBUG", "180": "DEBUG", "181": "DEBUG", "182": "DEBUG", "183": "DEBUG", "184": "DEBUG", "185": "DEBUG", "186": "DEBUG", "187": "DEBUG", "188": "DEBUG", "189": "DEBUG", "190": "DEBUG", "191": "DEBUG", "192": "DEBUG", "193": "DEBUG", "194": "DEBUG", "195": "DEBUG", "196": "DEBUG", "197": "DEBUG", "198": "DEBUG", "199": "DEBUG", "200": "DEBUG", "201": "DEBUG", "202": "DEBUG", "203": "DEBUG", "204": "DEBUG", "205": "INFO", "206": "DEBUG", "207": "DEBUG", "208": "DEBUG", "209": "DEBUG", "210": "DEBUG", "211": "DEBUG", "212": "DEBUG", "213": "DEBUG", "214": "DEBUG", "215": "DEBUG", "216": "DEBUG", "217": "DEBUG", "218": "DEBUG", "219": "DEBUG", "220": "DEBUG", "221": "DEBUG", "222": "DEBUG", "223": "DEBUG", "224": "DEBUG", "225": "DEBUG", "226": "DEBUG", "227": "DEBUG", "228": "DEBUG", "229": "DEBUG", "230": "DEBUG", "231": "DEBUG", "232": "DEBUG", "233": "DEBUG", "234": "DEBUG", "235": "DEBUG", "236": "DEBUG", "237": "DEBUG", "238": "DEBUG", "239": "DEBUG", "240": "DEBUG", "241": "DEBUG", "242": "DEBUG", "243": "DEBUG", "244": "DEBUG", "245": "DEBUG", "246": "DEBUG", "247": "DEBUG", "248": "DEBUG", "249": "DEBUG", "250": "DEBUG", "251": "DEBUG", "252": "DEBUG", "253": "DEBUG", "254": "DEBUG", "255": "DEBUG", "256": "DEBUG", "257": "DEBUG", "258": "DEBUG", "259": "DEBUG", "260": "DEBUG", "261": "DEBUG", "262": "DEBUG", "263": "DEBUG", "264": "DEBUG", "265": "DEBUG", "266": "DEBUG", "267": "DEBUG", "268": "INFO", "269": "DEBUG", "270": "DEBUG", "271": "DEBUG", "272": "DEBUG", "273": "DEBUG", "274": "DEBUG", "275": "DEBUG", "276": "DEBUG", "277": "DEBUG", "278": "DEBUG", "279": "DEBUG", "280": "DEBUG", "281": "DEBUG", "282": "DEBUG", "283": "DEBUG", "284": "DEBUG", "285": "DEBUG", "286": "DEBUG", "287": "DEBUG", "288": "DEBUG", "289": "DEBUG", "290": "DEBUG", "291": "DEBUG", "292": "DEBUG", "293": "DEBUG", "294": "DEBUG", "295": "DEBUG", "296": "DEBUG", "297": "INFO", "298": "DEBUG", "299": "DEBUG", "300": "DEBUG", "301": "DEBUG", "302": "DEBUG", "303": "DEBUG", "304": "DEBUG", "305": "DEBUG", "306": "DEBUG", "307": "DEBUG", "308": "DEBUG", "309": "INFO", "310": "DEBUG", "311": "DEBUG", "312": "DEBUG", "313": "DEBUG", "314": "INFO", "315": "DEBUG", "316": "DEBUG", "317": "DEBUG", "318": "DEBUG", "319": "INFO", "320": "DEBUG", "321": "DEBUG", "322": "DEBUG", "323": "DEBUG", "324": "DEBUG", "325": "DEBUG", "326": "DEBUG", "327": "INFO", "328": "DEBUG", "329": "DEBUG", "330": "DEBUG", "331": "DEBUG", "332": "DEBUG", "333": "DEBUG", "334": "DEBUG", "335": "DEBUG", "336": "DEBUG", "337": "INFO", "338": "DEBUG", "339": "DEBUG", "340": "DEBUG", "341": "DEBUG", "342": "DEBUG", "343": "INFO", "344": "INFO", "345": "DEBUG", "346": "DEBUG", "347": "DEBUG", "348": "INFO", "349": "INFO", "350": "DEBUG", "351": "INFO", "352": "DEBUG", "353": "INFO", "354": "DEBUG", "355": "DEBUG", "356": "DEBUG", "357": "INFO", "358": "DEBUG", "359": "INFO", "360": "DEBUG", "361": "DEBUG", "362": "DEBUG", "363": "DEBUG", "364": "DEBUG", "365": "DEBUG", "366": "INFO", "367": "DEBUG", "368": "DEBUG", "369": "DEBUG", "370": "DEBUG", "371": "DEBUG", "372": "INFO", "373": "INFO", "374": "INFO", "375": "INFO", "376": "DEBUG", "377": "DEBUG"}, "stage": {"0": "Workflow", "1": "Validation", "2": "Validation", "3": "Validation", "4": "DataImport", "5": "DataImport", "6": "DataImport", "7": "DataImport", "8": "DataImport", "9": "DataImport", "10": "DataImport", "11": "Workflow", "12": "Workflow", "13": "Workflow", "14": "Workflow", "15": "Workflow", "16": "ModelTraining", "17": "ModelTraining", "18": "ModelTraining", "19": "ModelTraining", "20": "ModelTraining", "21": "ModelTraining", "22": "ModelTraining", "23": "ModelTraining", "24": "ModelTraining", "25": "ModelTraining", "26": "ModelTraining", "27": "ModelTraining", "28": "ModelTraining", "29": "ModelTraining", "30": "ModelTraining", "31": "ModelTraining", "32": "ModelTraining", "33": "ModelTraining", "34": "ModelTraining", "35": "ModelTraining", "36": "ModelTraining", "37": "ModelTraining", "38": "ModelTraining", "39": "ModelTraining", "40": "ModelTraining", "41": "ModelTraining", "42": "ModelTraining", "43": "ModelTraining", "44": "ModelTraining", "45": "ModelTraining", "46": "ModelTraining", "47": "ModelTraining", "48": "ModelTraining", "49": "ModelTraining", "50": "ModelTraining", "51": "ModelTraining", "52": "ModelTraining", "53": "ModelTraining", "54": "ModelTraining", "55": "ModelTraining", "56": "ModelTraining", "57": "ModelTraining", "58": "ModelTraining", "59": "ModelTraining", "60": "ModelTraining", "61": "ModelTraining", "62": "ModelTraining", "63": "ModelTraining", "64": "ModelTraining", "65": "ModelTraining", "66": "ModelTraining", "67": "ModelTraining", "68": "ModelTraining", "69": "ModelTraining", "70": "ModelTraining", "71": "ModelTraining", "72": "ModelTraining", "73": "ModelTraining", "74": "ModelTraining", "75": "ModelTraining", "76": "ModelTraining", "77": "ModelTraining", "78": "ModelTraining", "79": "ModelTraining", "80": "ModelTraining", "81": "ModelTraining", "82": "ModelTraining", "83": "ModelTraining", "84": "ModelTraining", "85": "ModelTraining", "86": "ModelTraining", "87": "ModelTraining", "88": "ModelTraining", "89": "ModelTraining", "90": "ModelTraining", "91": "ModelTraining", "92": "ModelTraining", "93": "ModelTraining", "94": "ModelTraining", "95": "ModelTraining", "96": "ModelTraining", "97": "ModelTraining", "98": "ModelTraining", "99": "ModelTraining", "100": "ModelTraining", "101": "ModelTraining", "102": "ModelTraining", "103": "ModelTraining", "104": "ModelTraining", "105": "ModelTraining", "106": "ModelTraining", "107": "ModelTraining", "108": "ModelTraining", "109": "ModelTraining", "110": "ModelTraining", "111": "ModelTraining", "112": "ModelTraining", "113": "ModelTraining", "114": "ModelTraining", "115": "ModelTraining", "116": "ModelTraining", "117": "ModelTraining", "118": "ModelTraining", "119": "ModelTraining", "120": "ModelTraining", "121": "ModelTraining", "122": "ModelTraining", "123": "ModelTraining", "124": "ModelTraining", "125": "ModelTraining", "126": "ModelTraining", "127": "ModelTraining", "128": "ModelTraining", "129": "ModelTraining", "130": "ModelTraining", "131": "ModelTraining", "132": "ModelTraining", "133": "ModelTraining", "134": "ModelTraining", "135": "ModelTraining", "136": "ModelTraining", "137": "ModelTraining", "138": "ModelTraining", "139": "ModelTraining", "140": "ModelTraining", "141": "ModelTraining", "142": "ModelTraining", "143": "ModelTraining", "144": "ModelTraining", "145": "ModelTraining", "146": "ModelTraining", "147": "ModelTraining", "148": "ModelTraining", "149": "ModelTraining", "150": "ModelTraining", "151": "ModelTraining", "152": "ModelTraining", "153": "ModelTraining", "154": "ModelTraining", "155": "ModelTraining", "156": "ModelTraining", "157": "ModelTraining", "158": "ModelTraining", "159": "ModelTraining", "160": "ModelTraining", "161": "ModelTraining", "162": "ModelTraining", "163": "ModelTraining", "164": "ModelTraining", "165": "ModelTraining", "166": "ModelTraining", "167": "ModelTraining", "168": "ModelTraining", "169": "ModelTraining", "170": "ModelTraining", "171": "ModelTraining", "172": "ModelTraining", "173": "ModelTraining", "174": "ModelTraining", "175": "ModelTraining", "176": "ModelTraining", "177": "ModelTraining", "178": "ModelTraining", "179": "ModelTraining", "180": "ModelTraining", "181": "ModelTraining", "182": "ModelTraining", "183": "ModelTraining", "184": "ModelTraining", "185": "ModelTraining", "186": "ModelTraining", "187": "ModelTraining", "188": "ModelTraining", "189": "ModelTraining", "190": "ModelTraining", "191": "ModelTraining", "192": "ModelTraining", "193": "ModelTraining", "194": "ModelTraining", "195": "ModelTraining", "196": "ModelTraining", "197": "ModelTraining", "198": "ModelTraining", "199": "ModelTraining", "200": "ModelTraining", "201": "ModelTraining", "202": "ModelTraining", "203": "ModelTraining", "204": "ModelTraining", "205": "ModelTraining", "206": "ModelTraining", "207": "ModelTraining", "208": "ModelTraining", "209": "ModelTraining", "210": "ModelTraining", "211": "ModelTraining", "212": "ModelTraining", "213": "ModelTraining", "214": "ModelTraining", "215": "ModelTraining", "216": "ModelTraining", "217": "ModelTraining", "218": "ModelTraining", "219": "ModelTraining", "220": "ModelTraining", "221": "ModelTraining", "222": "ModelTraining", "223": "ModelTraining", "224": "ModelTraining", "225": "ModelTraining", "226": "ModelTraining", "227": "ModelTraining", "228": "ModelTraining", "229": "ModelTraining", "230": "ModelTraining", "231": "ModelTraining", "232": "ModelTraining", "233": "ModelTraining", "234": "ModelTraining", "235": "ModelTraining", "236": "ModelTraining", "237": "ModelTraining", "238": "ModelTraining", "239": "ModelTraining", "240": "ModelTraining", "241": "ModelTraining", "242": "ModelTraining", "243": "ModelTraining", "244": "ModelTraining", "245": "ModelTraining", "246": "ModelTraining", "247": "ModelTraining", "248": "ModelTraining", "249": "ModelTraining", "250": "ModelTraining", "251": "ModelTraining", "252": "ModelTraining", "253": "ModelTraining", "254": "ModelTraining", "255": "ModelTraining", "256": "ModelTraining", "257": "ModelTraining", "258": "ModelTraining", "259": "ModelTraining", "260": "ModelTraining", "261": "ModelTraining", "262": "ModelTraining", "263": "ModelTraining", "264": "ModelTraining", "265": "ModelTraining", "266": "ModelTraining", "267": "ModelTraining", "268": "ModelTraining", "269": "ModelTraining", "270": "ModelTraining", "271": "ModelTraining", "272": "ModelTraining", "273": "ModelTraining", "274": "ModelTraining", "275": "ModelTraining", "276": "ModelTraining", "277": "ModelTraining", "278": "ModelTraining", "279": "ModelTraining", "280": "ModelTraining", "281": "ModelTraining", "282": "ModelTraining", "283": "ModelTraining", "284": "ModelTraining", "285": "ModelTraining", "286": "ModelTraining", "287": "ModelTraining", "288": "ModelTraining", "289": "ModelTraining", "290": "ModelTraining", "291": "ModelTraining", "292": "ModelTraining", "293": "ModelTraining", "294": "ModelTraining", "295": "ModelTraining", "296": "ModelTraining", "297": "ModelTraining", "298": "ModelTraining", "299": "ModelTraining", "300": "ModelTraining", "301": "ModelTraining", "302": "ModelTraining", "303": "ModelTraining", "304": "ModelTraining", "305": "ModelTraining", "306": "ModelTraining", "307": "ModelTraining", "308": "ModelTraining", "309": "ModelTraining", "310": "ModelTraining", "311": "ModelTraining", "312": "ModelTraining", "313": "ModelTraining", "314": "ModelTraining", "315": "ModelTraining", "316": "ModelTraining", "317": "ModelTraining", "318": "ModelTraining", "319": "ModelTraining", "320": "ModelTraining", "321": "ModelTraining", "322": "ModelTraining", "323": "ModelTraining", "324": "ModelTraining", "325": "ModelTraining", "326": "ModelTraining", "327": "ModelTraining", "328": "ModelTraining", "329": "ModelTraining", "330": "ModelTraining", "331": "ModelTraining", "332": "ModelTraining", "333": "ModelTraining", "334": "ModelTraining", "335": "ModelTraining", "336": "ModelTraining", "337": "ModelTraining", "338": "ModelTraining", "339": "ModelTraining", "340": "ModelTraining", "341": "ModelTraining", "342": "ModelTraining", "343": "ModelSelection", "344": "ModelTraining", "345": "ModelTraining", "346": "ModelTraining", "347": "ModelTraining", "348": "ModelSelection", "349": "ModelTraining", "350": "ModelTraining", "351": "ModelTraining", "352": "ModelTraining", "353": "ModelTraining", "354": "ModelTraining", "355": "ModelTraining", "356": "ModelTraining", "357": "ModelTraining", "358": "ModelTraining", "359": "ModelTraining", "360": "ModelTraining", "361": "ModelTraining", "362": "ModelTraining", "363": "ModelTraining", "364": "ModelTraining", "365": "ModelTraining", "366": "ModelTraining", "367": "ModelTraining", "368": "ModelTraining", "369": "ModelTraining", "370": "ModelTraining", "371": "ModelTraining", "372": "Workflow", "373": "Workflow", "374": "Workflow", "375": "Workflow", "376": "Workflow", "377": "Workflow"}, "message": {"0": "Project: regression_test_2022-12-21T01.46.37", "1": "5-fold cross-validation will be used.", "2": "Setting stopping tolerance adaptively based on the training frame: 0.01141311595663168", "3": "Build control seed: -1 (random)", "4": "training frame: Frame key: AutoML_8_20221220_224639_training_py_2_sid_9a3a    cols: 5    rows: 7677  chunks: 48    size: 96930  checksum: -3766642357793056343", "5": "validation frame: NULL", "6": "leaderboard frame: Frame key: py_3_sid_9a3a    cols: 5    rows: 1891  chunks: 48    size: 39070  checksum: -1542097770078110000", "7": "blending frame: NULL", "8": "response column: HourlyEnergyOutputMW", "9": "fold column: null", "10": "weights column: null", "11": "Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]", "12": "Defined work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]", "13": "Actual work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]", "14": "AutoML job created: 2022.12.20 22:46:39.178", "15": "AutoML build started: 2022.12.20 22:46:39.182", "16": "Time assigned for XGBoost_1_AutoML_8_20221220_224639: 1028.570625s", "17": "AutoML: starting XGBoost_1_AutoML_8_20221220_224639 model training", "18": "XGBoost_1_AutoML_8_20221220_224639 [XGBoost def_2] started", "19": "XGBoost_1_AutoML_8_20221220_224639 [XGBoost def_2] complete", "20": "Adding model XGBoost_1_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=10s, total=33s", "21": "New leader: XGBoost_1_AutoML_8_20221220_224639, rmse: 3.4959831552773677", "22": "Time assigned for GLM_1_AutoML_8_20221220_224639: 1426.790375s", "23": "AutoML: starting GLM_1_AutoML_8_20221220_224639 model training", "24": "GLM_1_AutoML_8_20221220_224639 [GLM def_1] started", "25": "GLM_1_AutoML_8_20221220_224639 [GLM def_1] complete", "26": "Adding model GLM_1_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=0s, total=1s", "27": "Time assigned for GBM_1_AutoML_8_20221220_224639: 2377.206s", "28": "AutoML: starting GBM_1_AutoML_8_20221220_224639 model training", "29": "GBM_1_AutoML_8_20221220_224639 [GBM def_5] started", "30": "GBM_1_AutoML_8_20221220_224639 [GBM def_5] complete", "31": "Adding model GBM_1_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=15s", "32": "Time assigned for StackedEnsemble_BestOfFamily_1_AutoML_8_20221220_224639: 3550.812s", "33": "AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_8_20221220_224639 model training", "34": "StackedEnsemble_BestOfFamily_1_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_1 (built with AUTO metalearner, using top model from each algorithm type)] started", "35": "StackedEnsemble_BestOfFamily_1_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_1 (built with AUTO metalearner, using top model from each algorithm type)] complete", "36": "Adding model StackedEnsemble_BestOfFamily_1_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=0s, total=0s", "37": "Time assigned for XGBoost_2_AutoML_8_20221220_224639: 546.204s", "38": "AutoML: starting XGBoost_2_AutoML_8_20221220_224639 model training", "39": "XGBoost_2_AutoML_8_20221220_224639 [XGBoost def_1] started", "40": "XGBoost_2_AutoML_8_20221220_224639 [XGBoost def_1] complete", "41": "Adding model XGBoost_2_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=9s, total=30s", "42": "Time assigned for DRF_1_AutoML_8_20221220_224639: 639.9878125s", "43": "AutoML: starting DRF_1_AutoML_8_20221220_224639 model training", "44": "DRF_1_AutoML_8_20221220_224639 [DRF def_1] started", "45": "DRF_1_AutoML_8_20221220_224639 [DRF def_1] complete", "46": "Adding model DRF_1_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=10s, total=31s", "47": "New leader: DRF_1_AutoML_8_20221220_224639, rmse: 3.4512732025520054", "48": "Time assigned for GBM_2_AutoML_8_20221220_224639: 775.239125s", "49": "AutoML: starting GBM_2_AutoML_8_20221220_224639 model training", "50": "GBM_2_AutoML_8_20221220_224639 [GBM def_2] started", "51": "GBM_2_AutoML_8_20221220_224639 [GBM def_2] complete", "52": "Adding model GBM_2_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=13s", "53": "New leader: GBM_2_AutoML_8_20221220_224639, rmse: 3.34902834633315", "54": "Time assigned for GBM_3_AutoML_8_20221220_224639: 993.11975s", "55": "AutoML: starting GBM_3_AutoML_8_20221220_224639 model training", "56": "GBM_3_AutoML_8_20221220_224639 [GBM def_3] started", "57": "GBM_3_AutoML_8_20221220_224639 [GBM def_3] complete", "58": "Adding model GBM_3_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=13s", "59": "New leader: GBM_3_AutoML_8_20221220_224639, rmse: 3.320138329408794", "60": "Time assigned for GBM_4_AutoML_8_20221220_224639: 1384.96725s", "61": "AutoML: starting GBM_4_AutoML_8_20221220_224639 model training", "62": "GBM_4_AutoML_8_20221220_224639 [GBM def_4] started", "63": "GBM_4_AutoML_8_20221220_224639 [GBM def_4] complete", "64": "Adding model GBM_4_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=14s", "65": "New leader: GBM_4_AutoML_8_20221220_224639, rmse: 3.2762492225987234", "66": "Time assigned for StackedEnsemble_BestOfFamily_2_AutoML_8_20221220_224639: 1149.474375s", "67": "AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_8_20221220_224639 model training", "68": "StackedEnsemble_BestOfFamily_2_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_2 (built with AUTO metalearner, using top model from each algorithm type)] started", "69": "StackedEnsemble_BestOfFamily_2_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_2 (built with AUTO metalearner, using top model from each algorithm type)] complete", "70": "Adding model StackedEnsemble_BestOfFamily_2_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=0s, total=0s", "71": "Time assigned for StackedEnsemble_AllModels_1_AutoML_8_20221220_224639: 3447.906s", "72": "AutoML: starting StackedEnsemble_AllModels_1_AutoML_8_20221220_224639 model training", "73": "StackedEnsemble_AllModels_1_AutoML_8_20221220_224639 [StackedEnsemble all_2 (built with AUTO metalearner, using all AutoML models)] started", "74": "StackedEnsemble_AllModels_1_AutoML_8_20221220_224639 [StackedEnsemble all_2 (built with AUTO metalearner, using all AutoML models)] complete", "75": "Adding model StackedEnsemble_AllModels_1_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=1s, total=1s", "76": "Time assigned for XGBoost_3_AutoML_8_20221220_224639: 626.7769375s", "77": "AutoML: starting XGBoost_3_AutoML_8_20221220_224639 model training", "78": "XGBoost_3_AutoML_8_20221220_224639 [XGBoost def_3] started", "79": "XGBoost_3_AutoML_8_20221220_224639 [XGBoost def_3] complete", "80": "Adding model XGBoost_3_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=18s, total=60s", "81": "Time assigned for XRT_1_AutoML_8_20221220_224639: 752.661125s", "82": "AutoML: starting XRT_1_AutoML_8_20221220_224639 model training", "83": "XRT_1_AutoML_8_20221220_224639 [DRF XRT (Extremely Randomized Trees)] started", "84": "XRT_1_AutoML_8_20221220_224639 [DRF XRT (Extremely Randomized Trees)] complete", "85": "Adding model XRT_1_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=9s, total=29s", "86": "Time assigned for GBM_5_AutoML_8_20221220_224639: 959.294625s", "87": "AutoML: starting GBM_5_AutoML_8_20221220_224639 model training", "88": "GBM_5_AutoML_8_20221220_224639 [GBM def_1] started", "89": "GBM_5_AutoML_8_20221220_224639 [GBM def_1] complete", "90": "Adding model GBM_5_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=17s", "91": "Time assigned for DeepLearning_1_AutoML_8_20221220_224639: 1336.26925s", "92": "AutoML: starting DeepLearning_1_AutoML_8_20221220_224639 model training", "93": "DeepLearning_1_AutoML_8_20221220_224639 [DeepLearning def_1] started", "94": "DeepLearning_1_AutoML_8_20221220_224639 [DeepLearning def_1] complete", "95": "Adding model DeepLearning_1_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=0s, total=1s", "96": "Time assigned for StackedEnsemble_BestOfFamily_3_AutoML_8_20221220_224639: 1113.142375s", "97": "AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_8_20221220_224639 model training", "98": "StackedEnsemble_BestOfFamily_3_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_3 (built with AUTO metalearner, using top model from each algorithm type)] started", "99": "StackedEnsemble_BestOfFamily_3_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_3 (built with AUTO metalearner, using top model from each algorithm type)] complete", "100": "Adding model StackedEnsemble_BestOfFamily_3_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=0s, total=0s", "101": "Time assigned for StackedEnsemble_AllModels_2_AutoML_8_20221220_224639: 3338.895s", "102": "AutoML: starting StackedEnsemble_AllModels_2_AutoML_8_20221220_224639 model training", "103": "StackedEnsemble_AllModels_2_AutoML_8_20221220_224639 [StackedEnsemble all_3 (built with AUTO metalearner, using all AutoML models)] started", "104": "StackedEnsemble_AllModels_2_AutoML_8_20221220_224639 [StackedEnsemble all_3 (built with AUTO metalearner, using all AutoML models)] complete", "105": "Adding model StackedEnsemble_AllModels_2_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=1s, total=1s", "106": "Time assigned for XGBoost_grid_1_AutoML_8_20221220_224639: 1540.686875s", "107": "AutoML: starting XGBoost_grid_1_AutoML_8_20221220_224639 hyperparameter search", "108": "XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search] started", "109": "Built: 1 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "110": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_1 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=8s, total=24s", "111": "Built: 2 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "112": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_2 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=9s, total=30s", "113": "Built: 3 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "114": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_3 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=23s, total=78s", "115": "Built: 4 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "116": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_4 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=9s, total=32s", "117": "Built: 5 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "118": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_5 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=22s, total=69s", "119": "Built: 6 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "120": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_6 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=23s, total=72s", "121": "Built: 7 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "122": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_7 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=13s, total=47s", "123": "Built: 8 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "124": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_8 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=8s, total=26s", "125": "Built: 9 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "126": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_9 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=26s, total=86s", "127": "Built: 10 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "128": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_10 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=8s, total=27s", "129": "Built: 11 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "130": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_11 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=7s, total=24s", "131": "Built: 12 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "132": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_12 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=25s, total=78s", "133": "Built: 13 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "134": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_13 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=8s, total=28s", "135": "Built: 14 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "136": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_14 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=21s, total=71s", "137": "Built: 15 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "138": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_15 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=19s, total=60s", "139": "Built: 16 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "140": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_16 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=13s, total=40s", "141": "Built: 17 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "142": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_17 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=29s, total=98s", "143": "Built: 18 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "144": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_18 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=26s, total=77s", "145": "Built: 19 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "146": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_19 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=8s, total=27s", "147": "Built: 20 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "148": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_20 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=15s, total=49s", "149": "Built: 21 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "150": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_21 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=13s, total=44s", "151": "Built: 22 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "152": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_22 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=21s, total=74s", "153": "Built: 23 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "154": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_23 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=10s, total=31s", "155": "Built: 24 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "156": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_24 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=18s, total=61s", "157": "Built: 25 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "158": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_25 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=15s, total=51s", "159": "Built: 26 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "160": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_26 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=21s, total=65s", "161": "Built: 27 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "162": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_27 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=13s, total=42s", "163": "Built: 28 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "164": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_28 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=21s, total=72s", "165": "Built: 29 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "166": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_29 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=16s, total=53s", "167": "XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search] complete", "168": "Built: 30 models for HyperparamSearch : XGBoost_grid_1_AutoML_8_20221220_224639 [XGBoost Grid Search]", "169": "Adding model XGBoost_grid_1_AutoML_8_20221220_224639_model_30 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=2s, total=6s", "170": "Time assigned for GBM_grid_1_AutoML_8_20221220_224639: 1027.0331875s", "171": "AutoML: starting GBM_grid_1_AutoML_8_20221220_224639 hyperparameter search", "172": "GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search] started", "173": "Built: 1 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "174": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_1 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=2s, total=7s", "175": "Built: 2 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "176": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_2 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=11s", "177": "Built: 3 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "178": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_3 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=10s, total=31s", "179": "Built: 4 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "180": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_4 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=14s", "181": "Built: 5 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "182": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_5 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=18s", "183": "Built: 6 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "184": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_6 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=16s", "185": "Built: 7 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "186": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_7 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=13s", "187": "Built: 8 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "188": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_8 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=20s", "189": "Built: 9 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "190": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_9 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=16s", "191": "Built: 10 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "192": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_10 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=13s", "193": "Built: 11 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "194": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_11 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=7s, total=26s", "195": "Built: 12 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "196": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_12 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=12s", "197": "Built: 13 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "198": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_13 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=12s", "199": "Built: 14 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "200": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_14 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=20s", "201": "Built: 15 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "202": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_15 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=14s", "203": "Built: 16 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "204": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_16 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=22s", "205": "New leader: GBM_grid_1_AutoML_8_20221220_224639_model_16, rmse: 3.275107009813093", "206": "Built: 17 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "207": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_17 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=9s, total=31s", "208": "Built: 18 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "209": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_18 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=10s, total=32s", "210": "Built: 19 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "211": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_19 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=15s", "212": "Built: 20 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "213": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_20 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=21s", "214": "Built: 21 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "215": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_21 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=17s", "216": "Built: 22 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "217": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_22 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=21s", "218": "Built: 23 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "219": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_23 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=13s", "220": "Built: 24 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "221": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_24 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=19s", "222": "Built: 25 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "223": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_25 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=15s", "224": "Built: 26 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "225": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_26 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=2s, total=8s", "226": "Built: 27 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "227": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_27 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=13s", "228": "Built: 28 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "229": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_28 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=10s", "230": "Built: 29 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "231": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_29 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=19s", "232": "Built: 30 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "233": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_30 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=15s", "234": "Built: 31 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "235": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_31 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=9s, total=31s", "236": "Built: 32 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "237": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_32 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=2s, total=8s", "238": "Built: 33 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "239": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_33 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=12s", "240": "Built: 34 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "241": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_34 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=12s", "242": "Built: 35 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "243": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_35 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=19s", "244": "Built: 36 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "245": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_36 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=15s", "246": "Built: 37 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "247": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_37 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=17s", "248": "Built: 38 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "249": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_38 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=7s, total=22s", "250": "Built: 39 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "251": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_39 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=16s", "252": "Built: 40 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "253": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_40 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=17s", "254": "Built: 41 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "255": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_41 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=7s, total=26s", "256": "Built: 42 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "257": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_42 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=10s", "258": "Built: 43 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "259": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_43 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=11s", "260": "Built: 44 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "261": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_44 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=8s, total=27s", "262": "Built: 45 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "263": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_45 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=9s", "264": "Built: 46 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "265": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_46 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=22s", "266": "Built: 47 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "267": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_47 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=20s", "268": "New leader: GBM_grid_1_AutoML_8_20221220_224639_model_47, rmse: 3.2446535575222497", "269": "Built: 48 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "270": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_48 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=13s", "271": "Built: 49 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "272": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_49 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=13s", "273": "Built: 50 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "274": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_50 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=11s, total=37s", "275": "Built: 51 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "276": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_51 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=15s", "277": "Built: 52 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "278": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_52 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=22s", "279": "Built: 53 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "280": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_53 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=16s", "281": "Built: 54 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "282": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_54 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=15s", "283": "Built: 55 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "284": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_55 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=11s", "285": "Built: 56 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "286": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_56 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=20s", "287": "Built: 57 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "288": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_57 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=21s", "289": "Built: 58 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "290": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_58 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=3s, total=13s", "291": "Built: 59 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "292": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_59 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=5s, total=19s", "293": "GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search] complete", "294": "Built: 60 models for HyperparamSearch : GBM_grid_1_AutoML_8_20221220_224639 [GBM Grid Search]", "295": "Adding model GBM_grid_1_AutoML_8_20221220_224639_model_60 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=0s, total=2s", "296": "Time assigned for DeepLearning_grid_1_AutoML_8_20221220_224639: 513.25134375s", "297": "AutoML: starting DeepLearning_grid_1_AutoML_8_20221220_224639 hyperparameter search", "298": "DeepLearning_grid_1_AutoML_8_20221220_224639 [DeepLearning Grid Search] started", "299": "Built: 1 models for HyperparamSearch : DeepLearning_grid_1_AutoML_8_20221220_224639 [DeepLearning Grid Search]", "300": "Adding model DeepLearning_grid_1_AutoML_8_20221220_224639_model_1 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=40s, total=184s", "301": "Built: 2 models for HyperparamSearch : DeepLearning_grid_1_AutoML_8_20221220_224639 [DeepLearning Grid Search]", "302": "Adding model DeepLearning_grid_1_AutoML_8_20221220_224639_model_2 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=34s, total=155s", "303": "Built: 3 models for HyperparamSearch : DeepLearning_grid_1_AutoML_8_20221220_224639 [DeepLearning Grid Search]", "304": "Adding model DeepLearning_grid_1_AutoML_8_20221220_224639_model_3 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=43s, total=142s", "305": "DeepLearning_grid_1_AutoML_8_20221220_224639 [DeepLearning Grid Search] complete", "306": "Built: 4 models for HyperparamSearch : DeepLearning_grid_1_AutoML_8_20221220_224639 [DeepLearning Grid Search]", "307": "Adding model DeepLearning_grid_1_AutoML_8_20221220_224639_model_4 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=34s", "308": "Time assigned for StackedEnsemble_BestOfFamily_4_AutoML_8_20221220_224639: 85.0093359375s", "309": "AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_8_20221220_224639 model training", "310": "StackedEnsemble_BestOfFamily_4_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)] started", "311": "StackedEnsemble_BestOfFamily_4_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)] complete", "312": "Adding model StackedEnsemble_BestOfFamily_4_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=0s, total=0s", "313": "Time assigned for StackedEnsemble_AllModels_3_AutoML_8_20221220_224639: 254.381s", "314": "AutoML: starting StackedEnsemble_AllModels_3_AutoML_8_20221220_224639 model training", "315": "StackedEnsemble_AllModels_3_AutoML_8_20221220_224639 [StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)] started", "316": "StackedEnsemble_AllModels_3_AutoML_8_20221220_224639 [StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)] complete", "317": "Adding model StackedEnsemble_AllModels_3_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=2s, total=2s", "318": "Time assigned for DeepLearning_grid_2_AutoML_8_20221220_224639: 100.561203125s", "319": "AutoML: starting DeepLearning_grid_2_AutoML_8_20221220_224639 hyperparameter search", "320": "DeepLearning_grid_2_AutoML_8_20221220_224639 [DeepLearning Grid Search] started", "321": "Built: 1 models for HyperparamSearch : DeepLearning_grid_2_AutoML_8_20221220_224639 [DeepLearning Grid Search]", "322": "Adding model DeepLearning_grid_2_AutoML_8_20221220_224639_model_1 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=17s, total=81s", "323": "DeepLearning_grid_2_AutoML_8_20221220_224639 [DeepLearning Grid Search] complete", "324": "Built: 2 models for HyperparamSearch : DeepLearning_grid_2_AutoML_8_20221220_224639 [DeepLearning Grid Search]", "325": "Adding model DeepLearning_grid_2_AutoML_8_20221220_224639_model_2 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=4s, total=20s", "326": "Time assigned for DeepLearning_grid_3_AutoML_8_20221220_224639: 100.196s", "327": "AutoML: starting DeepLearning_grid_3_AutoML_8_20221220_224639 hyperparameter search", "328": "DeepLearning_grid_3_AutoML_8_20221220_224639 [DeepLearning Grid Search] started", "329": "Built: 1 models for HyperparamSearch : DeepLearning_grid_3_AutoML_8_20221220_224639 [DeepLearning Grid Search]", "330": "Adding model DeepLearning_grid_3_AutoML_8_20221220_224639_model_1 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=19s, total=88s", "331": "Built: 2 models for HyperparamSearch : DeepLearning_grid_3_AutoML_8_20221220_224639 [DeepLearning Grid Search]", "332": "Adding model DeepLearning_grid_3_AutoML_8_20221220_224639_model_2 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=1s, total=11s", "333": "DeepLearning_grid_3_AutoML_8_20221220_224639 [DeepLearning Grid Search] complete", "334": "Built: 3 models for HyperparamSearch : DeepLearning_grid_3_AutoML_8_20221220_224639 [DeepLearning Grid Search]", "335": "Adding model DeepLearning_grid_3_AutoML_8_20221220_224639_model_3 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=0s, total=4s", "336": "Time assigned for StackedEnsemble_AllModels_4_AutoML_8_20221220_224639: 47.474s", "337": "AutoML: starting StackedEnsemble_AllModels_4_AutoML_8_20221220_224639 model training", "338": "StackedEnsemble_AllModels_4_AutoML_8_20221220_224639 [StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)] started", "339": "StackedEnsemble_AllModels_4_AutoML_8_20221220_224639 [StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)] complete", "340": "Adding model StackedEnsemble_AllModels_4_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=2s, total=2s", "341": "Time assigned for XGBoost_lr_search_selection_AutoML_8_20221220_224639: 7.9267060546875s", "342": "XGBoost_lr_search_selection_AutoML_8_20221220_224639 [XGBoost lr_search] started", "343": "Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_8_20221220_224639_model_9", "344": "AutoML: starting XGBoost_lr_search_selection_AutoML_8_20221220_224639_select model training", "345": "XGBoost_lr_search_selection_AutoML_8_20221220_224639 [XGBoost lr_search] complete", "346": "Time assigned for GBM_lr_annealing_selection_AutoML_8_20221220_224639: 2.698071533203125s", "347": "GBM_lr_annealing_selection_AutoML_8_20221220_224639 [GBM lr_annealing] started", "348": "Retraining best GBM with learning rate annealing: GBM_grid_1_AutoML_8_20221220_224639_model_47", "349": "AutoML: starting GBM_lr_annealing_selection_AutoML_8_20221220_224639_select_model model training", "350": "GBM_lr_annealing_selection_AutoML_8_20221220_224639 [GBM lr_annealing] complete", "351": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.", "352": "Time assigned for StackedEnsemble_BestOfFamily_5_AutoML_8_20221220_224639: 33.648s", "353": "AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_8_20221220_224639 model training", "354": "StackedEnsemble_BestOfFamily_5_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)] started", "355": "StackedEnsemble_BestOfFamily_5_AutoML_8_20221220_224639 [StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)] complete", "356": "Adding model StackedEnsemble_BestOfFamily_5_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=6s, total=6s", "357": "New leader: StackedEnsemble_BestOfFamily_5_AutoML_8_20221220_224639, rmse: 3.181906884080173", "358": "Time assigned for StackedEnsemble_AllModels_5_AutoML_8_20221220_224639: 27.158s", "359": "AutoML: starting StackedEnsemble_AllModels_5_AutoML_8_20221220_224639 model training", "360": "StackedEnsemble_AllModels_5_AutoML_8_20221220_224639 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)] started", "361": "AutoML: out of time; skipping StackedEnsemble_AllModels_5_AutoML_8_20221220_224639 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)]", "362": "AutoML: out of time; skipping StackedEnsemble_AllModels_5_AutoML_8_20221220_224639 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)]", "363": "AutoML: out of time; skipping StackedEnsemble_AllModels_5_AutoML_8_20221220_224639 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)]", "364": "StackedEnsemble_AllModels_5_AutoML_8_20221220_224639 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)] complete", "365": "Adding model StackedEnsemble_AllModels_5_AutoML_8_20221220_224639 to leaderboard Leaderboard_regression_test_2022-12-21T01.46.37@@HourlyEnergyOutputMW. Training time: model=31s, total=31s", "366": "New leader: StackedEnsemble_AllModels_5_AutoML_8_20221220_224639, rmse: 3.173814102887965", "367": "AutoML: out of time; skipping StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)", "368": "AutoML: out of time; skipping StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)", "369": "AutoML: out of time; skipping completion resume_best_grids", "370": "AutoML: out of time; skipping StackedEnsemble best_of_family (built with AUTO metalearner, using top model from each algorithm type)", "371": "AutoML: out of time; skipping StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)", "372": "Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {StackedEnsemble : [best_of_family_gbm (6g, 10w), all_gbm (7g, 10w)]}]", "373": "AutoML build stopped: 2022.12.20 23:46:44.349", "374": "AutoML build done: built 111 models", "375": "AutoML duration:  1:00:05.167", "376": "Verifying training frame immutability. . .", "377": "Training frame was not mutated (as expected)."}, "name": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": "creation_epoch", "15": "start_epoch", "16": NaN, "17": "start_XGBoost_def_2", "18": NaN, "19": NaN, "20": NaN, "21": NaN, "22": NaN, "23": "start_GLM_def_1", "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": "start_GBM_def_5", "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": "start_StackedEnsemble_best_of_family_1", "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": "start_XGBoost_def_1", "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": "start_DRF_def_1", "44": NaN, "45": NaN, "46": NaN, "47": NaN, "48": NaN, "49": "start_GBM_def_2", "50": NaN, "51": NaN, "52": NaN, "53": NaN, "54": NaN, "55": "start_GBM_def_3", "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": NaN, "61": "start_GBM_def_4", "62": NaN, "63": NaN, "64": NaN, "65": NaN, "66": NaN, "67": "start_StackedEnsemble_best_of_family_2", "68": NaN, "69": NaN, "70": NaN, "71": NaN, "72": "start_StackedEnsemble_all_2", "73": NaN, "74": NaN, "75": NaN, "76": NaN, "77": "start_XGBoost_def_3", "78": NaN, "79": NaN, "80": NaN, "81": NaN, "82": "start_DRF_XRT", "83": NaN, "84": NaN, "85": NaN, "86": NaN, "87": "start_GBM_def_1", "88": NaN, "89": NaN, "90": NaN, "91": NaN, "92": "start_DeepLearning_def_1", "93": NaN, "94": NaN, "95": NaN, "96": NaN, "97": "start_StackedEnsemble_best_of_family_3", "98": NaN, "99": NaN, "100": NaN, "101": NaN, "102": "start_StackedEnsemble_all_3", "103": NaN, "104": NaN, "105": NaN, "106": NaN, "107": "start_XGBoost_grid_1", "108": NaN, "109": NaN, "110": NaN, "111": NaN, "112": NaN, "113": NaN, "114": NaN, "115": NaN, "116": NaN, "117": NaN, "118": NaN, "119": NaN, "120": NaN, "121": NaN, "122": NaN, "123": NaN, "124": NaN, "125": NaN, "126": NaN, "127": NaN, "128": NaN, "129": NaN, "130": NaN, "131": NaN, "132": NaN, "133": NaN, "134": NaN, "135": NaN, "136": NaN, "137": NaN, "138": NaN, "139": NaN, "140": NaN, "141": NaN, "142": NaN, "143": NaN, "144": NaN, "145": NaN, "146": NaN, "147": NaN, "148": NaN, "149": NaN, "150": NaN, "151": NaN, "152": NaN, "153": NaN, "154": NaN, "155": NaN, "156": NaN, "157": NaN, "158": NaN, "159": NaN, "160": NaN, "161": NaN, "162": NaN, "163": NaN, "164": NaN, "165": NaN, "166": NaN, "167": NaN, "168": NaN, "169": NaN, "170": NaN, "171": "start_GBM_grid_1", "172": NaN, "173": NaN, "174": NaN, "175": NaN, "176": NaN, "177": NaN, "178": NaN, "179": NaN, "180": NaN, "181": NaN, "182": NaN, "183": NaN, "184": NaN, "185": NaN, "186": NaN, "187": NaN, "188": NaN, "189": NaN, "190": NaN, "191": NaN, "192": NaN, "193": NaN, "194": NaN, "195": NaN, "196": NaN, "197": NaN, "198": NaN, "199": NaN, "200": NaN, "201": NaN, "202": NaN, "203": NaN, "204": NaN, "205": NaN, "206": NaN, "207": NaN, "208": NaN, "209": NaN, "210": NaN, "211": NaN, "212": NaN, "213": NaN, "214": NaN, "215": NaN, "216": NaN, "217": NaN, "218": NaN, "219": NaN, "220": NaN, "221": NaN, "222": NaN, "223": NaN, "224": NaN, "225": NaN, "226": NaN, "227": NaN, "228": NaN, "229": NaN, "230": NaN, "231": NaN, "232": NaN, "233": NaN, "234": NaN, "235": NaN, "236": NaN, "237": NaN, "238": NaN, "239": NaN, "240": NaN, "241": NaN, "242": NaN, "243": NaN, "244": NaN, "245": NaN, "246": NaN, "247": NaN, "248": NaN, "249": NaN, "250": NaN, "251": NaN, "252": NaN, "253": NaN, "254": NaN, "255": NaN, "256": NaN, "257": NaN, "258": NaN, "259": NaN, "260": NaN, "261": NaN, "262": NaN, "263": NaN, "264": NaN, "265": NaN, "266": NaN, "267": NaN, "268": NaN, "269": NaN, "270": NaN, "271": NaN, "272": NaN, "273": NaN, "274": NaN, "275": NaN, "276": NaN, "277": NaN, "278": NaN, "279": NaN, "280": NaN, "281": NaN, "282": NaN, "283": NaN, "284": NaN, "285": NaN, "286": NaN, "287": NaN, "288": NaN, "289": NaN, "290": NaN, "291": NaN, "292": NaN, "293": NaN, "294": NaN, "295": NaN, "296": NaN, "297": "start_DeepLearning_grid_1", "298": NaN, "299": NaN, "300": NaN, "301": NaN, "302": NaN, "303": NaN, "304": NaN, "305": NaN, "306": NaN, "307": NaN, "308": NaN, "309": "start_StackedEnsemble_best_of_family_4", "310": NaN, "311": NaN, "312": NaN, "313": NaN, "314": "start_StackedEnsemble_all_4", "315": NaN, "316": NaN, "317": NaN, "318": NaN, "319": "start_DeepLearning_grid_2", "320": NaN, "321": NaN, "322": NaN, "323": NaN, "324": NaN, "325": NaN, "326": NaN, "327": "start_DeepLearning_grid_3", "328": NaN, "329": NaN, "330": NaN, "331": NaN, "332": NaN, "333": NaN, "334": NaN, "335": NaN, "336": NaN, "337": "start_StackedEnsemble_all_5", "338": NaN, "339": NaN, "340": NaN, "341": NaN, "342": NaN, "343": NaN, "344": "start_XGBoost_lr_search", "345": NaN, "346": NaN, "347": NaN, "348": NaN, "349": "start_GBM_lr_annealing", "350": NaN, "351": NaN, "352": NaN, "353": "start_StackedEnsemble_best_of_family_gbm", "354": NaN, "355": NaN, "356": NaN, "357": NaN, "358": NaN, "359": "start_StackedEnsemble_all_gbm", "360": NaN, "361": NaN, "362": NaN, "363": NaN, "364": NaN, "365": NaN, "366": NaN, "367": NaN, "368": NaN, "369": NaN, "370": NaN, "371": NaN, "372": NaN, "373": "stop_epoch", "374": NaN, "375": "duration_secs", "376": NaN, "377": NaN}, "value": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": 1671576399.0, "15": 1671576399.0, "16": NaN, "17": 1671576399.0, "18": NaN, "19": NaN, "20": NaN, "21": NaN, "22": NaN, "23": 1671576432.0, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": 1671576433.0, "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": 1671576448.0, "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": 1671576449.0, "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": 1671576479.0, "44": NaN, "45": NaN, "46": NaN, "47": NaN, "48": NaN, "49": 1671576511.0, "50": NaN, "51": NaN, "52": NaN, "53": NaN, "54": NaN, "55": 1671576523.0, "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": NaN, "61": 1671576537.0, "62": NaN, "63": NaN, "64": NaN, "65": NaN, "66": NaN, "67": 1671576551.0, "68": NaN, "69": NaN, "70": NaN, "71": NaN, "72": 1671576551.0, "73": NaN, "74": NaN, "75": NaN, "76": NaN, "77": 1671576552.0, "78": NaN, "79": NaN, "80": NaN, "81": NaN, "82": 1671576612.0, "83": NaN, "84": NaN, "85": NaN, "86": NaN, "87": 1671576642.0, "88": NaN, "89": NaN, "90": NaN, "91": NaN, "92": 1671576659.0, "93": NaN, "94": NaN, "95": NaN, "96": NaN, "97": 1671576660.0, "98": NaN, "99": NaN, "100": NaN, "101": NaN, "102": 1671576660.0, "103": NaN, "104": NaN, "105": NaN, "106": NaN, "107": 1671576661.0, "108": NaN, "109": NaN, "110": NaN, "111": NaN, "112": NaN, "113": NaN, "114": NaN, "115": NaN, "116": NaN, "117": NaN, "118": NaN, "119": NaN, "120": NaN, "121": NaN, "122": NaN, "123": NaN, "124": NaN, "125": NaN, "126": NaN, "127": NaN, "128": NaN, "129": NaN, "130": NaN, "131": NaN, "132": NaN, "133": NaN, "134": NaN, "135": NaN, "136": NaN, "137": NaN, "138": NaN, "139": NaN, "140": NaN, "141": NaN, "142": NaN, "143": NaN, "144": NaN, "145": NaN, "146": NaN, "147": NaN, "148": NaN, "149": NaN, "150": NaN, "151": NaN, "152": NaN, "153": NaN, "154": NaN, "155": NaN, "156": NaN, "157": NaN, "158": NaN, "159": NaN, "160": NaN, "161": NaN, "162": NaN, "163": NaN, "164": NaN, "165": NaN, "166": NaN, "167": NaN, "168": NaN, "169": NaN, "170": NaN, "171": 1671578202.0, "172": NaN, "173": NaN, "174": NaN, "175": NaN, "176": NaN, "177": NaN, "178": NaN, "179": NaN, "180": NaN, "181": NaN, "182": NaN, "183": NaN, "184": NaN, "185": NaN, "186": NaN, "187": NaN, "188": NaN, "189": NaN, "190": NaN, "191": NaN, "192": NaN, "193": NaN, "194": NaN, "195": NaN, "196": NaN, "197": NaN, "198": NaN, "199": NaN, "200": NaN, "201": NaN, "202": NaN, "203": NaN, "204": NaN, "205": NaN, "206": NaN, "207": NaN, "208": NaN, "209": NaN, "210": NaN, "211": NaN, "212": NaN, "213": NaN, "214": NaN, "215": NaN, "216": NaN, "217": NaN, "218": NaN, "219": NaN, "220": NaN, "221": NaN, "222": NaN, "223": NaN, "224": NaN, "225": NaN, "226": NaN, "227": NaN, "228": NaN, "229": NaN, "230": NaN, "231": NaN, "232": NaN, "233": NaN, "234": NaN, "235": NaN, "236": NaN, "237": NaN, "238": NaN, "239": NaN, "240": NaN, "241": NaN, "242": NaN, "243": NaN, "244": NaN, "245": NaN, "246": NaN, "247": NaN, "248": NaN, "249": NaN, "250": NaN, "251": NaN, "252": NaN, "253": NaN, "254": NaN, "255": NaN, "256": NaN, "257": NaN, "258": NaN, "259": NaN, "260": NaN, "261": NaN, "262": NaN, "263": NaN, "264": NaN, "265": NaN, "266": NaN, "267": NaN, "268": NaN, "269": NaN, "270": NaN, "271": NaN, "272": NaN, "273": NaN, "274": NaN, "275": NaN, "276": NaN, "277": NaN, "278": NaN, "279": NaN, "280": NaN, "281": NaN, "282": NaN, "283": NaN, "284": NaN, "285": NaN, "286": NaN, "287": NaN, "288": NaN, "289": NaN, "290": NaN, "291": NaN, "292": NaN, "293": NaN, "294": NaN, "295": NaN, "296": NaN, "297": 1671579229.0, "298": NaN, "299": NaN, "300": NaN, "301": NaN, "302": NaN, "303": NaN, "304": NaN, "305": NaN, "306": NaN, "307": NaN, "308": NaN, "309": 1671579744.0, "310": NaN, "311": NaN, "312": NaN, "313": NaN, "314": 1671579745.0, "315": NaN, "316": NaN, "317": NaN, "318": NaN, "319": 1671579748.0, "320": NaN, "321": NaN, "322": NaN, "323": NaN, "324": NaN, "325": NaN, "326": NaN, "327": 1671579849.0, "328": NaN, "329": NaN, "330": NaN, "331": NaN, "332": NaN, "333": NaN, "334": NaN, "335": NaN, "336": NaN, "337": 1671579952.0, "338": NaN, "339": NaN, "340": NaN, "341": NaN, "342": NaN, "343": NaN, "344": 1671579954.0, "345": NaN, "346": NaN, "347": NaN, "348": NaN, "349": 1671579961.0, "350": NaN, "351": NaN, "352": NaN, "353": 1671579966.0, "354": NaN, "355": NaN, "356": NaN, "357": NaN, "358": NaN, "359": 1671579972.0, "360": NaN, "361": NaN, "362": NaN, "363": NaN, "364": NaN, "365": NaN, "366": NaN, "367": NaN, "368": NaN, "369": NaN, "370": NaN, "371": NaN, "372": NaN, "373": 1671580004.0, "374": NaN, "375": 3605.0, "376": NaN, "377": NaN}}}]