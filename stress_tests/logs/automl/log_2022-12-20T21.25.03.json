[{"experiment": "classification_1", "max_runtime_secs": 3600, "max_models": null, "include_algos": null, "start_time": "2022-12-20 21:25:05.910963", "end_time": "2022-12-20 22:25:16.309062", "elapsed_time": "1:00:10.398099", "leaderboard": {"model_id": {"0": "StackedEnsemble_AllModels_4_AutoML_2_20221220_182507", "1": "StackedEnsemble_AllModels_3_AutoML_2_20221220_182507", "2": "StackedEnsemble_BestOfFamily_4_AutoML_2_20221220_182507", "3": "StackedEnsemble_AllModels_2_AutoML_2_20221220_182507", "4": "StackedEnsemble_BestOfFamily_3_AutoML_2_20221220_182507", "5": "StackedEnsemble_BestOfFamily_5_AutoML_2_20221220_182507", "6": "StackedEnsemble_BestOfFamily_2_AutoML_2_20221220_182507", "7": "StackedEnsemble_AllModels_1_AutoML_2_20221220_182507", "8": "XGBoost_grid_1_AutoML_2_20221220_182507_model_19", "9": "StackedEnsemble_AllModels_5_AutoML_2_20221220_182507", "10": "GBM_grid_1_AutoML_2_20221220_182507_model_8", "11": "StackedEnsemble_BestOfFamily_1_AutoML_2_20221220_182507", "12": "GBM_grid_1_AutoML_2_20221220_182507_model_19", "13": "XGBoost_grid_1_AutoML_2_20221220_182507_model_1", "14": "GBM_4_AutoML_2_20221220_182507", "15": "XGBoost_grid_1_AutoML_2_20221220_182507_model_35", "16": "XGBoost_grid_1_AutoML_2_20221220_182507_model_15", "17": "XGBoost_grid_1_AutoML_2_20221220_182507_model_34", "18": "XGBoost_grid_1_AutoML_2_20221220_182507_model_24", "19": "GBM_grid_1_AutoML_2_20221220_182507_model_14", "20": "XGBoost_3_AutoML_2_20221220_182507", "21": "GBM_grid_1_AutoML_2_20221220_182507_model_26", "22": "XGBoost_grid_1_AutoML_2_20221220_182507_model_25", "23": "XGBoost_grid_1_AutoML_2_20221220_182507_model_38", "24": "XGBoost_grid_1_AutoML_2_20221220_182507_model_4", "25": "GBM_1_AutoML_2_20221220_182507", "26": "XGBoost_grid_1_AutoML_2_20221220_182507_model_32", "27": "XGBoost_grid_1_AutoML_2_20221220_182507_model_36", "28": "XGBoost_grid_1_AutoML_2_20221220_182507_model_20", "29": "GBM_grid_1_AutoML_2_20221220_182507_model_10", "30": "XGBoost_grid_1_AutoML_2_20221220_182507_model_37", "31": "XGBoost_2_AutoML_2_20221220_182507", "32": "XGBoost_grid_1_AutoML_2_20221220_182507_model_13", "33": "GBM_grid_1_AutoML_2_20221220_182507_model_2", "34": "XGBoost_grid_1_AutoML_2_20221220_182507_model_5", "35": "XGBoost_grid_1_AutoML_2_20221220_182507_model_9", "36": "XGBoost_grid_1_AutoML_2_20221220_182507_model_17", "37": "GBM_3_AutoML_2_20221220_182507", "38": "XGBoost_grid_1_AutoML_2_20221220_182507_model_2", "39": "GBM_grid_1_AutoML_2_20221220_182507_model_20", "40": "GBM_grid_1_AutoML_2_20221220_182507_model_5", "41": "XGBoost_grid_1_AutoML_2_20221220_182507_model_28", "42": "XGBoost_grid_1_AutoML_2_20221220_182507_model_33", "43": "GBM_grid_1_AutoML_2_20221220_182507_model_1", "44": "GBM_grid_1_AutoML_2_20221220_182507_model_31", "45": "XGBoost_grid_1_AutoML_2_20221220_182507_model_11", "46": "XGBoost_grid_1_AutoML_2_20221220_182507_model_29", "47": "XGBoost_grid_1_AutoML_2_20221220_182507_model_3", "48": "XGBoost_grid_1_AutoML_2_20221220_182507_model_23", "49": "GBM_grid_1_AutoML_2_20221220_182507_model_18", "50": "XGBoost_grid_1_AutoML_2_20221220_182507_model_7", "51": "XGBoost_grid_1_AutoML_2_20221220_182507_model_21", "52": "XGBoost_grid_1_AutoML_2_20221220_182507_model_22", "53": "XGBoost_grid_1_AutoML_2_20221220_182507_model_10", "54": "XGBoost_grid_1_AutoML_2_20221220_182507_model_14", "55": "GBM_grid_1_AutoML_2_20221220_182507_model_34", "56": "GBM_grid_1_AutoML_2_20221220_182507_model_28", "57": "GBM_2_AutoML_2_20221220_182507", "58": "XGBoost_grid_1_AutoML_2_20221220_182507_model_12", "59": "XGBoost_1_AutoML_2_20221220_182507", "60": "XGBoost_grid_1_AutoML_2_20221220_182507_model_31", "61": "GBM_grid_1_AutoML_2_20221220_182507_model_21", "62": "GBM_grid_1_AutoML_2_20221220_182507_model_23", "63": "XGBoost_grid_1_AutoML_2_20221220_182507_model_27", "64": "GBM_grid_1_AutoML_2_20221220_182507_model_33", "65": "XGBoost_grid_1_AutoML_2_20221220_182507_model_6", "66": "XGBoost_grid_1_AutoML_2_20221220_182507_model_18", "67": "XGBoost_grid_1_AutoML_2_20221220_182507_model_39", "68": "GBM_grid_1_AutoML_2_20221220_182507_model_9", "69": "XGBoost_grid_1_AutoML_2_20221220_182507_model_16", "70": "XGBoost_grid_1_AutoML_2_20221220_182507_model_26", "71": "GBM_grid_1_AutoML_2_20221220_182507_model_7", "72": "GBM_grid_1_AutoML_2_20221220_182507_model_32", "73": "GBM_grid_1_AutoML_2_20221220_182507_model_27", "74": "XGBoost_grid_1_AutoML_2_20221220_182507_model_8", "75": "GBM_5_AutoML_2_20221220_182507", "76": "GBM_grid_1_AutoML_2_20221220_182507_model_11", "77": "XGBoost_grid_1_AutoML_2_20221220_182507_model_30", "78": "GBM_grid_1_AutoML_2_20221220_182507_model_25", "79": "GBM_grid_1_AutoML_2_20221220_182507_model_12", "80": "XGBoost_grid_1_AutoML_2_20221220_182507_model_40", "81": "XRT_1_AutoML_2_20221220_182507", "82": "GBM_grid_1_AutoML_2_20221220_182507_model_17", "83": "GBM_grid_1_AutoML_2_20221220_182507_model_3", "84": "GBM_grid_1_AutoML_2_20221220_182507_model_24", "85": "GBM_grid_1_AutoML_2_20221220_182507_model_13", "86": "GBM_grid_1_AutoML_2_20221220_182507_model_30", "87": "GBM_grid_1_AutoML_2_20221220_182507_model_15", "88": "DRF_1_AutoML_2_20221220_182507", "89": "GBM_grid_1_AutoML_2_20221220_182507_model_6", "90": "GBM_grid_1_AutoML_2_20221220_182507_model_35", "91": "GBM_grid_1_AutoML_2_20221220_182507_model_16", "92": "GBM_grid_1_AutoML_2_20221220_182507_model_4", "93": "GBM_grid_1_AutoML_2_20221220_182507_model_22", "94": "GBM_grid_1_AutoML_2_20221220_182507_model_29", "95": "GBM_grid_1_AutoML_2_20221220_182507_model_36", "96": "GLM_1_AutoML_2_20221220_182507", "97": "DeepLearning_grid_1_AutoML_2_20221220_182507_model_1", "98": "DeepLearning_grid_1_AutoML_2_20221220_182507_model_3", "99": "DeepLearning_grid_1_AutoML_2_20221220_182507_model_5", "100": "DeepLearning_grid_2_AutoML_2_20221220_182507_model_1", "101": "DeepLearning_grid_1_AutoML_2_20221220_182507_model_2", "102": "DeepLearning_1_AutoML_2_20221220_182507", "103": "DeepLearning_grid_1_AutoML_2_20221220_182507_model_4", "104": "DeepLearning_grid_3_AutoML_2_20221220_182507_model_2", "105": "DeepLearning_grid_2_AutoML_2_20221220_182507_model_2", "106": "DeepLearning_grid_3_AutoML_2_20221220_182507_model_1"}, "auc": {"0": 0.95445027676872, "1": 0.954449317235824, "2": 0.9539058798651144, "3": 0.952654727834146, "4": 0.9522269996152932, "5": 0.951843475631098, "6": 0.9518149788185084, "7": 0.9517408187554874, "8": 0.9499071382465027, "9": 0.9489267716565656, "10": 0.9486619142886332, "11": 0.9486186564425853, "12": 0.9483830451115584, "13": 0.9482704117226844, "14": 0.9480707368702644, "15": 0.9480368640445987, "16": 0.9478442213853226, "17": 0.9477359650437698, "18": 0.9477313645435824, "19": 0.9476474251315914, "20": 0.9474281784369456, "21": 0.9474174132665072, "22": 0.9469635279180172, "23": 0.946907625268597, "24": 0.9468782477888288, "25": 0.9467363946516216, "26": 0.9466324496359584, "27": 0.9464092333668652, "28": 0.9464059472953028, "29": 0.9463780288313084, "30": 0.9463678157208923, "31": 0.9463524500502664, "32": 0.946316329551652, "33": 0.94630158166248, "34": 0.9461701782328412, "35": 0.9460980292456164, "36": 0.9460085035119692, "37": 0.9460036401260568, "38": 0.9458930835344104, "39": 0.9458386661893362, "40": 0.9457281095976896, "41": 0.9455087314601814, "42": 0.9454224260766656, "43": 0.945412765026272, "44": 0.9453137228293802, "45": 0.9452216208156282, "46": 0.9451947276059612, "47": 0.9451863152627614, "48": 0.9451530207856907, "49": 0.94513108297194, "50": 0.9448182621034822, "51": 0.9448135301604323, "52": 0.9447621097126232, "53": 0.9446851630609172, "54": 0.9446629492171552, "55": 0.944600461280324, "56": 0.9445784840337144, "57": 0.944540562767884, "58": 0.9444554929472756, "59": 0.9442132831845514, "60": 0.9441006235071048, "61": 0.94402605597121, "62": 0.9440129905506778, "63": 0.9439979009100632, "64": 0.943961267784285, "65": 0.9437322943178144, "66": 0.9437244208903508, "67": 0.9437128802070236, "68": 0.943345760292068, "69": 0.9432959828800404, "70": 0.9430585313489388, "71": 0.9429930333705562, "72": 0.9428887203148782, "73": 0.9428263375323368, "74": 0.9427736420887616, "75": 0.9426923052454482, "76": 0.9425525683383272, "77": 0.9424305893619296, "78": 0.9416781709841354, "79": 0.9406580560725788, "80": 0.9404677268076824, "81": 0.9403552511502432, "82": 0.9394378982685874, "83": 0.9386888579723592, "84": 0.9381063689272018, "85": 0.9376663639449916, "86": 0.9365452746264644, "87": 0.9354185069762774, "88": 0.932179137062886, "89": 0.9284164405367474, "90": 0.9252990890326126, "91": 0.9203818509794413, "92": 0.919586332487034, "93": 0.9185319241326518, "94": 0.9135824168567376, "95": 0.8834976824783142, "96": 0.756076090906094, "97": 0.6604060080744825, "98": 0.648757633609961, "99": 0.5679606392770937, "100": 0.5676726479653618, "101": 0.5584391023377849, "102": 0.5582094453684294, "103": 0.5575278615492351, "104": 0.5538659159772007, "105": 0.5466249915679403, "106": 0.5195755489145948}, "logloss": {"0": 0.164283253616232, "1": 0.1641320047500326, "2": 0.1655247859979284, "3": 0.167560413913419, "4": 0.1680934897305222, "5": 0.1684319139709889, "6": 0.1694016478476031, "7": 0.1691263790671641, "8": 0.1725864332489968, "9": 0.2088727095016366, "10": 0.1726552406954569, "11": 0.1732685224526614, "12": 0.1754811213455612, "13": 0.1768659130438178, "14": 0.1740283707886013, "15": 0.174807185496081, "16": 0.1738303266239473, "17": 0.1743175312267277, "18": 0.1777310999446523, "19": 0.1757364808045766, "20": 0.1746465839051791, "21": 0.1765441354026427, "22": 0.1748629421636156, "23": 0.1762087606921994, "24": 0.175244741657855, "25": 0.1765475748329183, "26": 0.1769267303746764, "27": 0.1767136941317047, "28": 0.1753801364839879, "29": 0.1782494626426176, "30": 0.1759334451149401, "31": 0.1800066579903957, "32": 0.1759854474501856, "33": 0.1778060239991409, "34": 0.1759298921736277, "35": 0.1804703418679293, "36": 0.1756826922058894, "37": 0.1781949643073256, "38": 0.1764029271922872, "39": 0.1794197939220592, "40": 0.18080945050562, "41": 0.1773827804800977, "42": 0.1788141129611868, "43": 0.1785706252606101, "44": 0.1792168929528481, "45": 0.1872207624453649, "46": 0.1777241987431039, "47": 0.1812093883083937, "48": 0.1859173542261953, "49": 0.1770386154326841, "50": 0.1849174318396624, "51": 0.1780618433204057, "52": 0.1778311218656535, "53": 0.1785812258245422, "54": 0.1795451147308587, "55": 0.180026584422784, "56": 0.1801666521837357, "57": 0.1794325792512665, "58": 0.1781365337028055, "59": 0.1814957094721366, "60": 0.1808843975985416, "61": 0.1809936783649636, "62": 0.1841350882279102, "63": 0.1785361782887057, "64": 0.1819971875748428, "65": 0.1796644920618549, "66": 0.1797942234686087, "67": 0.1963837630815349, "68": 0.182462932412867, "69": 0.1797559552431777, "70": 0.18104615134329, "71": 0.1833081081021217, "72": 0.1927743171003776, "73": 0.1859475753786874, "74": 0.1865561175380967, "75": 0.1836216919747917, "76": 0.1848178230458249, "77": 0.1811108048849526, "78": 0.1853848445190764, "79": 0.1833828039939073, "80": 0.1916206576285458, "81": 0.2085664211876116, "82": 0.1973205425798153, "83": 0.1893438137806563, "84": 0.1915315379087479, "85": 0.1941137755523541, "86": 0.1908399304783952, "87": 0.1959681104820331, "88": 0.2239944494397585, "89": 0.2033729091635773, "90": 0.2169707945400218, "91": 0.2231032199296136, "92": 0.2235767300541608, "93": 0.2294533083515086, "94": 0.2300982217897086, "95": 0.314846327533282, "96": 0.3349978161674908, "97": 0.712052554939997, "98": 0.8021912351590702, "99": 0.8168356087319495, "100": 0.7266172056648695, "101": 2.063563272799034, "102": 0.609342142712192, "103": 2.670396348848, "104": 1.0450204645092414, "105": 1.3290169595854595, "106": 2.3933459320571813}, "aucpr": {"0": 0.7628460036243917, "1": 0.7638879545381236, "2": 0.7597135823914748, "3": 0.7534632683522506, "4": 0.7551005214682932, "5": 0.7481928461655186, "6": 0.74684634011242, "7": 0.7470358732938577, "8": 0.7449956486523966, "9": 0.7464433492872686, "10": 0.7446018338219177, "11": 0.7395561486268678, "12": 0.7362477625856767, "13": 0.7392197721552982, "14": 0.7416095682522797, "15": 0.7392439374561719, "16": 0.7447986126143852, "17": 0.7422357845437719, "18": 0.7335960408612362, "19": 0.7365770643812666, "20": 0.7410476900974345, "21": 0.7343169606090898, "22": 0.744149098455517, "23": 0.7358525615620848, "24": 0.739195876844505, "25": 0.7366642728979123, "26": 0.7275288586638149, "27": 0.7312895492066454, "28": 0.7384137101688238, "29": 0.7295960301838141, "30": 0.7352746067561942, "31": 0.7218905995384539, "32": 0.7389025880729502, "33": 0.735160255892553, "34": 0.7356332407115538, "35": 0.73267870168619, "36": 0.7418882224470779, "37": 0.730991450136356, "38": 0.7339508397756588, "39": 0.7263328559928491, "40": 0.7235695746622065, "41": 0.7326098578510121, "42": 0.7295323737635085, "43": 0.7359765267248183, "44": 0.7334408504776683, "45": 0.7298316208807605, "46": 0.7300946531130801, "47": 0.7266462144973618, "48": 0.731820051001527, "49": 0.7410974932159496, "50": 0.712976073604433, "51": 0.730073862321917, "52": 0.7362326316908573, "53": 0.7269135147967498, "54": 0.720937448634833, "55": 0.7292663116759602, "56": 0.731177486218488, "57": 0.728809523516789, "58": 0.7306705847347446, "59": 0.7160368397276703, "60": 0.7209058119945312, "61": 0.726005559001427, "62": 0.7219209905358972, "63": 0.7299688734874091, "64": 0.7236250526153801, "65": 0.7288326533877209, "66": 0.7200066034963495, "67": 0.7239720916111804, "68": 0.7239695316381264, "69": 0.7250873417345957, "70": 0.7196867914939278, "71": 0.7257523354623745, "72": 0.7099185642195067, "73": 0.7170140270661742, "74": 0.7180089532970154, "75": 0.7213118253290508, "76": 0.7166228845480809, "77": 0.7183366692243555, "78": 0.7231064359159427, "79": 0.7320233203225808, "80": 0.7230909685731929, "81": 0.7163676063245923, "82": 0.7020233996868845, "83": 0.7060357411893896, "84": 0.7114627739903446, "85": 0.7013606859357886, "86": 0.707405352610604, "87": 0.6973293274100973, "88": 0.6808382209632831, "89": 0.6769196009744688, "90": 0.6584344144787783, "91": 0.6466643979616473, "92": 0.6405848657890441, "93": 0.6327188463828677, "94": 0.6241871364377692, "95": 0.5209475169451113, "96": 0.2823348254100117, "97": 0.2186673793550019, "98": 0.2671745934693072, "99": 0.1627812805481603, "100": 0.1771696518720718, "101": 0.1425189246431318, "102": 0.15999473896552, "103": 0.1361871274282291, "104": 0.1644272395627536, "105": 0.1497641074485748, "106": 0.1434977244019114}, "mean_per_class_error": {"0": 0.1428195708537755, "1": 0.1409935534636745, "2": 0.1486647560833202, "3": 0.1565553894176192, "4": 0.1430067717785444, "5": 0.1448340115872667, "6": 0.1664641307412731, "7": 0.1561967475672949, "8": 0.1569261897327246, "9": 0.1391973210262154, "10": 0.1621811439325107, "11": 0.1606505312315864, "12": 0.1431003722409289, "13": 0.1689399490664165, "14": 0.1526261547846963, "15": 0.158561917290788, "16": 0.1582057202777062, "17": 0.1440006112618877, "18": 0.1543707301771939, "19": 0.1605544859319596, "20": 0.1594390618008061, "21": 0.1581029845363781, "22": 0.1659717457783575, "23": 0.1527003279920036, "24": 0.1536224391052821, "25": 0.1549925469268106, "26": 0.1711914470024218, "27": 0.1539592088632868, "28": 0.157733406639894, "29": 0.1588871069326067, "30": 0.1531391894213102, "31": 0.1680074802555733, "32": 0.1582707582060699, "33": 0.1518681500852459, "34": 0.1587771024009826, "35": 0.1507308538617729, "36": 0.1498956527691777, "37": 0.1544995836153002, "38": 0.1573516702786289, "39": 0.157123104285032, "40": 0.1584658719911611, "41": 0.1590044459759582, "42": 0.1648806385767661, "43": 0.1559614911319969, "44": 0.1520237652901567, "45": 0.1493570787843806, "46": 0.1570009412886269, "47": 0.158652494567335, "48": 0.1456777038887791, "49": 0.1518244059006068, "50": 0.1473389707950258, "51": 0.1575060630649184, "52": 0.1537835223332727, "53": 0.1674567478059951, "54": 0.163912916790201, "55": 0.1707720128281924, "56": 0.1553931321945579, "57": 0.1456400060758148, "58": 0.1439033435436396, "59": 0.1612869512832267, "60": 0.1594931636830101, "61": 0.1647645219520358, "62": 0.1438614001262167, "63": 0.1654696471879035, "64": 0.1479711452422074, "65": 0.1780195356691501, "66": 0.157255624979002, "67": 0.1565407861155958, "68": 0.1572963459778037, "69": 0.1503807032203659, "70": 0.1508718657646601, "71": 0.1558794050643673, "72": 0.1633621843406229, "73": 0.1589697713488314, "74": 0.1678032311915384, "75": 0.1694371579823857, "76": 0.1639700418582424, "77": 0.1628734666335711, "78": 0.1615483254153029, "79": 0.1618419293372635, "80": 0.1590050243245532, "81": 0.1729353783248932, "82": 0.1609732760361628, "83": 0.1604723998643299, "84": 0.1721518342772595, "85": 0.1723317664117323, "86": 0.157099365704065, "87": 0.185178282000777, "88": 0.1789081945739229, "89": 0.1776888122828202, "90": 0.191292110152694, "91": 0.2012172555455875, "92": 0.2032170929770551, "93": 0.1944900361315398, "94": 0.1771283004842723, "95": 0.2165601076906114, "96": 0.2880286809377512, "97": 0.3763004102436893, "98": 0.3924310126079468, "99": 0.4512869596955699, "100": 0.4310016061792026, "101": 0.424543279428966, "102": 0.4614650405887673, "103": 0.4422087269543201, "104": 0.4567613446100093, "105": 0.4664889839577141, "106": 0.5}, "rmse": {"0": 0.2201673915600416, "1": 0.2201003297094391, "2": 0.2213233337626049, "3": 0.2229790793497881, "4": 0.2232946952482833, "5": 0.223250408708442, "6": 0.2236300335161665, "7": 0.2237246882128047, "8": 0.2250674402022781, "9": 0.2406228892053941, "10": 0.2249007996397765, "11": 0.2271204833242865, "12": 0.2277179095984216, "13": 0.227767281552779, "14": 0.2269589026696415, "15": 0.227224283395987, "16": 0.2266471521520534, "17": 0.2271136266582881, "18": 0.228220626222011, "19": 0.2281058756812514, "20": 0.2269231246701442, "21": 0.2289347246770096, "22": 0.2272923164676695, "23": 0.227215709678157, "24": 0.2275756030862714, "25": 0.2296407148350648, "26": 0.2285619842782497, "27": 0.2272852491157701, "28": 0.2273610205838791, "29": 0.2306276838383991, "30": 0.2278111934553389, "31": 0.2292287970190929, "32": 0.2280964510753929, "33": 0.2291639049726809, "34": 0.2276661276469531, "35": 0.2285732723947801, "36": 0.2275846427748357, "37": 0.2291716160579854, "38": 0.2278879213904588, "39": 0.230782980938914, "40": 0.2312490845890419, "41": 0.228897383338593, "42": 0.228707815824646, "43": 0.229507940485978, "44": 0.2298685664749157, "45": 0.2311599374151159, "46": 0.2289431432638073, "47": 0.228975434354176, "48": 0.2303966464141735, "49": 0.226815834056189, "50": 0.2321792935218073, "51": 0.229146812923714, "52": 0.2291873307849822, "53": 0.2293993704371858, "54": 0.2301096971861919, "55": 0.230997962751052, "56": 0.2305154033303325, "57": 0.2297957859938745, "58": 0.2292242916389788, "59": 0.2313600575824874, "60": 0.2295710150586763, "61": 0.2319778723518746, "62": 0.2335363309560251, "63": 0.2292676247796462, "64": 0.2314151134792647, "65": 0.2303003142193813, "66": 0.2294399582961163, "67": 0.2323583197905654, "68": 0.2315690198503538, "69": 0.2299728308710696, "70": 0.2305525239058366, "71": 0.2328664456250107, "72": 0.2378375699597157, "73": 0.233554759887903, "74": 0.2318460078862793, "75": 0.2315865517875822, "76": 0.2340537838818016, "77": 0.2303827011869236, "78": 0.2337555319882923, "79": 0.2324942780605164, "80": 0.2325187259709851, "81": 0.2453886670952601, "82": 0.2405446993607223, "83": 0.2359561166575098, "84": 0.236455161894507, "85": 0.2386752859662412, "86": 0.2369573507656053, "87": 0.2404097557568013, "88": 0.2555655246287415, "89": 0.2449276605635522, "90": 0.2526401938342545, "91": 0.256010069348438, "92": 0.2567040459700618, "93": 0.2599423622016645, "94": 0.2602056515165997, "95": 0.3031217960935315, "96": 0.312796262456043, "97": 0.4585737420451549, "98": 0.3297766472938538, "99": 0.3384397838822002, "100": 0.3970181813117475, "101": 0.5651380885081768, "102": 0.3715644384582446, "103": 0.5201016170228088, "104": 0.3420257466799004, "105": 0.5883236797291852, "106": 0.5125796752434895}, "mse": {"0": 0.0484736803063526, "1": 0.0484441551382038, "2": 0.0489840180677934, "3": 0.0497196698276791, "4": 0.0498605209260237, "5": 0.0498407449884863, "6": 0.0500103918904417, "7": 0.0500527361159166, "8": 0.050655352639206, "9": 0.0578993748095514, "10": 0.0505803696786109, "11": 0.0515837139454575, "12": 0.0518554463518749, "13": 0.0518779345459429, "14": 0.0515103435010078, "15": 0.0516308749648198, "16": 0.051368931578636, "17": 0.0515805994138802, "18": 0.0520846542331668, "19": 0.0520322905203105, "20": 0.0514941045100618, "21": 0.0524111081629382, "22": 0.0516617971252392, "23": 0.0516269787245485, "24": 0.0517906551200801, "25": 0.0527348579099595, "26": 0.0522405806572108, "27": 0.0516585844656177, "28": 0.0516930336809431, "29": 0.0531891285526645, "30": 0.0518979398635458, "31": 0.0525458413828204, "32": 0.0520279909931891, "33": 0.0525160953423279, "34": 0.0518318656777587, "35": 0.0522457408532583, "36": 0.0517947696269496, "37": 0.0525196296066287, "38": 0.0519329047156639, "39": 0.0532607842910511, "40": 0.0534761391232698, "41": 0.0523940120992548, "42": 0.0523072650192801, "43": 0.0526738947461152, "44": 0.0528395578532327, "45": 0.0534349166657603, "46": 0.0524149628475122, "47": 0.0524297495376836, "48": 0.0530826146788976, "49": 0.0514454225786046, "50": 0.0539072243402855, "51": 0.0525082618730956, "52": 0.0525268325923448, "53": 0.0526240711569772, "54": 0.0529504727391209, "55": 0.0533600587951364, "56": 0.0531373511725458, "57": 0.0528061032605425, "58": 0.0525437758773916, "59": 0.0535274762445719, "60": 0.0527028509550709, "61": 0.0538137332609026, "62": 0.0545392178764021, "63": 0.0525636437721006, "64": 0.0535529547466209, "65": 0.0530382347295457, "66": 0.0526426944629236, "67": 0.0539903887758946, "68": 0.0536242109544535, "69": 0.0528875029388536, "70": 0.0531544662793513, "71": 0.054226781498026, "72": 0.0565667096843426, "73": 0.054547825866296, "74": 0.0537525713728046, "75": 0.0536323309688624, "76": 0.054781173749389, "77": 0.0530761890061833, "78": 0.0546416487351295, "79": 0.0540535893308807, "80": 0.05406495792717, "81": 0.0602155979387883, "82": 0.0578617523905403, "83": 0.0556752889880923, "84": 0.0559110435865575, "85": 0.056965892131067, "86": 0.0561487860818541, "87": 0.0577968506630448, "88": 0.0653137373787638, "89": 0.0599895589091346, "90": 0.0638270675406097, "91": 0.065541155607792, "92": 0.0658969672173996, "93": 0.0675700316669813, "94": 0.0677069810811781, "95": 0.0918828232669685, "96": 0.0978415018064697, "97": 0.2102898768932963, "98": 0.1087526371003748, "99": 0.1145414873142303, "100": 0.1576234362920876, "101": 0.3193810590826759, "102": 0.1380601319267907, "103": 0.2705056920297404, "104": 0.1169816113919434, "105": 0.3461247521300888, "106": 0.2627379234727211}}, "event_log": {"timestamp": {"0": "18:25:07.422", "1": "18:25:07.422", "2": "18:25:07.422", "3": "18:25:07.422", "4": "18:25:07.424", "5": "18:25:07.424", "6": "18:25:07.424", "7": "18:25:07.424", "8": "18:25:07.424", "9": "18:25:07.424", "10": "18:25:07.424", "11": "18:25:07.427", "12": "18:25:07.428", "13": "18:25:07.429", "14": "18:25:07.429", "15": "18:25:07.429", "16": "18:25:07.432", "17": "18:25:07.433", "18": "18:25:07.436", "19": "18:25:36.421", "20": "18:25:36.421", "21": "18:25:36.459", "22": "18:25:36.461", "23": "18:25:36.461", "24": "18:25:36.463", "25": "18:25:42.250", "26": "18:25:42.250", "27": "18:25:42.262", "28": "18:25:42.262", "29": "18:25:42.266", "30": "18:26:22.354", "31": "18:26:22.354", "32": "18:26:22.366", "33": "18:26:22.372", "34": "18:26:22.372", "35": "18:26:22.375", "36": "18:26:25.454", "37": "18:26:25.455", "38": "18:26:25.465", "39": "18:26:25.470", "40": "18:26:25.470", "41": "18:26:25.473", "42": "18:26:54.246", "43": "18:26:54.246", "44": "18:26:54.262", "45": "18:26:54.262", "46": "18:26:54.265", "47": "18:27:15.760", "48": "18:27:15.760", "49": "18:27:15.778", "50": "18:27:15.778", "51": "18:27:15.781", "52": "18:27:49.61", "53": "18:27:49.61", "54": "18:27:49.79", "55": "18:27:49.79", "56": "18:27:49.81", "57": "18:28:19.349", "58": "18:28:19.349", "59": "18:28:19.369", "60": "18:28:19.369", "61": "18:28:19.371", "62": "18:28:52.634", "63": "18:28:52.634", "64": "18:28:52.658", "65": "18:28:52.659", "66": "18:28:52.661", "67": "18:28:55.724", "68": "18:28:55.724", "69": "18:28:55.743", "70": "18:28:55.750", "71": "18:28:55.750", "72": "18:28:55.753", "73": "18:29:00.576", "74": "18:29:00.576", "75": "18:29:00.606", "76": "18:29:00.606", "77": "18:29:00.609", "78": "18:29:32.490", "79": "18:29:32.490", "80": "18:29:32.516", "81": "18:29:32.516", "82": "18:29:32.519", "83": "18:29:52.600", "84": "18:29:52.600", "85": "18:29:52.624", "86": "18:29:52.625", "87": "18:29:52.627", "88": "18:30:24.90", "89": "18:30:24.90", "90": "18:30:24.113", "91": "18:30:24.113", "92": "18:30:24.118", "93": "18:30:29.927", "94": "18:30:29.927", "95": "18:30:29.954", "96": "18:30:29.954", "97": "18:30:29.956", "98": "18:30:33.234", "99": "18:30:33.234", "100": "18:30:33.260", "101": "18:30:33.268", "102": "18:30:33.268", "103": "18:30:33.270", "104": "18:30:38.221", "105": "18:30:38.221", "106": "18:30:38.248", "107": "18:30:38.252", "108": "18:30:38.252", "109": "18:30:38.282", "110": "18:31:08.295", "111": "18:31:08.295", "112": "18:31:43.333", "113": "18:31:43.333", "114": "18:32:13.383", "115": "18:32:13.383", "116": "18:33:03.429", "117": "18:33:03.429", "118": "18:33:48.485", "119": "18:33:48.486", "120": "18:34:48.240", "121": "18:34:48.240", "122": "18:35:15.276", "123": "18:35:15.276", "124": "18:35:42.323", "125": "18:35:42.323", "126": "18:36:09.364", "127": "18:36:09.365", "128": "18:36:39.404", "129": "18:36:39.404", "130": "18:37:08.454", "131": "18:37:08.454", "132": "18:37:56.506", "133": "18:37:56.507", "134": "18:38:46.560", "135": "18:38:46.560", "136": "18:39:18.848", "137": "18:39:18.848", "138": "18:40:15.913", "139": "18:40:15.913", "140": "18:41:11.977", "141": "18:41:11.977", "142": "18:42:06.62", "143": "18:42:06.62", "144": "18:42:35.111", "145": "18:42:35.111", "146": "18:43:09.177", "147": "18:43:09.177", "148": "18:43:56.271", "149": "18:43:56.271", "150": "18:44:37.738", "151": "18:44:37.738", "152": "18:45:22.795", "153": "18:45:22.795", "154": "18:45:54.877", "155": "18:45:54.877", "156": "18:46:22.941", "157": "18:46:22.941", "158": "18:47:09.4", "159": "18:47:09.4", "160": "18:47:38.74", "161": "18:47:38.75", "162": "18:48:28.136", "163": "18:48:28.136", "164": "18:49:16.220", "165": "18:49:16.220", "166": "18:50:03.292", "167": "18:50:03.292", "168": "18:50:33.369", "169": "18:50:33.369", "170": "18:51:01.431", "171": "18:51:01.431", "172": "18:51:33.513", "173": "18:51:33.513", "174": "18:52:02.596", "175": "18:52:02.596", "176": "18:52:58.694", "177": "18:52:58.695", "178": "18:53:29.762", "179": "18:53:29.762", "180": "18:54:06.855", "181": "18:54:06.856", "182": "18:54:41.934", "183": "18:54:41.935", "184": "18:55:12.15", "185": "18:55:12.16", "186": "18:55:41.105", "187": "18:55:41.105", "188": "18:55:48.338", "189": "18:55:48.338", "190": "18:55:48.339", "191": "18:55:48.426", "192": "18:55:48.426", "193": "18:55:48.430", "194": "18:56:17.443", "195": "18:56:17.443", "196": "18:56:44.560", "197": "18:56:44.560", "198": "18:57:19.686", "199": "18:57:19.686", "200": "18:57:38.795", "201": "18:57:38.795", "202": "18:58:08.904", "203": "18:58:08.905", "204": "18:58:47.21", "205": "18:58:47.21", "206": "18:59:15.240", "207": "18:59:15.240", "208": "18:59:40.361", "209": "18:59:40.361", "210": "19:00:12.497", "211": "19:00:12.498", "212": "19:00:55.626", "213": "19:00:55.627", "214": "19:01:21.759", "215": "19:01:21.759", "216": "19:02:00.884", "217": "19:02:00.885", "218": "19:02:21.14", "219": "19:02:21.14", "220": "19:02:51.172", "221": "19:02:51.172", "222": "19:03:28.319", "223": "19:03:28.319", "224": "19:03:49.456", "225": "19:03:49.456", "226": "19:04:13.606", "227": "19:04:13.606", "228": "19:04:52.912", "229": "19:04:52.912", "230": "19:05:16.52", "231": "19:05:16.52", "232": "19:05:48.197", "233": "19:05:48.197", "234": "19:06:24.344", "235": "19:06:24.344", "236": "19:06:42.480", "237": "19:06:42.480", "238": "19:07:08.629", "239": "19:07:08.630", "240": "19:07:28.786", "241": "19:07:28.786", "242": "19:07:51.949", "243": "19:07:51.949", "244": "19:08:21.152", "245": "19:08:21.152", "246": "19:08:41.315", "247": "19:08:41.315", "248": "19:09:02.477", "249": "19:09:02.478", "250": "19:09:34.846", "251": "19:09:34.847", "252": "19:10:16.6", "253": "19:10:16.7", "254": "19:10:43.158", "255": "19:10:43.158", "256": "19:11:02.338", "257": "19:11:02.338", "258": "19:11:29.481", "259": "19:11:29.481", "260": "19:12:08.630", "261": "19:12:08.630", "262": "19:12:31.798", "263": "19:12:31.799", "264": "19:12:34.334", "265": "19:12:34.334", "266": "19:12:34.334", "267": "19:12:34.456", "268": "19:12:34.457", "269": "19:12:34.462", "270": "19:16:36.946", "271": "19:16:36.946", "272": "19:18:54.309", "273": "19:18:54.309", "274": "19:20:17.724", "275": "19:20:17.724", "276": "19:20:55.117", "277": "19:20:55.117", "278": "19:20:57.467", "279": "19:20:57.467", "280": "19:20:57.467", "281": "19:20:57.610", "282": "19:20:57.611", "283": "19:20:57.614", "284": "19:21:00.355", "285": "19:21:00.355", "286": "19:21:00.481", "287": "19:21:00.513", "288": "19:21:00.514", "289": "19:21:00.537", "290": "19:21:07.763", "291": "19:21:07.763", "292": "19:21:07.881", "293": "19:21:07.885", "294": "19:21:07.885", "295": "19:21:07.887", "296": "19:22:25.901", "297": "19:22:25.901", "298": "19:22:45.234", "299": "19:22:45.234", "300": "19:22:45.234", "301": "19:22:45.356", "302": "19:22:45.357", "303": "19:22:45.359", "304": "19:24:05.373", "305": "19:24:05.373", "306": "19:24:23.902", "307": "19:24:23.902", "308": "19:24:23.902", "309": "19:24:24.162", "310": "19:24:24.162", "311": "19:24:24.168", "312": "19:24:32.371", "313": "19:24:32.371", "314": "19:24:32.503", "315": "19:24:32.522", "316": "19:24:32.529", "317": "19:24:32.529", "318": "19:24:32.530", "319": "19:24:39.434", "320": "19:24:39.435", "321": "19:24:39.438", "322": "19:24:39.438", "323": "19:24:39.438", "324": "19:24:42.723", "325": "19:24:42.725", "326": "19:24:42.730", "327": "19:24:42.730", "328": "19:24:42.734", "329": "19:24:58.946", "330": "19:24:58.946", "331": "19:24:59.82", "332": "19:24:59.82", "333": "19:24:59.86", "334": "19:25:08.87", "335": "19:25:09.89", "336": "19:25:10.89", "337": "19:25:11.89", "338": "19:25:11.802", "339": "19:25:11.803", "340": "19:25:11.917", "341": "19:25:11.917", "342": "19:25:11.917", "343": "19:25:11.917", "344": "19:25:11.917", "345": "19:25:11.917", "346": "19:25:11.917", "347": "19:25:11.917", "348": "19:25:11.917", "349": "19:25:11.958", "350": "19:25:11.958"}, "level": {"0": "INFO", "1": "INFO", "2": "INFO", "3": "INFO", "4": "INFO", "5": "INFO", "6": "INFO", "7": "INFO", "8": "INFO", "9": "INFO", "10": "INFO", "11": "INFO", "12": "DEBUG", "13": "DEBUG", "14": "INFO", "15": "INFO", "16": "DEBUG", "17": "INFO", "18": "DEBUG", "19": "DEBUG", "20": "DEBUG", "21": "INFO", "22": "DEBUG", "23": "INFO", "24": "DEBUG", "25": "DEBUG", "26": "DEBUG", "27": "DEBUG", "28": "INFO", "29": "DEBUG", "30": "DEBUG", "31": "DEBUG", "32": "INFO", "33": "DEBUG", "34": "INFO", "35": "DEBUG", "36": "DEBUG", "37": "DEBUG", "38": "INFO", "39": "DEBUG", "40": "INFO", "41": "DEBUG", "42": "DEBUG", "43": "DEBUG", "44": "DEBUG", "45": "INFO", "46": "DEBUG", "47": "DEBUG", "48": "DEBUG", "49": "DEBUG", "50": "INFO", "51": "DEBUG", "52": "DEBUG", "53": "DEBUG", "54": "DEBUG", "55": "INFO", "56": "DEBUG", "57": "DEBUG", "58": "DEBUG", "59": "DEBUG", "60": "INFO", "61": "DEBUG", "62": "DEBUG", "63": "DEBUG", "64": "DEBUG", "65": "INFO", "66": "DEBUG", "67": "DEBUG", "68": "DEBUG", "69": "INFO", "70": "DEBUG", "71": "INFO", "72": "DEBUG", "73": "DEBUG", "74": "DEBUG", "75": "DEBUG", "76": "INFO", "77": "DEBUG", "78": "DEBUG", "79": "DEBUG", "80": "DEBUG", "81": "INFO", "82": "DEBUG", "83": "DEBUG", "84": "DEBUG", "85": "DEBUG", "86": "INFO", "87": "DEBUG", "88": "DEBUG", "89": "DEBUG", "90": "DEBUG", "91": "INFO", "92": "DEBUG", "93": "DEBUG", "94": "DEBUG", "95": "DEBUG", "96": "INFO", "97": "DEBUG", "98": "DEBUG", "99": "DEBUG", "100": "INFO", "101": "DEBUG", "102": "INFO", "103": "DEBUG", "104": "DEBUG", "105": "DEBUG", "106": "INFO", "107": "DEBUG", "108": "INFO", "109": "DEBUG", "110": "DEBUG", "111": "DEBUG", "112": "DEBUG", "113": "DEBUG", "114": "DEBUG", "115": "DEBUG", "116": "DEBUG", "117": "DEBUG", "118": "DEBUG", "119": "DEBUG", "120": "DEBUG", "121": "DEBUG", "122": "DEBUG", "123": "DEBUG", "124": "DEBUG", "125": "DEBUG", "126": "DEBUG", "127": "DEBUG", "128": "DEBUG", "129": "DEBUG", "130": "DEBUG", "131": "DEBUG", "132": "DEBUG", "133": "DEBUG", "134": "DEBUG", "135": "DEBUG", "136": "DEBUG", "137": "DEBUG", "138": "DEBUG", "139": "DEBUG", "140": "DEBUG", "141": "DEBUG", "142": "DEBUG", "143": "DEBUG", "144": "DEBUG", "145": "DEBUG", "146": "DEBUG", "147": "DEBUG", "148": "DEBUG", "149": "DEBUG", "150": "DEBUG", "151": "DEBUG", "152": "DEBUG", "153": "DEBUG", "154": "DEBUG", "155": "DEBUG", "156": "DEBUG", "157": "DEBUG", "158": "DEBUG", "159": "DEBUG", "160": "DEBUG", "161": "DEBUG", "162": "DEBUG", "163": "DEBUG", "164": "DEBUG", "165": "DEBUG", "166": "DEBUG", "167": "DEBUG", "168": "DEBUG", "169": "DEBUG", "170": "DEBUG", "171": "DEBUG", "172": "DEBUG", "173": "DEBUG", "174": "DEBUG", "175": "DEBUG", "176": "DEBUG", "177": "DEBUG", "178": "DEBUG", "179": "DEBUG", "180": "DEBUG", "181": "DEBUG", "182": "DEBUG", "183": "DEBUG", "184": "DEBUG", "185": "DEBUG", "186": "DEBUG", "187": "DEBUG", "188": "DEBUG", "189": "DEBUG", "190": "DEBUG", "191": "DEBUG", "192": "INFO", "193": "DEBUG", "194": "DEBUG", "195": "DEBUG", "196": "DEBUG", "197": "DEBUG", "198": "DEBUG", "199": "DEBUG", "200": "DEBUG", "201": "DEBUG", "202": "DEBUG", "203": "DEBUG", "204": "DEBUG", "205": "DEBUG", "206": "DEBUG", "207": "DEBUG", "208": "DEBUG", "209": "DEBUG", "210": "DEBUG", "211": "DEBUG", "212": "DEBUG", "213": "DEBUG", "214": "DEBUG", "215": "DEBUG", "216": "DEBUG", "217": "DEBUG", "218": "DEBUG", "219": "DEBUG", "220": "DEBUG", "221": "DEBUG", "222": "DEBUG", "223": "DEBUG", "224": "DEBUG", "225": "DEBUG", "226": "DEBUG", "227": "DEBUG", "228": "DEBUG", "229": "DEBUG", "230": "DEBUG", "231": "DEBUG", "232": "DEBUG", "233": "DEBUG", "234": "DEBUG", "235": "DEBUG", "236": "DEBUG", "237": "DEBUG", "238": "DEBUG", "239": "DEBUG", "240": "DEBUG", "241": "DEBUG", "242": "DEBUG", "243": "DEBUG", "244": "DEBUG", "245": "DEBUG", "246": "DEBUG", "247": "DEBUG", "248": "DEBUG", "249": "DEBUG", "250": "DEBUG", "251": "DEBUG", "252": "DEBUG", "253": "DEBUG", "254": "DEBUG", "255": "DEBUG", "256": "DEBUG", "257": "DEBUG", "258": "DEBUG", "259": "DEBUG", "260": "DEBUG", "261": "DEBUG", "262": "DEBUG", "263": "DEBUG", "264": "DEBUG", "265": "DEBUG", "266": "DEBUG", "267": "DEBUG", "268": "INFO", "269": "DEBUG", "270": "DEBUG", "271": "DEBUG", "272": "DEBUG", "273": "DEBUG", "274": "DEBUG", "275": "DEBUG", "276": "DEBUG", "277": "DEBUG", "278": "DEBUG", "279": "DEBUG", "280": "DEBUG", "281": "DEBUG", "282": "INFO", "283": "DEBUG", "284": "DEBUG", "285": "DEBUG", "286": "INFO", "287": "DEBUG", "288": "INFO", "289": "DEBUG", "290": "DEBUG", "291": "DEBUG", "292": "INFO", "293": "DEBUG", "294": "INFO", "295": "DEBUG", "296": "DEBUG", "297": "DEBUG", "298": "DEBUG", "299": "DEBUG", "300": "DEBUG", "301": "DEBUG", "302": "INFO", "303": "DEBUG", "304": "DEBUG", "305": "DEBUG", "306": "DEBUG", "307": "DEBUG", "308": "DEBUG", "309": "DEBUG", "310": "INFO", "311": "DEBUG", "312": "DEBUG", "313": "DEBUG", "314": "INFO", "315": "DEBUG", "316": "INFO", "317": "INFO", "318": "DEBUG", "319": "DEBUG", "320": "DEBUG", "321": "DEBUG", "322": "INFO", "323": "INFO", "324": "DEBUG", "325": "INFO", "326": "DEBUG", "327": "INFO", "328": "DEBUG", "329": "DEBUG", "330": "DEBUG", "331": "DEBUG", "332": "INFO", "333": "DEBUG", "334": "DEBUG", "335": "DEBUG", "336": "DEBUG", "337": "DEBUG", "338": "DEBUG", "339": "DEBUG", "340": "DEBUG", "341": "DEBUG", "342": "DEBUG", "343": "DEBUG", "344": "DEBUG", "345": "INFO", "346": "INFO", "347": "INFO", "348": "INFO", "349": "DEBUG", "350": "DEBUG"}, "stage": {"0": "Workflow", "1": "Validation", "2": "Validation", "3": "Validation", "4": "DataImport", "5": "DataImport", "6": "DataImport", "7": "DataImport", "8": "DataImport", "9": "DataImport", "10": "DataImport", "11": "Workflow", "12": "Workflow", "13": "Workflow", "14": "Workflow", "15": "Workflow", "16": "ModelTraining", "17": "ModelTraining", "18": "ModelTraining", "19": "ModelTraining", "20": "ModelTraining", "21": "ModelTraining", "22": "ModelTraining", "23": "ModelTraining", "24": "ModelTraining", "25": "ModelTraining", "26": "ModelTraining", "27": "ModelTraining", "28": "ModelTraining", "29": "ModelTraining", "30": "ModelTraining", "31": "ModelTraining", "32": "ModelTraining", "33": "ModelTraining", "34": "ModelTraining", "35": "ModelTraining", "36": "ModelTraining", "37": "ModelTraining", "38": "ModelTraining", "39": "ModelTraining", "40": "ModelTraining", "41": "ModelTraining", "42": "ModelTraining", "43": "ModelTraining", "44": "ModelTraining", "45": "ModelTraining", "46": "ModelTraining", "47": "ModelTraining", "48": "ModelTraining", "49": "ModelTraining", "50": "ModelTraining", "51": "ModelTraining", "52": "ModelTraining", "53": "ModelTraining", "54": "ModelTraining", "55": "ModelTraining", "56": "ModelTraining", "57": "ModelTraining", "58": "ModelTraining", "59": "ModelTraining", "60": "ModelTraining", "61": "ModelTraining", "62": "ModelTraining", "63": "ModelTraining", "64": "ModelTraining", "65": "ModelTraining", "66": "ModelTraining", "67": "ModelTraining", "68": "ModelTraining", "69": "ModelTraining", "70": "ModelTraining", "71": "ModelTraining", "72": "ModelTraining", "73": "ModelTraining", "74": "ModelTraining", "75": "ModelTraining", "76": "ModelTraining", "77": "ModelTraining", "78": "ModelTraining", "79": "ModelTraining", "80": "ModelTraining", "81": "ModelTraining", "82": "ModelTraining", "83": "ModelTraining", "84": "ModelTraining", "85": "ModelTraining", "86": "ModelTraining", "87": "ModelTraining", "88": "ModelTraining", "89": "ModelTraining", "90": "ModelTraining", "91": "ModelTraining", "92": "ModelTraining", "93": "ModelTraining", "94": "ModelTraining", "95": "ModelTraining", "96": "ModelTraining", "97": "ModelTraining", "98": "ModelTraining", "99": "ModelTraining", "100": "ModelTraining", "101": "ModelTraining", "102": "ModelTraining", "103": "ModelTraining", "104": "ModelTraining", "105": "ModelTraining", "106": "ModelTraining", "107": "ModelTraining", "108": "ModelTraining", "109": "ModelTraining", "110": "ModelTraining", "111": "ModelTraining", "112": "ModelTraining", "113": "ModelTraining", "114": "ModelTraining", "115": "ModelTraining", "116": "ModelTraining", "117": "ModelTraining", "118": "ModelTraining", "119": "ModelTraining", "120": "ModelTraining", "121": "ModelTraining", "122": "ModelTraining", "123": "ModelTraining", "124": "ModelTraining", "125": "ModelTraining", "126": "ModelTraining", "127": "ModelTraining", "128": "ModelTraining", "129": "ModelTraining", "130": "ModelTraining", "131": "ModelTraining", "132": "ModelTraining", "133": "ModelTraining", "134": "ModelTraining", "135": "ModelTraining", "136": "ModelTraining", "137": "ModelTraining", "138": "ModelTraining", "139": "ModelTraining", "140": "ModelTraining", "141": "ModelTraining", "142": "ModelTraining", "143": "ModelTraining", "144": "ModelTraining", "145": "ModelTraining", "146": "ModelTraining", "147": "ModelTraining", "148": "ModelTraining", "149": "ModelTraining", "150": "ModelTraining", "151": "ModelTraining", "152": "ModelTraining", "153": "ModelTraining", "154": "ModelTraining", "155": "ModelTraining", "156": "ModelTraining", "157": "ModelTraining", "158": "ModelTraining", "159": "ModelTraining", "160": "ModelTraining", "161": "ModelTraining", "162": "ModelTraining", "163": "ModelTraining", "164": "ModelTraining", "165": "ModelTraining", "166": "ModelTraining", "167": "ModelTraining", "168": "ModelTraining", "169": "ModelTraining", "170": "ModelTraining", "171": "ModelTraining", "172": "ModelTraining", "173": "ModelTraining", "174": "ModelTraining", "175": "ModelTraining", "176": "ModelTraining", "177": "ModelTraining", "178": "ModelTraining", "179": "ModelTraining", "180": "ModelTraining", "181": "ModelTraining", "182": "ModelTraining", "183": "ModelTraining", "184": "ModelTraining", "185": "ModelTraining", "186": "ModelTraining", "187": "ModelTraining", "188": "ModelTraining", "189": "ModelTraining", "190": "ModelTraining", "191": "ModelTraining", "192": "ModelTraining", "193": "ModelTraining", "194": "ModelTraining", "195": "ModelTraining", "196": "ModelTraining", "197": "ModelTraining", "198": "ModelTraining", "199": "ModelTraining", "200": "ModelTraining", "201": "ModelTraining", "202": "ModelTraining", "203": "ModelTraining", "204": "ModelTraining", "205": "ModelTraining", "206": "ModelTraining", "207": "ModelTraining", "208": "ModelTraining", "209": "ModelTraining", "210": "ModelTraining", "211": "ModelTraining", "212": "ModelTraining", "213": "ModelTraining", "214": "ModelTraining", "215": "ModelTraining", "216": "ModelTraining", "217": "ModelTraining", "218": "ModelTraining", "219": "ModelTraining", "220": "ModelTraining", "221": "ModelTraining", "222": "ModelTraining", "223": "ModelTraining", "224": "ModelTraining", "225": "ModelTraining", "226": "ModelTraining", "227": "ModelTraining", "228": "ModelTraining", "229": "ModelTraining", "230": "ModelTraining", "231": "ModelTraining", "232": "ModelTraining", "233": "ModelTraining", "234": "ModelTraining", "235": "ModelTraining", "236": "ModelTraining", "237": "ModelTraining", "238": "ModelTraining", "239": "ModelTraining", "240": "ModelTraining", "241": "ModelTraining", "242": "ModelTraining", "243": "ModelTraining", "244": "ModelTraining", "245": "ModelTraining", "246": "ModelTraining", "247": "ModelTraining", "248": "ModelTraining", "249": "ModelTraining", "250": "ModelTraining", "251": "ModelTraining", "252": "ModelTraining", "253": "ModelTraining", "254": "ModelTraining", "255": "ModelTraining", "256": "ModelTraining", "257": "ModelTraining", "258": "ModelTraining", "259": "ModelTraining", "260": "ModelTraining", "261": "ModelTraining", "262": "ModelTraining", "263": "ModelTraining", "264": "ModelTraining", "265": "ModelTraining", "266": "ModelTraining", "267": "ModelTraining", "268": "ModelTraining", "269": "ModelTraining", "270": "ModelTraining", "271": "ModelTraining", "272": "ModelTraining", "273": "ModelTraining", "274": "ModelTraining", "275": "ModelTraining", "276": "ModelTraining", "277": "ModelTraining", "278": "ModelTraining", "279": "ModelTraining", "280": "ModelTraining", "281": "ModelTraining", "282": "ModelTraining", "283": "ModelTraining", "284": "ModelTraining", "285": "ModelTraining", "286": "ModelTraining", "287": "ModelTraining", "288": "ModelTraining", "289": "ModelTraining", "290": "ModelTraining", "291": "ModelTraining", "292": "ModelTraining", "293": "ModelTraining", "294": "ModelTraining", "295": "ModelTraining", "296": "ModelTraining", "297": "ModelTraining", "298": "ModelTraining", "299": "ModelTraining", "300": "ModelTraining", "301": "ModelTraining", "302": "ModelTraining", "303": "ModelTraining", "304": "ModelTraining", "305": "ModelTraining", "306": "ModelTraining", "307": "ModelTraining", "308": "ModelTraining", "309": "ModelTraining", "310": "ModelTraining", "311": "ModelTraining", "312": "ModelTraining", "313": "ModelTraining", "314": "ModelTraining", "315": "ModelTraining", "316": "ModelSelection", "317": "ModelTraining", "318": "ModelTraining", "319": "ModelTraining", "320": "ModelTraining", "321": "ModelTraining", "322": "ModelSelection", "323": "ModelTraining", "324": "ModelTraining", "325": "ModelTraining", "326": "ModelTraining", "327": "ModelTraining", "328": "ModelTraining", "329": "ModelTraining", "330": "ModelTraining", "331": "ModelTraining", "332": "ModelTraining", "333": "ModelTraining", "334": "ModelTraining", "335": "ModelTraining", "336": "ModelTraining", "337": "ModelTraining", "338": "ModelTraining", "339": "ModelTraining", "340": "ModelTraining", "341": "ModelTraining", "342": "ModelTraining", "343": "ModelTraining", "344": "ModelTraining", "345": "Workflow", "346": "Workflow", "347": "Workflow", "348": "Workflow", "349": "Workflow", "350": "Workflow"}, "message": {"0": "Project: classification_test_2022-12-20T21.25.05", "1": "5-fold cross-validation will be used.", "2": "Setting stopping tolerance adaptively based on the training frame: 0.00724466513640519", "3": "Build control seed: -1 (random)", "4": "training frame: Frame key: AutoML_2_20221220_182507_training_product_backorders1.hex    cols: 23    rows: 19053  chunks: 48    size: 896711  checksum: 340006888695133344", "5": "validation frame: NULL", "6": "leaderboard frame: NULL", "7": "blending frame: NULL", "8": "response column: went_on_backorder", "9": "fold column: null", "10": "weights column: null", "11": "Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]", "12": "Defined work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]", "13": "Actual work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]", "14": "AutoML job created: 2022.12.20 18:25:07.419", "15": "AutoML build started: 2022.12.20 18:25:07.429", "16": "Time assigned for XGBoost_1_AutoML_2_20221220_182507: 1028.570625s", "17": "AutoML: starting XGBoost_1_AutoML_2_20221220_182507 model training", "18": "XGBoost_1_AutoML_2_20221220_182507 [XGBoost def_2] started", "19": "XGBoost_1_AutoML_2_20221220_182507 [XGBoost def_2] complete", "20": "Adding model XGBoost_1_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=29s", "21": "New leader: XGBoost_1_AutoML_2_20221220_182507, auc: 0.9442132831845514", "22": "Time assigned for GLM_1_AutoML_2_20221220_182507: 1428.38725s", "23": "AutoML: starting GLM_1_AutoML_2_20221220_182507 model training", "24": "GLM_1_AutoML_2_20221220_182507 [GLM def_1] started", "25": "GLM_1_AutoML_2_20221220_182507 [GLM def_1] complete", "26": "Adding model GLM_1_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=1s, total=6s", "27": "Time assigned for GBM_1_AutoML_2_20221220_182507: 2376.778s", "28": "AutoML: starting GBM_1_AutoML_2_20221220_182507 model training", "29": "GBM_1_AutoML_2_20221220_182507 [GBM def_5] started", "30": "GBM_1_AutoML_2_20221220_182507 [GBM def_5] complete", "31": "Adding model GBM_1_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=10s, total=40s", "32": "New leader: GBM_1_AutoML_2_20221220_182507, auc: 0.9467363946516215", "33": "Time assigned for StackedEnsemble_BestOfFamily_1_AutoML_2_20221220_182507: 3525.057s", "34": "AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_2_20221220_182507 model training", "35": "StackedEnsemble_BestOfFamily_1_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_1 (built with AUTO metalearner, using top model from each algorithm type)] started", "36": "StackedEnsemble_BestOfFamily_1_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_1 (built with AUTO metalearner, using top model from each algorithm type)] complete", "37": "Adding model StackedEnsemble_BestOfFamily_1_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=3s, total=3s", "38": "New leader: StackedEnsemble_BestOfFamily_1_AutoML_2_20221220_182507, auc: 0.9486186564425851", "39": "Time assigned for XGBoost_2_AutoML_2_20221220_182507: 541.839875s", "40": "AutoML: starting XGBoost_2_AutoML_2_20221220_182507 model training", "41": "XGBoost_2_AutoML_2_20221220_182507 [XGBoost def_1] started", "42": "XGBoost_2_AutoML_2_20221220_182507 [XGBoost def_1] complete", "43": "Adding model XGBoost_2_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=29s", "44": "Time assigned for DRF_1_AutoML_2_20221220_182507: 635.1213125s", "45": "AutoML: starting DRF_1_AutoML_2_20221220_182507 model training", "46": "DRF_1_AutoML_2_20221220_182507 [DRF def_1] started", "47": "DRF_1_AutoML_2_20221220_182507 [DRF def_1] complete", "48": "Adding model DRF_1_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=21s", "49": "Time assigned for GBM_2_AutoML_2_20221220_182507: 771.478s", "50": "AutoML: starting GBM_2_AutoML_2_20221220_182507 model training", "51": "GBM_2_AutoML_2_20221220_182507 [GBM def_2] started", "52": "GBM_2_AutoML_2_20221220_182507 [GBM def_2] complete", "53": "Adding model GBM_2_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=33s", "54": "Time assigned for GBM_3_AutoML_2_20221220_182507: 982.38575s", "55": "AutoML: starting GBM_3_AutoML_2_20221220_182507 model training", "56": "GBM_3_AutoML_2_20221220_182507 [GBM def_3] started", "57": "GBM_3_AutoML_2_20221220_182507 [GBM def_3] complete", "58": "Adding model GBM_3_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=30s", "59": "Time assigned for GBM_4_AutoML_2_20221220_182507: 1363.224s", "60": "AutoML: starting GBM_4_AutoML_2_20221220_182507 model training", "61": "GBM_4_AutoML_2_20221220_182507 [GBM def_4] started", "62": "GBM_4_AutoML_2_20221220_182507 [GBM def_4] complete", "63": "Adding model GBM_4_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=33s", "64": "Time assigned for StackedEnsemble_BestOfFamily_2_AutoML_2_20221220_182507: 1124.92375s", "65": "AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_2_20221220_182507 model training", "66": "StackedEnsemble_BestOfFamily_2_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_2 (built with AUTO metalearner, using top model from each algorithm type)] started", "67": "StackedEnsemble_BestOfFamily_2_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_2 (built with AUTO metalearner, using top model from each algorithm type)] complete", "68": "Adding model StackedEnsemble_BestOfFamily_2_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=3s, total=3s", "69": "New leader: StackedEnsemble_BestOfFamily_2_AutoML_2_20221220_182507, auc: 0.9518149788185085", "70": "Time assigned for StackedEnsemble_AllModels_1_AutoML_2_20221220_182507: 3371.679s", "71": "AutoML: starting StackedEnsemble_AllModels_1_AutoML_2_20221220_182507 model training", "72": "StackedEnsemble_AllModels_1_AutoML_2_20221220_182507 [StackedEnsemble all_2 (built with AUTO metalearner, using all AutoML models)] started", "73": "StackedEnsemble_AllModels_1_AutoML_2_20221220_182507 [StackedEnsemble all_2 (built with AUTO metalearner, using all AutoML models)] complete", "74": "Adding model StackedEnsemble_AllModels_1_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=5s", "75": "Time assigned for XGBoost_3_AutoML_2_20221220_182507: 612.149625s", "76": "AutoML: starting XGBoost_3_AutoML_2_20221220_182507 model training", "77": "XGBoost_3_AutoML_2_20221220_182507 [XGBoost def_3] started", "78": "XGBoost_3_AutoML_2_20221220_182507 [XGBoost def_3] complete", "79": "Adding model XGBoost_3_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=10s, total=32s", "80": "Time assigned for XRT_1_AutoML_2_20221220_182507: 741.0918125s", "81": "AutoML: starting XRT_1_AutoML_2_20221220_182507 model training", "82": "XRT_1_AutoML_2_20221220_182507 [DRF XRT (Extremely Randomized Trees)] started", "83": "XRT_1_AutoML_2_20221220_182507 [DRF XRT (Extremely Randomized Trees)] complete", "84": "Adding model XRT_1_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=4s, total=20s", "85": "Time assigned for GBM_5_AutoML_2_20221220_182507: 947.0871875s", "86": "AutoML: starting GBM_5_AutoML_2_20221220_182507 model training", "87": "GBM_5_AutoML_2_20221220_182507 [GBM def_1] started", "88": "GBM_5_AutoML_2_20221220_182507 [GBM def_1] complete", "89": "Adding model GBM_5_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=31s", "90": "Time assigned for DeepLearning_1_AutoML_2_20221220_182507: 1313.326375s", "91": "AutoML: starting DeepLearning_1_AutoML_2_20221220_182507 model training", "92": "DeepLearning_1_AutoML_2_20221220_182507 [DeepLearning def_1] started", "93": "DeepLearning_1_AutoML_2_20221220_182507 [DeepLearning def_1] complete", "94": "Adding model DeepLearning_1_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=1s, total=6s", "95": "Time assigned for StackedEnsemble_BestOfFamily_3_AutoML_2_20221220_182507: 1092.49175s", "96": "AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_2_20221220_182507 model training", "97": "StackedEnsemble_BestOfFamily_3_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_3 (built with AUTO metalearner, using top model from each algorithm type)] started", "98": "StackedEnsemble_BestOfFamily_3_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_3 (built with AUTO metalearner, using top model from each algorithm type)] complete", "99": "Adding model StackedEnsemble_BestOfFamily_3_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=3s, total=3s", "100": "New leader: StackedEnsemble_BestOfFamily_3_AutoML_2_20221220_182507, auc: 0.9522269996152931", "101": "Time assigned for StackedEnsemble_AllModels_2_AutoML_2_20221220_182507: 3274.161s", "102": "AutoML: starting StackedEnsemble_AllModels_2_AutoML_2_20221220_182507 model training", "103": "StackedEnsemble_AllModels_2_AutoML_2_20221220_182507 [StackedEnsemble all_3 (built with AUTO metalearner, using all AutoML models)] started", "104": "StackedEnsemble_AllModels_2_AutoML_2_20221220_182507 [StackedEnsemble all_3 (built with AUTO metalearner, using all AutoML models)] complete", "105": "Adding model StackedEnsemble_AllModels_2_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=5s", "106": "New leader: StackedEnsemble_AllModels_2_AutoML_2_20221220_182507, auc: 0.9526547278341461", "107": "Time assigned for XGBoost_grid_1_AutoML_2_20221220_182507: 1508.850875s", "108": "AutoML: starting XGBoost_grid_1_AutoML_2_20221220_182507 hyperparameter search", "109": "XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search] started", "110": "Built: 1 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "111": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_1 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=30s", "112": "Built: 2 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "113": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_2 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=10s, total=35s", "114": "Built: 3 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "115": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_3 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=30s", "116": "Built: 4 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "117": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_4 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=15s, total=50s", "118": "Built: 5 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "119": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_5 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=13s, total=45s", "120": "Built: 6 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "121": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_6 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=18s, total=60s", "122": "Built: 7 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "123": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_7 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=26s", "124": "Built: 8 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "125": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_8 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=27s", "126": "Built: 9 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "127": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_9 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=27s", "128": "Built: 10 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "129": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_10 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=30s", "130": "Built: 11 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "131": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_11 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=29s", "132": "Built: 12 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "133": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_12 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=14s, total=48s", "134": "Built: 13 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "135": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_13 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=14s, total=50s", "136": "Built: 14 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "137": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_14 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=33s", "138": "Built: 15 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "139": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_15 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=18s, total=57s", "140": "Built: 16 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "141": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_16 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=17s, total=56s", "142": "Built: 17 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "143": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_17 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=15s, total=54s", "144": "Built: 18 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "145": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_18 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=29s", "146": "Built: 19 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "147": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_19 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=10s, total=34s", "148": "Built: 20 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "149": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_20 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=14s, total=47s", "150": "Built: 21 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "151": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_21 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=12s, total=42s", "152": "Built: 22 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "153": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_22 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=14s, total=45s", "154": "Built: 23 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "155": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_23 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=10s, total=32s", "156": "Built: 24 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "157": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_24 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=28s", "158": "Built: 25 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "159": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_25 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=14s, total=45s", "160": "Built: 26 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "161": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_26 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=30s", "162": "Built: 27 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "163": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_27 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=14s, total=50s", "164": "Built: 28 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "165": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_28 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=14s, total=48s", "166": "Built: 29 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "167": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_29 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=14s, total=47s", "168": "Built: 30 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "169": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_30 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=31s", "170": "Built: 31 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "171": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_31 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=28s", "172": "Built: 32 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "173": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_32 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=32s", "174": "Built: 33 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "175": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_33 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=29s", "176": "Built: 34 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "177": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_34 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=17s, total=56s", "178": "Built: 35 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "179": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_35 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=31s", "180": "Built: 36 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "181": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_36 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=11s, total=37s", "182": "Built: 37 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "183": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_37 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=10s, total=35s", "184": "Built: 38 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "185": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_38 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=31s", "186": "Built: 39 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "187": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_39 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=29s", "188": "XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search] complete", "189": "Built: 40 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20221220_182507 [XGBoost Grid Search]", "190": "Adding model XGBoost_grid_1_AutoML_2_20221220_182507_model_40 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=2s, total=7s", "191": "Time assigned for GBM_grid_1_AutoML_2_20221220_182507: 1005.1451875s", "192": "AutoML: starting GBM_grid_1_AutoML_2_20221220_182507 hyperparameter search", "193": "GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search] started", "194": "Built: 1 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "195": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_1 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=29s", "196": "Built: 2 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "197": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_2 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=27s", "198": "Built: 3 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "199": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_3 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=35s", "200": "Built: 4 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "201": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_4 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=19s", "202": "Built: 5 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "203": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_5 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=29s", "204": "Built: 6 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "205": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_6 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=39s", "206": "Built: 7 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "207": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_7 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=28s", "208": "Built: 8 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "209": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_8 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=6s, total=25s", "210": "Built: 9 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "211": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_9 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=32s", "212": "Built: 10 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "213": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_10 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=11s, total=43s", "214": "Built: 11 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "215": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_11 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=6s, total=26s", "216": "Built: 12 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "217": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_12 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=10s, total=40s", "218": "Built: 13 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "219": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_13 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=20s", "220": "Built: 14 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "221": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_14 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=31s", "222": "Built: 15 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "223": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_15 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=37s", "224": "Built: 16 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "225": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_16 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=22s", "226": "Built: 17 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "227": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_17 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=6s, total=24s", "228": "Built: 18 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "229": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_18 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=39s", "230": "Built: 19 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "231": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_19 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=6s, total=23s", "232": "Built: 20 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "233": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_20 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=33s", "234": "Built: 21 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "235": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_21 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=9s, total=36s", "236": "Built: 22 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "237": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_22 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=4s, total=18s", "238": "Built: 23 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "239": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_23 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=26s", "240": "Built: 24 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "241": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_24 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=20s", "242": "Built: 25 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "243": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_25 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=6s, total=23s", "244": "Built: 26 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "245": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_26 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=29s", "246": "Built: 27 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "247": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_27 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=20s", "248": "Built: 28 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "249": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_28 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=22s", "250": "Built: 29 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "251": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_29 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=32s", "252": "Built: 30 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "253": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_30 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=10s, total=41s", "254": "Built: 31 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "255": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_31 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=27s", "256": "Built: 32 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "257": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_32 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=20s", "258": "Built: 33 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "259": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_33 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=27s", "260": "Built: 34 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "261": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_34 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=10s, total=39s", "262": "Built: 35 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "263": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_35 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=24s", "264": "GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search] complete", "265": "Built: 36 models for HyperparamSearch : GBM_grid_1_AutoML_2_20221220_182507 [GBM Grid Search]", "266": "Adding model GBM_grid_1_AutoML_2_20221220_182507_model_36 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=0s, total=3s", "267": "Time assigned for DeepLearning_grid_1_AutoML_2_20221220_182507: 501.982s", "268": "AutoML: starting DeepLearning_grid_1_AutoML_2_20221220_182507 hyperparameter search", "269": "DeepLearning_grid_1_AutoML_2_20221220_182507 [DeepLearning Grid Search] started", "270": "Built: 1 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20221220_182507 [DeepLearning Grid Search]", "271": "Adding model DeepLearning_grid_1_AutoML_2_20221220_182507_model_1 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=42s, total=242s", "272": "Built: 2 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20221220_182507 [DeepLearning Grid Search]", "273": "Adding model DeepLearning_grid_1_AutoML_2_20221220_182507_model_2 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=18s, total=137s", "274": "Built: 3 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20221220_182507 [DeepLearning Grid Search]", "275": "Adding model DeepLearning_grid_1_AutoML_2_20221220_182507_model_3 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=11s, total=84s", "276": "Built: 4 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20221220_182507 [DeepLearning Grid Search]", "277": "Adding model DeepLearning_grid_1_AutoML_2_20221220_182507_model_4 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=6s, total=37s", "278": "DeepLearning_grid_1_AutoML_2_20221220_182507 [DeepLearning Grid Search] complete", "279": "Built: 5 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20221220_182507 [DeepLearning Grid Search]", "280": "Adding model DeepLearning_grid_1_AutoML_2_20221220_182507_model_5 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=1s, total=3s", "281": "Time assigned for StackedEnsemble_BestOfFamily_4_AutoML_2_20221220_182507: 83.273s", "282": "AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_2_20221220_182507 model training", "283": "StackedEnsemble_BestOfFamily_4_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)] started", "284": "StackedEnsemble_BestOfFamily_4_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)] complete", "285": "Adding model StackedEnsemble_BestOfFamily_4_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=3s, total=3s", "286": "New leader: StackedEnsemble_BestOfFamily_4_AutoML_2_20221220_182507, auc: 0.9539058798651144", "287": "Time assigned for StackedEnsemble_AllModels_3_AutoML_2_20221220_182507: 246.916s", "288": "AutoML: starting StackedEnsemble_AllModels_3_AutoML_2_20221220_182507 model training", "289": "StackedEnsemble_AllModels_3_AutoML_2_20221220_182507 [StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)] started", "290": "StackedEnsemble_AllModels_3_AutoML_2_20221220_182507 [StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)] complete", "291": "Adding model StackedEnsemble_AllModels_3_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=7s, total=7s", "292": "New leader: StackedEnsemble_AllModels_3_AutoML_2_20221220_182507, auc: 0.9544493172358239", "293": "Time assigned for DeepLearning_grid_2_AutoML_2_20221220_182507: 95.818s", "294": "AutoML: starting DeepLearning_grid_2_AutoML_2_20221220_182507 hyperparameter search", "295": "DeepLearning_grid_2_AutoML_2_20221220_182507 [DeepLearning Grid Search] started", "296": "Built: 1 models for HyperparamSearch : DeepLearning_grid_2_AutoML_2_20221220_182507 [DeepLearning Grid Search]", "297": "Adding model DeepLearning_grid_2_AutoML_2_20221220_182507_model_1 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=14s, total=78s", "298": "DeepLearning_grid_2_AutoML_2_20221220_182507 [DeepLearning Grid Search] complete", "299": "Built: 2 models for HyperparamSearch : DeepLearning_grid_2_AutoML_2_20221220_182507 [DeepLearning Grid Search]", "300": "Adding model DeepLearning_grid_2_AutoML_2_20221220_182507_model_2 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=19s", "301": "Time assigned for DeepLearning_grid_3_AutoML_2_20221220_182507: 94.7153359375s", "302": "AutoML: starting DeepLearning_grid_3_AutoML_2_20221220_182507 hyperparameter search", "303": "DeepLearning_grid_3_AutoML_2_20221220_182507 [DeepLearning Grid Search] started", "304": "Built: 1 models for HyperparamSearch : DeepLearning_grid_3_AutoML_2_20221220_182507 [DeepLearning Grid Search]", "305": "Adding model DeepLearning_grid_3_AutoML_2_20221220_182507_model_1 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=13s, total=80s", "306": "DeepLearning_grid_3_AutoML_2_20221220_182507 [DeepLearning Grid Search] complete", "307": "Built: 2 models for HyperparamSearch : DeepLearning_grid_3_AutoML_2_20221220_182507 [DeepLearning Grid Search]", "308": "Adding model DeepLearning_grid_3_AutoML_2_20221220_182507_model_2 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=5s, total=19s", "309": "Time assigned for StackedEnsemble_AllModels_4_AutoML_2_20221220_182507: 43.267s", "310": "AutoML: starting StackedEnsemble_AllModels_4_AutoML_2_20221220_182507 model training", "311": "StackedEnsemble_AllModels_4_AutoML_2_20221220_182507 [StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)] started", "312": "StackedEnsemble_AllModels_4_AutoML_2_20221220_182507 [StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)] complete", "313": "Adding model StackedEnsemble_AllModels_4_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=8s, total=8s", "314": "New leader: StackedEnsemble_AllModels_4_AutoML_2_20221220_182507, auc: 0.9544502767687201", "315": "Time assigned for XGBoost_lr_search_selection_AutoML_2_20221220_182507: 6.16005908203125s", "316": "Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_2_20221220_182507_model_19", "317": "AutoML: starting XGBoost_lr_search_selection_AutoML_2_20221220_182507_select model training", "318": "XGBoost_lr_search_selection_AutoML_2_20221220_182507 [XGBoost lr_search] started", "319": "XGBoost_lr_search_selection_AutoML_2_20221220_182507 [XGBoost lr_search] complete", "320": "Time assigned for GBM_lr_annealing_selection_AutoML_2_20221220_182507: 1.999571533203125s", "321": "GBM_lr_annealing_selection_AutoML_2_20221220_182507 [GBM lr_annealing] started", "322": "Retraining best GBM with learning rate annealing: GBM_grid_1_AutoML_2_20221220_182507_model_8", "323": "AutoML: starting GBM_lr_annealing_selection_AutoML_2_20221220_182507_select_model model training", "324": "GBM_lr_annealing_selection_AutoML_2_20221220_182507 [GBM lr_annealing] complete", "325": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.", "326": "Time assigned for StackedEnsemble_BestOfFamily_5_AutoML_2_20221220_182507: 24.699s", "327": "AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_2_20221220_182507 model training", "328": "StackedEnsemble_BestOfFamily_5_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)] started", "329": "StackedEnsemble_BestOfFamily_5_AutoML_2_20221220_182507 [StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)] complete", "330": "Adding model StackedEnsemble_BestOfFamily_5_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=16s, total=16s", "331": "Time assigned for StackedEnsemble_AllModels_5_AutoML_2_20221220_182507: 8.347s", "332": "AutoML: starting StackedEnsemble_AllModels_5_AutoML_2_20221220_182507 model training", "333": "StackedEnsemble_AllModels_5_AutoML_2_20221220_182507 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)] started", "334": "AutoML: out of time; skipping StackedEnsemble_AllModels_5_AutoML_2_20221220_182507 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)]", "335": "AutoML: out of time; skipping StackedEnsemble_AllModels_5_AutoML_2_20221220_182507 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)]", "336": "AutoML: out of time; skipping StackedEnsemble_AllModels_5_AutoML_2_20221220_182507 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)]", "337": "AutoML: out of time; skipping StackedEnsemble_AllModels_5_AutoML_2_20221220_182507 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)]", "338": "StackedEnsemble_AllModels_5_AutoML_2_20221220_182507 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)] complete", "339": "Adding model StackedEnsemble_AllModels_5_AutoML_2_20221220_182507 to leaderboard Leaderboard_classification_test_2022-12-20T21.25.05@@went_on_backorder. Training time: model=13s, total=13s", "340": "AutoML: out of time; skipping StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)", "341": "AutoML: out of time; skipping StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)", "342": "AutoML: out of time; skipping completion resume_best_grids", "343": "AutoML: out of time; skipping StackedEnsemble best_of_family (built with AUTO metalearner, using top model from each algorithm type)", "344": "AutoML: out of time; skipping StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)", "345": "Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {StackedEnsemble : [best_of_family_gbm (6g, 10w), all_gbm (7g, 10w)]}]", "346": "AutoML build stopped: 2022.12.20 19:25:11.917", "347": "AutoML build done: built 97 models", "348": "AutoML duration:  1:00:04.488", "349": "Verifying training frame immutability. . .", "350": "Training frame was not mutated (as expected)."}, "name": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": "creation_epoch", "15": "start_epoch", "16": NaN, "17": "start_XGBoost_def_2", "18": NaN, "19": NaN, "20": NaN, "21": NaN, "22": NaN, "23": "start_GLM_def_1", "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": "start_GBM_def_5", "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": "start_StackedEnsemble_best_of_family_1", "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": NaN, "40": "start_XGBoost_def_1", "41": NaN, "42": NaN, "43": NaN, "44": NaN, "45": "start_DRF_def_1", "46": NaN, "47": NaN, "48": NaN, "49": NaN, "50": "start_GBM_def_2", "51": NaN, "52": NaN, "53": NaN, "54": NaN, "55": "start_GBM_def_3", "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": "start_GBM_def_4", "61": NaN, "62": NaN, "63": NaN, "64": NaN, "65": "start_StackedEnsemble_best_of_family_2", "66": NaN, "67": NaN, "68": NaN, "69": NaN, "70": NaN, "71": "start_StackedEnsemble_all_2", "72": NaN, "73": NaN, "74": NaN, "75": NaN, "76": "start_XGBoost_def_3", "77": NaN, "78": NaN, "79": NaN, "80": NaN, "81": "start_DRF_XRT", "82": NaN, "83": NaN, "84": NaN, "85": NaN, "86": "start_GBM_def_1", "87": NaN, "88": NaN, "89": NaN, "90": NaN, "91": "start_DeepLearning_def_1", "92": NaN, "93": NaN, "94": NaN, "95": NaN, "96": "start_StackedEnsemble_best_of_family_3", "97": NaN, "98": NaN, "99": NaN, "100": NaN, "101": NaN, "102": "start_StackedEnsemble_all_3", "103": NaN, "104": NaN, "105": NaN, "106": NaN, "107": NaN, "108": "start_XGBoost_grid_1", "109": NaN, "110": NaN, "111": NaN, "112": NaN, "113": NaN, "114": NaN, "115": NaN, "116": NaN, "117": NaN, "118": NaN, "119": NaN, "120": NaN, "121": NaN, "122": NaN, "123": NaN, "124": NaN, "125": NaN, "126": NaN, "127": NaN, "128": NaN, "129": NaN, "130": NaN, "131": NaN, "132": NaN, "133": NaN, "134": NaN, "135": NaN, "136": NaN, "137": NaN, "138": NaN, "139": NaN, "140": NaN, "141": NaN, "142": NaN, "143": NaN, "144": NaN, "145": NaN, "146": NaN, "147": NaN, "148": NaN, "149": NaN, "150": NaN, "151": NaN, "152": NaN, "153": NaN, "154": NaN, "155": NaN, "156": NaN, "157": NaN, "158": NaN, "159": NaN, "160": NaN, "161": NaN, "162": NaN, "163": NaN, "164": NaN, "165": NaN, "166": NaN, "167": NaN, "168": NaN, "169": NaN, "170": NaN, "171": NaN, "172": NaN, "173": NaN, "174": NaN, "175": NaN, "176": NaN, "177": NaN, "178": NaN, "179": NaN, "180": NaN, "181": NaN, "182": NaN, "183": NaN, "184": NaN, "185": NaN, "186": NaN, "187": NaN, "188": NaN, "189": NaN, "190": NaN, "191": NaN, "192": "start_GBM_grid_1", "193": NaN, "194": NaN, "195": NaN, "196": NaN, "197": NaN, "198": NaN, "199": NaN, "200": NaN, "201": NaN, "202": NaN, "203": NaN, "204": NaN, "205": NaN, "206": NaN, "207": NaN, "208": NaN, "209": NaN, "210": NaN, "211": NaN, "212": NaN, "213": NaN, "214": NaN, "215": NaN, "216": NaN, "217": NaN, "218": NaN, "219": NaN, "220": NaN, "221": NaN, "222": NaN, "223": NaN, "224": NaN, "225": NaN, "226": NaN, "227": NaN, "228": NaN, "229": NaN, "230": NaN, "231": NaN, "232": NaN, "233": NaN, "234": NaN, "235": NaN, "236": NaN, "237": NaN, "238": NaN, "239": NaN, "240": NaN, "241": NaN, "242": NaN, "243": NaN, "244": NaN, "245": NaN, "246": NaN, "247": NaN, "248": NaN, "249": NaN, "250": NaN, "251": NaN, "252": NaN, "253": NaN, "254": NaN, "255": NaN, "256": NaN, "257": NaN, "258": NaN, "259": NaN, "260": NaN, "261": NaN, "262": NaN, "263": NaN, "264": NaN, "265": NaN, "266": NaN, "267": NaN, "268": "start_DeepLearning_grid_1", "269": NaN, "270": NaN, "271": NaN, "272": NaN, "273": NaN, "274": NaN, "275": NaN, "276": NaN, "277": NaN, "278": NaN, "279": NaN, "280": NaN, "281": NaN, "282": "start_StackedEnsemble_best_of_family_4", "283": NaN, "284": NaN, "285": NaN, "286": NaN, "287": NaN, "288": "start_StackedEnsemble_all_4", "289": NaN, "290": NaN, "291": NaN, "292": NaN, "293": NaN, "294": "start_DeepLearning_grid_2", "295": NaN, "296": NaN, "297": NaN, "298": NaN, "299": NaN, "300": NaN, "301": NaN, "302": "start_DeepLearning_grid_3", "303": NaN, "304": NaN, "305": NaN, "306": NaN, "307": NaN, "308": NaN, "309": NaN, "310": "start_StackedEnsemble_all_5", "311": NaN, "312": NaN, "313": NaN, "314": NaN, "315": NaN, "316": NaN, "317": "start_XGBoost_lr_search", "318": NaN, "319": NaN, "320": NaN, "321": NaN, "322": NaN, "323": "start_GBM_lr_annealing", "324": NaN, "325": NaN, "326": NaN, "327": "start_StackedEnsemble_best_of_family_gbm", "328": NaN, "329": NaN, "330": NaN, "331": NaN, "332": "start_StackedEnsemble_all_gbm", "333": NaN, "334": NaN, "335": NaN, "336": NaN, "337": NaN, "338": NaN, "339": NaN, "340": NaN, "341": NaN, "342": NaN, "343": NaN, "344": NaN, "345": NaN, "346": "stop_epoch", "347": NaN, "348": "duration_secs", "349": NaN, "350": NaN}, "value": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": 1671560707.0, "15": 1671560707.0, "16": NaN, "17": 1671560707.0, "18": NaN, "19": NaN, "20": NaN, "21": NaN, "22": NaN, "23": 1671560736.0, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": 1671560742.0, "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": 1671560782.0, "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": NaN, "40": 1671560785.0, "41": NaN, "42": NaN, "43": NaN, "44": NaN, "45": 1671560814.0, "46": NaN, "47": NaN, "48": NaN, "49": NaN, "50": 1671560836.0, "51": NaN, "52": NaN, "53": NaN, "54": NaN, "55": 1671560869.0, "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": 1671560899.0, "61": NaN, "62": NaN, "63": NaN, "64": NaN, "65": 1671560933.0, "66": NaN, "67": NaN, "68": NaN, "69": NaN, "70": NaN, "71": 1671560936.0, "72": NaN, "73": NaN, "74": NaN, "75": NaN, "76": 1671560941.0, "77": NaN, "78": NaN, "79": NaN, "80": NaN, "81": 1671560973.0, "82": NaN, "83": NaN, "84": NaN, "85": NaN, "86": 1671560993.0, "87": NaN, "88": NaN, "89": NaN, "90": NaN, "91": 1671561024.0, "92": NaN, "93": NaN, "94": NaN, "95": NaN, "96": 1671561030.0, "97": NaN, "98": NaN, "99": NaN, "100": NaN, "101": NaN, "102": 1671561033.0, "103": NaN, "104": NaN, "105": NaN, "106": NaN, "107": NaN, "108": 1671561038.0, "109": NaN, "110": NaN, "111": NaN, "112": NaN, "113": NaN, "114": NaN, "115": NaN, "116": NaN, "117": NaN, "118": NaN, "119": NaN, "120": NaN, "121": NaN, "122": NaN, "123": NaN, "124": NaN, "125": NaN, "126": NaN, "127": NaN, "128": NaN, "129": NaN, "130": NaN, "131": NaN, "132": NaN, "133": NaN, "134": NaN, "135": NaN, "136": NaN, "137": NaN, "138": NaN, "139": NaN, "140": NaN, "141": NaN, "142": NaN, "143": NaN, "144": NaN, "145": NaN, "146": NaN, "147": NaN, "148": NaN, "149": NaN, "150": NaN, "151": NaN, "152": NaN, "153": NaN, "154": NaN, "155": NaN, "156": NaN, "157": NaN, "158": NaN, "159": NaN, "160": NaN, "161": NaN, "162": NaN, "163": NaN, "164": NaN, "165": NaN, "166": NaN, "167": NaN, "168": NaN, "169": NaN, "170": NaN, "171": NaN, "172": NaN, "173": NaN, "174": NaN, "175": NaN, "176": NaN, "177": NaN, "178": NaN, "179": NaN, "180": NaN, "181": NaN, "182": NaN, "183": NaN, "184": NaN, "185": NaN, "186": NaN, "187": NaN, "188": NaN, "189": NaN, "190": NaN, "191": NaN, "192": 1671562548.0, "193": NaN, "194": NaN, "195": NaN, "196": NaN, "197": NaN, "198": NaN, "199": NaN, "200": NaN, "201": NaN, "202": NaN, "203": NaN, "204": NaN, "205": NaN, "206": NaN, "207": NaN, "208": NaN, "209": NaN, "210": NaN, "211": NaN, "212": NaN, "213": NaN, "214": NaN, "215": NaN, "216": NaN, "217": NaN, "218": NaN, "219": NaN, "220": NaN, "221": NaN, "222": NaN, "223": NaN, "224": NaN, "225": NaN, "226": NaN, "227": NaN, "228": NaN, "229": NaN, "230": NaN, "231": NaN, "232": NaN, "233": NaN, "234": NaN, "235": NaN, "236": NaN, "237": NaN, "238": NaN, "239": NaN, "240": NaN, "241": NaN, "242": NaN, "243": NaN, "244": NaN, "245": NaN, "246": NaN, "247": NaN, "248": NaN, "249": NaN, "250": NaN, "251": NaN, "252": NaN, "253": NaN, "254": NaN, "255": NaN, "256": NaN, "257": NaN, "258": NaN, "259": NaN, "260": NaN, "261": NaN, "262": NaN, "263": NaN, "264": NaN, "265": NaN, "266": NaN, "267": NaN, "268": 1671563554.0, "269": NaN, "270": NaN, "271": NaN, "272": NaN, "273": NaN, "274": NaN, "275": NaN, "276": NaN, "277": NaN, "278": NaN, "279": NaN, "280": NaN, "281": NaN, "282": 1671564058.0, "283": NaN, "284": NaN, "285": NaN, "286": NaN, "287": NaN, "288": 1671564061.0, "289": NaN, "290": NaN, "291": NaN, "292": NaN, "293": NaN, "294": 1671564068.0, "295": NaN, "296": NaN, "297": NaN, "298": NaN, "299": NaN, "300": NaN, "301": NaN, "302": 1671564165.0, "303": NaN, "304": NaN, "305": NaN, "306": NaN, "307": NaN, "308": NaN, "309": NaN, "310": 1671564264.0, "311": NaN, "312": NaN, "313": NaN, "314": NaN, "315": NaN, "316": NaN, "317": 1671564273.0, "318": NaN, "319": NaN, "320": NaN, "321": NaN, "322": NaN, "323": 1671564279.0, "324": NaN, "325": NaN, "326": NaN, "327": 1671564283.0, "328": NaN, "329": NaN, "330": NaN, "331": NaN, "332": 1671564299.0, "333": NaN, "334": NaN, "335": NaN, "336": NaN, "337": NaN, "338": NaN, "339": NaN, "340": NaN, "341": NaN, "342": NaN, "343": NaN, "344": NaN, "345": NaN, "346": 1671564312.0, "347": NaN, "348": 3604.0, "349": NaN, "350": NaN}}}]