[{"experiment": "classification_1", "max_runtime_secs": 1800, "max_models": null, "include_algos": ["DRF"], "start_time": "2022-12-21 03:02:47.759189", "end_time": "2022-12-21 03:03:32.611997", "elapsed_time": "0:00:44.852808", "leaderboard": {"model_id": {"0": "XRT_1_AutoML_11_20221221_00249", "1": "DRF_1_AutoML_11_20221221_00249"}, "auc": {"0": 0.9424266592203407, "1": 0.9351830796652582}, "logloss": {"0": 0.2049380953296828, "1": 0.2178022354076629}, "aucpr": {"0": 0.7231785391818483, "1": 0.6968698145800235}, "mean_per_class_error": {"0": 0.1634977282204303, "1": 0.1898928614485497}, "rmse": {"0": 0.2428400529996625, "1": 0.2524300254743769}, "mse": {"0": 0.0589712913408789, "1": 0.0637209177609945}}, "event_log": {"timestamp": {"0": "00:02:49.129", "1": "00:02:49.129", "2": "00:02:49.129", "3": "00:02:49.129", "4": "00:02:49.131", "5": "00:02:49.131", "6": "00:02:49.131", "7": "00:02:49.131", "8": "00:02:49.131", "9": "00:02:49.131", "10": "00:02:49.131", "11": "00:02:49.133", "12": "00:02:49.134", "13": "00:02:49.134", "14": "00:02:49.134", "15": "00:02:49.134", "16": "00:02:49.134", "17": "00:02:49.134", "18": "00:02:49.134", "19": "00:02:49.135", "20": "00:02:49.137", "21": "00:02:49.137", "22": "00:02:49.141", "23": "00:02:49.141", "24": "00:02:49.144", "25": "00:03:10.333", "26": "00:03:10.333", "27": "00:03:10.340", "28": "00:03:10.341", "29": "00:03:10.341", "30": "00:03:10.344", "31": "00:03:10.344", "32": "00:03:10.349", "33": "00:03:28.622", "34": "00:03:28.622", "35": "00:03:28.628", "36": "00:03:28.629", "37": "00:03:28.629", "38": "00:03:28.630", "39": "00:03:28.630", "40": "00:03:28.630", "41": "00:03:28.630", "42": "00:03:28.630", "43": "00:03:28.631", "44": "00:03:28.631", "45": "00:03:28.631", "46": "00:03:28.631", "47": "00:03:28.632", "48": "00:03:28.632", "49": "00:03:28.632", "50": "00:03:28.632", "51": "00:03:28.632", "52": "00:03:28.632", "53": "00:03:28.637", "54": "00:03:28.637"}, "level": {"0": "INFO", "1": "INFO", "2": "INFO", "3": "INFO", "4": "INFO", "5": "INFO", "6": "INFO", "7": "INFO", "8": "INFO", "9": "INFO", "10": "INFO", "11": "INFO", "12": "INFO", "13": "INFO", "14": "INFO", "15": "INFO", "16": "INFO", "17": "DEBUG", "18": "DEBUG", "19": "INFO", "20": "INFO", "21": "INFO", "22": "DEBUG", "23": "INFO", "24": "DEBUG", "25": "DEBUG", "26": "DEBUG", "27": "INFO", "28": "INFO", "29": "INFO", "30": "DEBUG", "31": "INFO", "32": "DEBUG", "33": "DEBUG", "34": "DEBUG", "35": "INFO", "36": "INFO", "37": "INFO", "38": "INFO", "39": "INFO", "40": "INFO", "41": "INFO", "42": "INFO", "43": "INFO", "44": "INFO", "45": "INFO", "46": "INFO", "47": "INFO", "48": "INFO", "49": "INFO", "50": "INFO", "51": "INFO", "52": "INFO", "53": "DEBUG", "54": "DEBUG"}, "stage": {"0": "Workflow", "1": "Validation", "2": "Validation", "3": "Validation", "4": "DataImport", "5": "DataImport", "6": "DataImport", "7": "DataImport", "8": "DataImport", "9": "DataImport", "10": "DataImport", "11": "Workflow", "12": "Workflow", "13": "Workflow", "14": "Workflow", "15": "Workflow", "16": "Workflow", "17": "Workflow", "18": "Workflow", "19": "Workflow", "20": "Workflow", "21": "ModelTraining", "22": "ModelTraining", "23": "ModelTraining", "24": "ModelTraining", "25": "ModelTraining", "26": "ModelTraining", "27": "ModelTraining", "28": "ModelTraining", "29": "ModelTraining", "30": "ModelTraining", "31": "ModelTraining", "32": "ModelTraining", "33": "ModelTraining", "34": "ModelTraining", "35": "ModelTraining", "36": "ModelTraining", "37": "ModelTraining", "38": "ModelTraining", "39": "ModelTraining", "40": "ModelTraining", "41": "ModelTraining", "42": "ModelTraining", "43": "ModelTraining", "44": "ModelTraining", "45": "ModelTraining", "46": "ModelTraining", "47": "ModelTraining", "48": "ModelTraining", "49": "Workflow", "50": "Workflow", "51": "Workflow", "52": "Workflow", "53": "Workflow", "54": "Workflow"}, "message": {"0": "Project: classification_test_2022-12-21T03.02.47", "1": "5-fold cross-validation will be used.", "2": "Setting stopping tolerance adaptively based on the training frame: 0.00724466513640519", "3": "Build control seed: -1 (random)", "4": "training frame: Frame key: AutoML_11_20221221_00249_training_product_backorders4.hex    cols: 23    rows: 19053  chunks: 48    size: 896711  checksum: 340006888695133344", "5": "validation frame: NULL", "6": "leaderboard frame: NULL", "7": "blending frame: NULL", "8": "response column: went_on_backorder", "9": "fold column: null", "10": "weights column: null", "11": "Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]", "12": "Disabling Algo: StackedEnsemble as requested by the user.", "13": "Disabling Algo: DeepLearning as requested by the user.", "14": "Disabling Algo: GLM as requested by the user.", "15": "Disabling Algo: GBM as requested by the user.", "16": "Disabling Algo: XGBoost as requested by the user.", "17": "Defined work allocations: [Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "18": "Actual work allocations: [Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "19": "AutoML job created: 2022.12.21 00:02:49.127", "20": "AutoML build started: 2022.12.21 00:02:49.137", "21": "Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.", "22": "Time assigned for DRF_1_AutoML_11_20221221_00249: 1799.996s", "23": "AutoML: starting DRF_1_AutoML_11_20221221_00249 model training", "24": "DRF_1_AutoML_11_20221221_00249 [DRF def_1] started", "25": "DRF_1_AutoML_11_20221221_00249 [DRF def_1] complete", "26": "Adding model DRF_1_AutoML_11_20221221_00249 to leaderboard Leaderboard_classification_test_2022-12-21T03.02.47@@went_on_backorder. Training time: model=5s, total=21s", "27": "New leader: DRF_1_AutoML_11_20221221_00249, auc: 0.9351830796652582", "28": "Skipping StackedEnsemble 'best_of_family_2' due to the exclude_algos option or it is already trained.", "29": "Skipping StackedEnsemble 'all_2' due to the exclude_algos option or it is already trained.", "30": "Time assigned for XRT_1_AutoML_11_20221221_00249: 1778.793s", "31": "AutoML: starting XRT_1_AutoML_11_20221221_00249 model training", "32": "XRT_1_AutoML_11_20221221_00249 [DRF XRT (Extremely Randomized Trees)] started", "33": "XRT_1_AutoML_11_20221221_00249 [DRF XRT (Extremely Randomized Trees)] complete", "34": "Adding model XRT_1_AutoML_11_20221221_00249 to leaderboard Leaderboard_classification_test_2022-12-21T03.02.47@@went_on_backorder. Training time: model=4s, total=18s", "35": "New leader: XRT_1_AutoML_11_20221221_00249, auc: 0.9424266592203409", "36": "Skipping StackedEnsemble 'best_of_family_3' due to the exclude_algos option or it is already trained.", "37": "Skipping StackedEnsemble 'all_3' due to the exclude_algos option or it is already trained.", "38": "Skipping StackedEnsemble 'best_of_family_4' due to the exclude_algos option or it is already trained.", "39": "Skipping StackedEnsemble 'all_4' due to the exclude_algos option or it is already trained.", "40": "Skipping StackedEnsemble 'best_of_family_5' due to the exclude_algos option or it is already trained.", "41": "Skipping StackedEnsemble 'all_5' due to the exclude_algos option or it is already trained.", "42": "Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.", "43": "Skipping StackedEnsemble 'best_of_family_gbm' due to the exclude_algos option or it is already trained.", "44": "Skipping StackedEnsemble 'all_gbm' due to the exclude_algos option or it is already trained.", "45": "Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.", "46": "Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.", "47": "Skipping StackedEnsemble 'best_of_family' due to the exclude_algos option or it is already trained.", "48": "Skipping StackedEnsemble 'best_N' due to the exclude_algos option or it is already trained.", "49": "Actual modeling steps: [{DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}]", "50": "AutoML build stopped: 2022.12.21 00:03:28.632", "51": "AutoML build done: built 2 models", "52": "AutoML duration: 39.495 sec", "53": "Verifying training frame immutability. . .", "54": "Training frame was not mutated (as expected)."}, "name": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": "creation_epoch", "20": "start_epoch", "21": NaN, "22": NaN, "23": "start_DRF_def_1", "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": NaN, "30": NaN, "31": "start_DRF_XRT", "32": NaN, "33": NaN, "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": NaN, "45": NaN, "46": NaN, "47": NaN, "48": NaN, "49": NaN, "50": "stop_epoch", "51": NaN, "52": "duration_secs", "53": NaN, "54": NaN}, "value": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": 1671580969.0, "20": 1671580969.0, "21": NaN, "22": NaN, "23": 1671580969.0, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": NaN, "30": NaN, "31": 1671580990.0, "32": NaN, "33": NaN, "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": NaN, "45": NaN, "46": NaN, "47": NaN, "48": NaN, "49": NaN, "50": 1671581009.0, "51": NaN, "52": 39.0, "53": NaN, "54": NaN}}}, {"experiment": "classification_1", "max_runtime_secs": 1800, "max_models": null, "include_algos": ["GLM"], "start_time": "2022-12-21 03:03:34.789756", "end_time": "2022-12-21 03:03:43.557327", "elapsed_time": "0:00:08.767571", "leaderboard": {"model_id": {"0": "GLM_1_AutoML_12_20221221_00336"}, "auc": {"0": 0.756076090906094}, "logloss": {"0": 0.3349978161674908}, "aucpr": {"0": 0.2823348254100117}, "mean_per_class_error": {"0": 0.2880286809377512}, "rmse": {"0": 0.312796262456043}, "mse": {"0": 0.0978415018064697}}, "event_log": {"timestamp": {"0": "00:03:36.159", "1": "00:03:36.160", "2": "00:03:36.160", "3": "00:03:36.160", "4": "00:03:36.160", "5": "00:03:36.160", "6": "00:03:36.160", "7": "00:03:36.160", "8": "00:03:36.160", "9": "00:03:36.160", "10": "00:03:36.160", "11": "00:03:36.163", "12": "00:03:36.163", "13": "00:03:36.163", "14": "00:03:36.163", "15": "00:03:36.164", "16": "00:03:36.164", "17": "00:03:36.164", "18": "00:03:36.164", "19": "00:03:36.164", "20": "00:03:36.165", "21": "00:03:36.167", "22": "00:03:36.168", "23": "00:03:36.171", "24": "00:03:40.582", "25": "00:03:40.582", "26": "00:03:40.588", "27": "00:03:40.589", "28": "00:03:40.590", "29": "00:03:40.590", "30": "00:03:40.590", "31": "00:03:40.590", "32": "00:03:40.590", "33": "00:03:40.591", "34": "00:03:40.591", "35": "00:03:40.591", "36": "00:03:40.591", "37": "00:03:40.591", "38": "00:03:40.591", "39": "00:03:40.592", "40": "00:03:40.592", "41": "00:03:40.592", "42": "00:03:40.592", "43": "00:03:40.592", "44": "00:03:40.592", "45": "00:03:40.592", "46": "00:03:40.593", "47": "00:03:40.595", "48": "00:03:40.595"}, "level": {"0": "INFO", "1": "INFO", "2": "INFO", "3": "INFO", "4": "INFO", "5": "INFO", "6": "INFO", "7": "INFO", "8": "INFO", "9": "INFO", "10": "INFO", "11": "INFO", "12": "INFO", "13": "INFO", "14": "INFO", "15": "INFO", "16": "INFO", "17": "DEBUG", "18": "DEBUG", "19": "INFO", "20": "INFO", "21": "DEBUG", "22": "INFO", "23": "DEBUG", "24": "DEBUG", "25": "DEBUG", "26": "INFO", "27": "INFO", "28": "INFO", "29": "INFO", "30": "INFO", "31": "INFO", "32": "INFO", "33": "INFO", "34": "INFO", "35": "INFO", "36": "INFO", "37": "INFO", "38": "INFO", "39": "INFO", "40": "INFO", "41": "INFO", "42": "INFO", "43": "INFO", "44": "INFO", "45": "INFO", "46": "INFO", "47": "DEBUG", "48": "DEBUG"}, "stage": {"0": "Workflow", "1": "Validation", "2": "Validation", "3": "Validation", "4": "DataImport", "5": "DataImport", "6": "DataImport", "7": "DataImport", "8": "DataImport", "9": "DataImport", "10": "DataImport", "11": "Workflow", "12": "Workflow", "13": "Workflow", "14": "Workflow", "15": "Workflow", "16": "Workflow", "17": "Workflow", "18": "Workflow", "19": "Workflow", "20": "Workflow", "21": "ModelTraining", "22": "ModelTraining", "23": "ModelTraining", "24": "ModelTraining", "25": "ModelTraining", "26": "ModelTraining", "27": "ModelTraining", "28": "ModelTraining", "29": "ModelTraining", "30": "ModelTraining", "31": "ModelTraining", "32": "ModelTraining", "33": "ModelTraining", "34": "ModelTraining", "35": "ModelTraining", "36": "ModelTraining", "37": "ModelTraining", "38": "ModelTraining", "39": "ModelTraining", "40": "ModelTraining", "41": "ModelTraining", "42": "ModelTraining", "43": "Workflow", "44": "Workflow", "45": "Workflow", "46": "Workflow", "47": "Workflow", "48": "Workflow"}, "message": {"0": "Project: classification_test_2022-12-21T03.03.34", "1": "5-fold cross-validation will be used.", "2": "Setting stopping tolerance adaptively based on the training frame: 0.00724466513640519", "3": "Build control seed: -1 (random)", "4": "training frame: Frame key: AutoML_12_20221221_00336_training_product_backorders5.hex    cols: 23    rows: 19053  chunks: 48    size: 896711  checksum: 340006888695133344", "5": "validation frame: NULL", "6": "leaderboard frame: NULL", "7": "blending frame: NULL", "8": "response column: went_on_backorder", "9": "fold column: null", "10": "weights column: null", "11": "Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]", "12": "Disabling Algo: StackedEnsemble as requested by the user.", "13": "Disabling Algo: DeepLearning as requested by the user.", "14": "Disabling Algo: DRF as requested by the user.", "15": "Disabling Algo: GBM as requested by the user.", "16": "Disabling Algo: XGBoost as requested by the user.", "17": "Defined work allocations: [Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "18": "Actual work allocations: [Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "19": "AutoML job created: 2022.12.21 00:03:36.159", "20": "AutoML build started: 2022.12.21 00:03:36.165", "21": "Time assigned for GLM_1_AutoML_12_20221221_00336: 1799.998s", "22": "AutoML: starting GLM_1_AutoML_12_20221221_00336 model training", "23": "GLM_1_AutoML_12_20221221_00336 [GLM def_1] started", "24": "GLM_1_AutoML_12_20221221_00336 [GLM def_1] complete", "25": "Adding model GLM_1_AutoML_12_20221221_00336 to leaderboard Leaderboard_classification_test_2022-12-21T03.03.34@@went_on_backorder. Training time: model=1s, total=4s", "26": "New leader: GLM_1_AutoML_12_20221221_00336, auc: 0.756076090906094", "27": "Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.", "28": "Skipping StackedEnsemble 'best_of_family_2' due to the exclude_algos option or it is already trained.", "29": "Skipping StackedEnsemble 'all_2' due to the exclude_algos option or it is already trained.", "30": "Skipping StackedEnsemble 'best_of_family_3' due to the exclude_algos option or it is already trained.", "31": "Skipping StackedEnsemble 'all_3' due to the exclude_algos option or it is already trained.", "32": "Skipping StackedEnsemble 'best_of_family_4' due to the exclude_algos option or it is already trained.", "33": "Skipping StackedEnsemble 'all_4' due to the exclude_algos option or it is already trained.", "34": "Skipping StackedEnsemble 'best_of_family_5' due to the exclude_algos option or it is already trained.", "35": "Skipping StackedEnsemble 'all_5' due to the exclude_algos option or it is already trained.", "36": "Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.", "37": "Skipping StackedEnsemble 'best_of_family_gbm' due to the exclude_algos option or it is already trained.", "38": "Skipping StackedEnsemble 'all_gbm' due to the exclude_algos option or it is already trained.", "39": "Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.", "40": "Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.", "41": "Skipping StackedEnsemble 'best_of_family' due to the exclude_algos option or it is already trained.", "42": "Skipping StackedEnsemble 'best_N' due to the exclude_algos option or it is already trained.", "43": "Actual modeling steps: [{GLM : [def_1 (1g, 10w)]}]", "44": "AutoML build stopped: 2022.12.21 00:03:40.592", "45": "AutoML build done: built 1 models", "46": "AutoML duration:  4.427 sec", "47": "Verifying training frame immutability. . .", "48": "Training frame was not mutated (as expected)."}, "name": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": "creation_epoch", "20": "start_epoch", "21": NaN, "22": "start_GLM_def_1", "23": NaN, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": "stop_epoch", "45": NaN, "46": "duration_secs", "47": NaN, "48": NaN}, "value": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": 1671581016.0, "20": 1671581016.0, "21": NaN, "22": 1671581016.0, "23": NaN, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": 1671581021.0, "45": NaN, "46": 4.0, "47": NaN, "48": NaN}}}, {"experiment": "classification_1", "max_runtime_secs": 1800, "max_models": null, "include_algos": ["XGBoost"], "start_time": "2022-12-21 03:04:51.774561", "end_time": "2022-12-21 03:34:57.470579", "elapsed_time": "0:30:05.696018", "leaderboard": {"model_id": {"0": "XGBoost_grid_1_AutoML_13_20221221_00453_model_3", "1": "XGBoost_grid_1_AutoML_13_20221221_00453_model_19", "2": "XGBoost_grid_1_AutoML_13_20221221_00453_model_36", "3": "XGBoost_grid_1_AutoML_13_20221221_00453_model_8", "4": "XGBoost_grid_1_AutoML_13_20221221_00453_model_23", "5": "XGBoost_grid_1_AutoML_13_20221221_00453_model_31", "6": "XGBoost_grid_1_AutoML_13_20221221_00453_model_10", "7": "XGBoost_grid_1_AutoML_13_20221221_00453_model_40", "8": "XGBoost_grid_1_AutoML_13_20221221_00453_model_28", "9": "XGBoost_grid_1_AutoML_13_20221221_00453_model_24", "10": "XGBoost_grid_1_AutoML_13_20221221_00453_model_17", "11": "XGBoost_grid_1_AutoML_13_20221221_00453_model_48", "12": "XGBoost_grid_1_AutoML_13_20221221_00453_model_22", "13": "XGBoost_grid_1_AutoML_13_20221221_00453_model_34", "14": "XGBoost_grid_1_AutoML_13_20221221_00453_model_11", "15": "XGBoost_grid_1_AutoML_13_20221221_00453_model_46", "16": "XGBoost_grid_1_AutoML_13_20221221_00453_model_5", "17": "XGBoost_grid_1_AutoML_13_20221221_00453_model_41", "18": "XGBoost_grid_1_AutoML_13_20221221_00453_model_29", "19": "XGBoost_3_AutoML_13_20221221_00453", "20": "XGBoost_grid_1_AutoML_13_20221221_00453_model_26", "21": "XGBoost_grid_1_AutoML_13_20221221_00453_model_37", "22": "XGBoost_grid_1_AutoML_13_20221221_00453_model_15", "23": "XGBoost_grid_1_AutoML_13_20221221_00453_model_42", "24": "XGBoost_grid_1_AutoML_13_20221221_00453_model_1", "25": "XGBoost_grid_1_AutoML_13_20221221_00453_model_7", "26": "XGBoost_grid_1_AutoML_13_20221221_00453_model_20", "27": "XGBoost_grid_1_AutoML_13_20221221_00453_model_33", "28": "XGBoost_grid_1_AutoML_13_20221221_00453_model_47", "29": "XGBoost_grid_1_AutoML_13_20221221_00453_model_14", "30": "XGBoost_grid_1_AutoML_13_20221221_00453_model_39", "31": "XGBoost_grid_1_AutoML_13_20221221_00453_model_2", "32": "XGBoost_grid_1_AutoML_13_20221221_00453_model_16", "33": "XGBoost_grid_1_AutoML_13_20221221_00453_model_4", "34": "XGBoost_grid_1_AutoML_13_20221221_00453_model_38", "35": "XGBoost_grid_1_AutoML_13_20221221_00453_model_35", "36": "XGBoost_1_AutoML_13_20221221_00453", "37": "XGBoost_grid_1_AutoML_13_20221221_00453_model_45", "38": "XGBoost_grid_1_AutoML_13_20221221_00453_model_21", "39": "XGBoost_grid_1_AutoML_13_20221221_00453_model_30", "40": "XGBoost_grid_1_AutoML_13_20221221_00453_model_6", "41": "XGBoost_2_AutoML_13_20221221_00453", "42": "XGBoost_grid_1_AutoML_13_20221221_00453_model_43", "43": "XGBoost_grid_1_AutoML_13_20221221_00453_model_32", "44": "XGBoost_grid_1_AutoML_13_20221221_00453_model_13", "45": "XGBoost_grid_1_AutoML_13_20221221_00453_model_12", "46": "XGBoost_grid_1_AutoML_13_20221221_00453_model_44", "47": "XGBoost_grid_1_AutoML_13_20221221_00453_model_25", "48": "XGBoost_grid_1_AutoML_13_20221221_00453_model_9", "49": "XGBoost_grid_1_AutoML_13_20221221_00453_model_27", "50": "XGBoost_grid_1_AutoML_13_20221221_00453_model_18"}, "auc": {"0": 0.9493336136045676, "1": 0.9488515206177855, "2": 0.9484229643088988, "3": 0.948040242126165, "4": 0.9480401632604476, "5": 0.9478684725934534, "6": 0.947617666467522, "7": 0.947241726736493, "8": 0.9470332977894308, "9": 0.9468657475726052, "10": 0.9468333206184272, "11": 0.946794531829704, "12": 0.9467392995388826, "13": 0.9464787666411264, "14": 0.9464029898308968, "15": 0.9463376495839492, "16": 0.9462972046151586, "17": 0.9461255665253094, "18": 0.9460889071109588, "19": 0.9460793117819968, "20": 0.9459432158421668, "21": 0.9459419539906868, "22": 0.9459392725562918, "23": 0.945807225056627, "24": 0.9457701581694028, "25": 0.9454511200535488, "26": 0.945439973698809, "27": 0.9454134222405846, "28": 0.9453083862491628, "29": 0.9452694134404322, "30": 0.9451695825863656, "31": 0.9451103807210964, "32": 0.9450878382701784, "33": 0.9450423984726128, "34": 0.9449858911860252, "35": 0.9448006487599075, "36": 0.944756983440986, "37": 0.9447518703136348, "38": 0.9446516451309804, "39": 0.9445863968940368, "40": 0.9445734497720808, "41": 0.9443345523694916, "42": 0.9442417142757096, "43": 0.9442115612830528, "44": 0.9441580377494436, "45": 0.9435806092544924, "46": 0.9429795210442914, "47": 0.9428028486928086, "48": 0.9427494040249172, "49": 0.9425808548423366, "50": 0.9425710097719356}, "logloss": {"0": 0.1725193405096632, "1": 0.1730075692717361, "2": 0.1744662028070834, "3": 0.179158523658446, "4": 0.1750721820424488, "5": 0.1815437393159863, "6": 0.1750328105394384, "7": 0.1755264915825089, "8": 0.1743051263206763, "9": 0.1805687673164568, "10": 0.1748988784398154, "11": 0.1751151093097419, "12": 0.1841284460047889, "13": 0.1757515450408797, "14": 0.1772813567172315, "15": 0.184148278709716, "16": 0.1760763978264074, "17": 0.1780332286120484, "18": 0.1761536694914331, "19": 0.1764181757926609, "20": 0.1759037855761826, "21": 0.177178436300662, "22": 0.18678581351916, "23": 0.1785903125554198, "24": 0.1776712033469172, "25": 0.1782333653907982, "26": 0.1795293683953641, "27": 0.1793729005958397, "28": 0.1809118682662648, "29": 0.1793985543514337, "30": 0.1767275414176797, "31": 0.1783083338355557, "32": 0.1768107552345081, "33": 0.1878730043264774, "34": 0.1773275982692058, "35": 0.1818336694483148, "36": 0.1805379740899978, "37": 0.178007828982541, "38": 0.1805992065064824, "39": 0.1793609647936399, "40": 0.1790499903817885, "41": 0.1814349571448759, "42": 0.1785384476477404, "43": 0.1787807753585143, "44": 0.1941848345536017, "45": 0.1794356504219682, "46": 0.1870758400056305, "47": 0.1808689430114936, "48": 0.1802561960476187, "49": 0.1813628294371025, "50": 0.1829017048724755}, "aucpr": {"0": 0.7479712755812304, "1": 0.7430965207937175, "2": 0.7379614545621931, "3": 0.7415495424441542, "4": 0.7392637432334981, "5": 0.7430087618118119, "6": 0.7374670945038748, "7": 0.7355671910909679, "8": 0.7425865151224732, "9": 0.7312471314529785, "10": 0.7429849337298822, "11": 0.7405076238210315, "12": 0.7300890908788729, "13": 0.7348902400087526, "14": 0.7371230725407307, "15": 0.7346842240225777, "16": 0.7359172513572545, "17": 0.7310022878649929, "18": 0.7402308348990105, "19": 0.7378736537503787, "20": 0.7335517108704263, "21": 0.732750878375706, "22": 0.7307141605528621, "23": 0.7251883347898802, "24": 0.7281865169537036, "25": 0.7272382775921976, "26": 0.7371431808029744, "27": 0.7382341655570137, "28": 0.7298253742866119, "29": 0.729057257914652, "30": 0.7375778129155363, "31": 0.7296112558091992, "32": 0.7335609731745751, "33": 0.7322661284894155, "34": 0.7334102637112793, "35": 0.7343096558435306, "36": 0.7279809700161901, "37": 0.7300794485325515, "38": 0.7210933127879554, "39": 0.7233685084416432, "40": 0.7277013260223296, "41": 0.726225471740072, "42": 0.7274297706212549, "43": 0.7285300961236291, "44": 0.7235901240165684, "45": 0.7262852325190465, "46": 0.7195966866745069, "47": 0.7216460506798807, "48": 0.7226629887713469, "49": 0.7208809997357504, "50": 0.7222483049606937}, "mean_per_class_error": {"0": 0.1581826257667653, "1": 0.1630218130481857, "2": 0.1597867676049706, "3": 0.1519137607585325, "4": 0.1535288386428976, "5": 0.1596512237251632, "6": 0.1478301333393201, "7": 0.1608304633660592, "8": 0.1583668035056968, "9": 0.158277448647771, "10": 0.1706200648791453, "11": 0.1602700172889426, "12": 0.1599125978572395, "13": 0.1731621435512738, "14": 0.1596177715166576, "15": 0.1608371538077604, "16": 0.1667011879437872, "17": 0.1530388985172246, "18": 0.1553062221738746, "19": 0.1639493921845441, "20": 0.1726302600081778, "21": 0.1648180454856448, "22": 0.1635974407759209, "23": 0.1546770709125305, "24": 0.1639682410910262, "25": 0.1580932709088396, "26": 0.1486744697108588, "27": 0.1452935226902715, "28": 0.1517666367625391, "29": 0.164777902835438, "30": 0.1491552745575882, "31": 0.1630667796514461, "32": 0.1575723234119034, "33": 0.1584859433162645, "34": 0.1563122201219989, "35": 0.1633184401559837, "36": 0.1750507540324961, "37": 0.1762135896041524, "38": 0.1632321084838954, "39": 0.1608699619462397, "40": 0.1725086753603677, "41": 0.170170845752274, "42": 0.1547257047716545, "43": 0.1622668315345728, "44": 0.1671400493730938, "45": 0.1641986078518393, "46": 0.1648806385767661, "47": 0.1550508944134733, "48": 0.1559888312473964, "49": 0.1573291541162831, "50": 0.1714242586004773}, "rmse": {"0": 0.2251786888311738, "1": 0.2257410064590856, "2": 0.2269564721955441, "3": 0.227431884664624, "4": 0.2277405650946682, "5": 0.2276953216949129, "6": 0.2272711085655883, "7": 0.2275618019840106, "8": 0.2264743337142899, "9": 0.2289649419628287, "10": 0.227202257881026, "11": 0.2272746336071147, "12": 0.2307783629831012, "13": 0.2271180873616938, "14": 0.2283761191721815, "15": 0.2293675702123155, "16": 0.2274414719129613, "17": 0.2283745960623765, "18": 0.2280732105219672, "19": 0.2282089311762816, "20": 0.2271073291334502, "21": 0.227531932873018, "22": 0.2310483167179424, "23": 0.2297437988946958, "24": 0.2290552670441668, "25": 0.2286664332949994, "26": 0.2276530566739504, "27": 0.2295971835057334, "28": 0.2300685329085124, "29": 0.2301401164320507, "30": 0.2281281628162253, "31": 0.2289036427885105, "32": 0.2280870744817489, "33": 0.230874573957497, "34": 0.2286033436676149, "35": 0.2293414596270401, "36": 0.231217957858334, "37": 0.2290015478808849, "38": 0.2308055794035163, "39": 0.2299683790090314, "40": 0.229916076404234, "41": 0.2306075447972153, "42": 0.229296967909862, "43": 0.2292723739322558, "44": 0.2343293385979044, "45": 0.22976980840768, "46": 0.2325831348484895, "47": 0.2308621472952269, "48": 0.2303581931830817, "49": 0.2311498274224378, "50": 0.2310480614686547}, "mse": {"0": 0.0507054419037266, "1": 0.0509590019971609, "2": 0.0515092402714468, "3": 0.0517252621621028, "4": 0.0518657649896388, "5": 0.0518451595217499, "6": 0.0516521567886314, "7": 0.05178437372221, "8": 0.0512906238313315, "9": 0.0524249446480415, "10": 0.0516208659862362, "11": 0.0516537590812482, "12": 0.05325865282116, "13": 0.0515826256068339, "14": 0.0521556518081464, "15": 0.0526094822651014, "16": 0.0517296231459344, "17": 0.0521549561266536, "18": 0.0520173893577975, "19": 0.0520793162686208, "20": 0.0515777389461292, "21": 0.0517707804769315, "22": 0.0533833246581946, "23": 0.0527822131305664, "24": 0.0524663153606745, "25": 0.0522883377158564, "26": 0.0518259142129929, "27": 0.0527148666737654, "28": 0.0529315298346752, "29": 0.0529644731913578, "30": 0.0520424586699062, "31": 0.05239687768185, "32": 0.0520237135456428, "33": 0.0533030689000557, "34": 0.0522594887360136, "35": 0.0525975051038612, "36": 0.0534617440361783, "37": 0.0524417089318412, "38": 0.0532712154837929, "39": 0.0528854553440415, "40": 0.0528614021891175, "41": 0.0531798397173996, "42": 0.0525770994926563, "43": 0.0525658214485321, "44": 0.0549102389277313, "45": 0.0527941648557019, "46": 0.0540949146159506, "47": 0.053297331053763, "48": 0.053064897166574, "49": 0.0534302427174227, "50": 0.0533832067084232}}, "event_log": {"timestamp": {"0": "00:04:53.158", "1": "00:04:53.158", "2": "00:04:53.158", "3": "00:04:53.158", "4": "00:04:53.159", "5": "00:04:53.159", "6": "00:04:53.159", "7": "00:04:53.159", "8": "00:04:53.159", "9": "00:04:53.159", "10": "00:04:53.159", "11": "00:04:53.160", "12": "00:04:53.161", "13": "00:04:53.161", "14": "00:04:53.161", "15": "00:04:53.161", "16": "00:04:53.161", "17": "00:04:53.161", "18": "00:04:53.161", "19": "00:04:53.161", "20": "00:04:53.163", "21": "00:04:53.165", "22": "00:04:53.165", "23": "00:04:53.169", "24": "00:05:19.718", "25": "00:05:19.719", "26": "00:05:19.728", "27": "00:05:19.729", "28": "00:05:19.733", "29": "00:05:19.733", "30": "00:05:19.736", "31": "00:05:48.394", "32": "00:05:48.394", "33": "00:05:48.401", "34": "00:05:48.401", "35": "00:05:48.404", "36": "00:05:48.404", "37": "00:05:48.407", "38": "00:06:19.658", "39": "00:06:19.658", "40": "00:06:19.665", "41": "00:06:19.667", "42": "00:06:19.667", "43": "00:06:19.670", "44": "00:06:19.670", "45": "00:06:19.674", "46": "00:06:51.681", "47": "00:06:51.681", "48": "00:07:22.114", "49": "00:07:22.114", "50": "00:07:59.136", "51": "00:07:59.136", "52": "00:07:59.152", "53": "00:08:30.158", "54": "00:08:30.158", "55": "00:09:01.195", "56": "00:09:01.195", "57": "00:09:30.213", "58": "00:09:30.213", "59": "00:10:00.234", "60": "00:10:00.234", "61": "00:10:28.256", "62": "00:10:28.257", "63": "00:11:11.284", "64": "00:11:11.284", "65": "00:11:39.317", "66": "00:11:39.317", "67": "00:12:06.341", "68": "00:12:06.341", "69": "00:12:49.370", "70": "00:12:49.371", "71": "00:13:19.410", "72": "00:13:19.410", "73": "00:13:45.440", "74": "00:13:45.440", "75": "00:14:14.468", "76": "00:14:14.468", "77": "00:15:02.499", "78": "00:15:02.499", "79": "00:15:56.542", "80": "00:15:56.543", "81": "00:16:24.571", "82": "00:16:24.572", "83": "00:16:58.609", "84": "00:16:58.609", "85": "00:17:28.272", "86": "00:17:28.272", "87": "00:17:55.312", "88": "00:17:55.312", "89": "00:18:23.375", "90": "00:18:23.375", "91": "00:18:52.433", "92": "00:18:52.433", "93": "00:19:24.489", "94": "00:19:24.498", "95": "00:20:20.563", "96": "00:20:20.563", "97": "00:20:55.618", "98": "00:20:55.618", "99": "00:21:54.663", "100": "00:21:54.663", "101": "00:22:44.198", "102": "00:22:44.199", "103": "00:23:41.280", "104": "00:23:41.280", "105": "00:24:09.346", "106": "00:24:09.346", "107": "00:24:37.396", "108": "00:24:37.396", "109": "00:25:08.455", "110": "00:25:08.455", "111": "00:25:36.522", "112": "00:25:36.522", "113": "00:26:08.488", "114": "00:26:08.488", "115": "00:26:36.548", "116": "00:26:36.548", "117": "00:27:09.622", "118": "00:27:09.623", "119": "00:27:42.684", "120": "00:27:42.684", "121": "00:28:38.777", "122": "00:28:38.778", "123": "00:29:22.843", "124": "00:29:22.843", "125": "00:29:50.894", "126": "00:29:50.894", "127": "00:30:19.962", "128": "00:30:19.963", "129": "00:30:50.46", "130": "00:30:50.46", "131": "00:31:36.127", "132": "00:31:36.128", "133": "00:32:05.200", "134": "00:32:05.201", "135": "00:32:58.298", "136": "00:32:58.299", "137": "00:33:27.373", "138": "00:33:27.373", "139": "00:33:57.434", "140": "00:33:57.435", "141": "00:34:44.510", "142": "00:34:44.510", "143": "00:34:53.584", "144": "00:34:53.658", "145": "00:34:53.658", "146": "00:34:53.658", "147": "00:34:53.658", "148": "00:34:53.658", "149": "00:34:53.658", "150": "00:34:53.658", "151": "00:34:53.658", "152": "00:34:53.658", "153": "00:34:53.658", "154": "00:34:53.658", "155": "00:34:53.658", "156": "00:34:53.658", "157": "00:34:53.658", "158": "00:34:53.658", "159": "00:34:53.658", "160": "00:34:53.658", "161": "00:34:53.658", "162": "00:34:53.658", "163": "00:34:53.658", "164": "00:34:53.658", "165": "00:34:53.658", "166": "00:34:53.658", "167": "00:34:53.678", "168": "00:34:53.678"}, "level": {"0": "INFO", "1": "INFO", "2": "INFO", "3": "INFO", "4": "INFO", "5": "INFO", "6": "INFO", "7": "INFO", "8": "INFO", "9": "INFO", "10": "INFO", "11": "INFO", "12": "INFO", "13": "INFO", "14": "INFO", "15": "INFO", "16": "INFO", "17": "DEBUG", "18": "DEBUG", "19": "INFO", "20": "INFO", "21": "DEBUG", "22": "INFO", "23": "DEBUG", "24": "DEBUG", "25": "DEBUG", "26": "INFO", "27": "INFO", "28": "DEBUG", "29": "INFO", "30": "DEBUG", "31": "DEBUG", "32": "DEBUG", "33": "INFO", "34": "INFO", "35": "DEBUG", "36": "INFO", "37": "DEBUG", "38": "DEBUG", "39": "DEBUG", "40": "INFO", "41": "INFO", "42": "INFO", "43": "DEBUG", "44": "INFO", "45": "DEBUG", "46": "DEBUG", "47": "DEBUG", "48": "DEBUG", "49": "DEBUG", "50": "DEBUG", "51": "DEBUG", "52": "INFO", "53": "DEBUG", "54": "DEBUG", "55": "DEBUG", "56": "DEBUG", "57": "DEBUG", "58": "DEBUG", "59": "DEBUG", "60": "DEBUG", "61": "DEBUG", "62": "DEBUG", "63": "DEBUG", "64": "DEBUG", "65": "DEBUG", "66": "DEBUG", "67": "DEBUG", "68": "DEBUG", "69": "DEBUG", "70": "DEBUG", "71": "DEBUG", "72": "DEBUG", "73": "DEBUG", "74": "DEBUG", "75": "DEBUG", "76": "DEBUG", "77": "DEBUG", "78": "DEBUG", "79": "DEBUG", "80": "DEBUG", "81": "DEBUG", "82": "DEBUG", "83": "DEBUG", "84": "DEBUG", "85": "DEBUG", "86": "DEBUG", "87": "DEBUG", "88": "DEBUG", "89": "DEBUG", "90": "DEBUG", "91": "DEBUG", "92": "DEBUG", "93": "DEBUG", "94": "DEBUG", "95": "DEBUG", "96": "DEBUG", "97": "DEBUG", "98": "DEBUG", "99": "DEBUG", "100": "DEBUG", "101": "DEBUG", "102": "DEBUG", "103": "DEBUG", "104": "DEBUG", "105": "DEBUG", "106": "DEBUG", "107": "DEBUG", "108": "DEBUG", "109": "DEBUG", "110": "DEBUG", "111": "DEBUG", "112": "DEBUG", "113": "DEBUG", "114": "DEBUG", "115": "DEBUG", "116": "DEBUG", "117": "DEBUG", "118": "DEBUG", "119": "DEBUG", "120": "DEBUG", "121": "DEBUG", "122": "DEBUG", "123": "DEBUG", "124": "DEBUG", "125": "DEBUG", "126": "DEBUG", "127": "DEBUG", "128": "DEBUG", "129": "DEBUG", "130": "DEBUG", "131": "DEBUG", "132": "DEBUG", "133": "DEBUG", "134": "DEBUG", "135": "DEBUG", "136": "DEBUG", "137": "DEBUG", "138": "DEBUG", "139": "DEBUG", "140": "DEBUG", "141": "DEBUG", "142": "DEBUG", "143": "DEBUG", "144": "DEBUG", "145": "DEBUG", "146": "DEBUG", "147": "DEBUG", "148": "DEBUG", "149": "DEBUG", "150": "DEBUG", "151": "DEBUG", "152": "DEBUG", "153": "DEBUG", "154": "DEBUG", "155": "DEBUG", "156": "DEBUG", "157": "DEBUG", "158": "DEBUG", "159": "DEBUG", "160": "DEBUG", "161": "DEBUG", "162": "DEBUG", "163": "INFO", "164": "INFO", "165": "INFO", "166": "INFO", "167": "DEBUG", "168": "DEBUG"}, "stage": {"0": "Workflow", "1": "Validation", "2": "Validation", "3": "Validation", "4": "DataImport", "5": "DataImport", "6": "DataImport", "7": "DataImport", "8": "DataImport", "9": "DataImport", "10": "DataImport", "11": "Workflow", "12": "Workflow", "13": "Workflow", "14": "Workflow", "15": "Workflow", "16": "Workflow", "17": "Workflow", "18": "Workflow", "19": "Workflow", "20": "Workflow", "21": "ModelTraining", "22": "ModelTraining", "23": "ModelTraining", "24": "ModelTraining", "25": "ModelTraining", "26": "ModelTraining", "27": "ModelTraining", "28": "ModelTraining", "29": "ModelTraining", "30": "ModelTraining", "31": "ModelTraining", "32": "ModelTraining", "33": "ModelTraining", "34": "ModelTraining", "35": "ModelTraining", "36": "ModelTraining", "37": "ModelTraining", "38": "ModelTraining", "39": "ModelTraining", "40": "ModelTraining", "41": "ModelTraining", "42": "ModelTraining", "43": "ModelTraining", "44": "ModelTraining", "45": "ModelTraining", "46": "ModelTraining", "47": "ModelTraining", "48": "ModelTraining", "49": "ModelTraining", "50": "ModelTraining", "51": "ModelTraining", "52": "ModelTraining", "53": "ModelTraining", "54": "ModelTraining", "55": "ModelTraining", "56": "ModelTraining", "57": "ModelTraining", "58": "ModelTraining", "59": "ModelTraining", "60": "ModelTraining", "61": "ModelTraining", "62": "ModelTraining", "63": "ModelTraining", "64": "ModelTraining", "65": "ModelTraining", "66": "ModelTraining", "67": "ModelTraining", "68": "ModelTraining", "69": "ModelTraining", "70": "ModelTraining", "71": "ModelTraining", "72": "ModelTraining", "73": "ModelTraining", "74": "ModelTraining", "75": "ModelTraining", "76": "ModelTraining", "77": "ModelTraining", "78": "ModelTraining", "79": "ModelTraining", "80": "ModelTraining", "81": "ModelTraining", "82": "ModelTraining", "83": "ModelTraining", "84": "ModelTraining", "85": "ModelTraining", "86": "ModelTraining", "87": "ModelTraining", "88": "ModelTraining", "89": "ModelTraining", "90": "ModelTraining", "91": "ModelTraining", "92": "ModelTraining", "93": "ModelTraining", "94": "ModelTraining", "95": "ModelTraining", "96": "ModelTraining", "97": "ModelTraining", "98": "ModelTraining", "99": "ModelTraining", "100": "ModelTraining", "101": "ModelTraining", "102": "ModelTraining", "103": "ModelTraining", "104": "ModelTraining", "105": "ModelTraining", "106": "ModelTraining", "107": "ModelTraining", "108": "ModelTraining", "109": "ModelTraining", "110": "ModelTraining", "111": "ModelTraining", "112": "ModelTraining", "113": "ModelTraining", "114": "ModelTraining", "115": "ModelTraining", "116": "ModelTraining", "117": "ModelTraining", "118": "ModelTraining", "119": "ModelTraining", "120": "ModelTraining", "121": "ModelTraining", "122": "ModelTraining", "123": "ModelTraining", "124": "ModelTraining", "125": "ModelTraining", "126": "ModelTraining", "127": "ModelTraining", "128": "ModelTraining", "129": "ModelTraining", "130": "ModelTraining", "131": "ModelTraining", "132": "ModelTraining", "133": "ModelTraining", "134": "ModelTraining", "135": "ModelTraining", "136": "ModelTraining", "137": "ModelTraining", "138": "ModelTraining", "139": "ModelTraining", "140": "ModelTraining", "141": "ModelTraining", "142": "ModelTraining", "143": "ModelTraining", "144": "ModelTraining", "145": "ModelTraining", "146": "ModelTraining", "147": "ModelTraining", "148": "ModelTraining", "149": "ModelTraining", "150": "ModelTraining", "151": "ModelTraining", "152": "ModelTraining", "153": "ModelTraining", "154": "ModelTraining", "155": "ModelTraining", "156": "ModelTraining", "157": "ModelTraining", "158": "ModelTraining", "159": "ModelTraining", "160": "ModelTraining", "161": "ModelTraining", "162": "ModelTraining", "163": "Workflow", "164": "Workflow", "165": "Workflow", "166": "Workflow", "167": "Workflow", "168": "Workflow"}, "message": {"0": "Project: classification_test_2022-12-21T03.04.51", "1": "5-fold cross-validation will be used.", "2": "Setting stopping tolerance adaptively based on the training frame: 0.00724466513640519", "3": "Build control seed: -1 (random)", "4": "training frame: Frame key: AutoML_13_20221221_00453_training_product_backorders6.hex    cols: 23    rows: 19053  chunks: 48    size: 896711  checksum: 340006888695133344", "5": "validation frame: NULL", "6": "leaderboard frame: NULL", "7": "blending frame: NULL", "8": "response column: went_on_backorder", "9": "fold column: null", "10": "weights column: null", "11": "Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]", "12": "Disabling Algo: StackedEnsemble as requested by the user.", "13": "Disabling Algo: DeepLearning as requested by the user.", "14": "Disabling Algo: GLM as requested by the user.", "15": "Disabling Algo: DRF as requested by the user.", "16": "Disabling Algo: GBM as requested by the user.", "17": "Defined work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "18": "Actual work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "19": "AutoML job created: 2022.12.21 00:04:53.156", "20": "AutoML build started: 2022.12.21 00:04:53.163", "21": "Time assigned for XGBoost_1_AutoML_13_20221221_00453: 1799.998s", "22": "AutoML: starting XGBoost_1_AutoML_13_20221221_00453 model training", "23": "XGBoost_1_AutoML_13_20221221_00453 [XGBoost def_2] started", "24": "XGBoost_1_AutoML_13_20221221_00453 [XGBoost def_2] complete", "25": "Adding model XGBoost_1_AutoML_13_20221221_00453 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=27s", "26": "New leader: XGBoost_1_AutoML_13_20221221_00453, auc: 0.9447569834409859", "27": "Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.", "28": "Time assigned for XGBoost_2_AutoML_13_20221221_00453: 1773.43s", "29": "AutoML: starting XGBoost_2_AutoML_13_20221221_00453 model training", "30": "XGBoost_2_AutoML_13_20221221_00453 [XGBoost def_1] started", "31": "XGBoost_2_AutoML_13_20221221_00453 [XGBoost def_1] complete", "32": "Adding model XGBoost_2_AutoML_13_20221221_00453 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=29s", "33": "Skipping StackedEnsemble 'best_of_family_2' due to the exclude_algos option or it is already trained.", "34": "Skipping StackedEnsemble 'all_2' due to the exclude_algos option or it is already trained.", "35": "Time assigned for XGBoost_3_AutoML_13_20221221_00453: 1744.759s", "36": "AutoML: starting XGBoost_3_AutoML_13_20221221_00453 model training", "37": "XGBoost_3_AutoML_13_20221221_00453 [XGBoost def_3] started", "38": "XGBoost_3_AutoML_13_20221221_00453 [XGBoost def_3] complete", "39": "Adding model XGBoost_3_AutoML_13_20221221_00453 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=31s", "40": "New leader: XGBoost_3_AutoML_13_20221221_00453, auc: 0.9460793117819967", "41": "Skipping StackedEnsemble 'best_of_family_3' due to the exclude_algos option or it is already trained.", "42": "Skipping StackedEnsemble 'all_3' due to the exclude_algos option or it is already trained.", "43": "Time assigned for XGBoost_grid_1_AutoML_13_20221221_00453: 1713.493s", "44": "AutoML: starting XGBoost_grid_1_AutoML_13_20221221_00453 hyperparameter search", "45": "XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search] started", "46": "Built: 1 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "47": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_1 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=31s", "48": "Built: 2 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "49": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_2 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=31s", "50": "Built: 3 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "51": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_3 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=11s, total=37s", "52": "New leader: XGBoost_grid_1_AutoML_13_20221221_00453_model_3, auc: 0.9493336136045677", "53": "Built: 4 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "54": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_4 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=10s, total=32s", "55": "Built: 5 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "56": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_5 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=31s", "57": "Built: 6 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "58": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_6 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=28s", "59": "Built: 7 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "60": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_7 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=31s", "61": "Built: 8 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "62": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_8 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=27s", "63": "Built: 9 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "64": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_9 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=13s, total=43s", "65": "Built: 10 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "66": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_10 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=27s", "67": "Built: 11 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "68": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_11 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=27s", "69": "Built: 12 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "70": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_12 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=14s, total=43s", "71": "Built: 13 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "72": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_13 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=30s", "73": "Built: 14 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "74": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_14 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=27s", "75": "Built: 15 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "76": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_15 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=28s", "77": "Built: 16 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "78": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_16 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=15s, total=48s", "79": "Built: 17 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "80": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_17 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=16s, total=54s", "81": "Built: 18 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "82": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_18 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=28s", "83": "Built: 19 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "84": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_19 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=10s, total=33s", "85": "Built: 20 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "86": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_20 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=30s", "87": "Built: 21 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "88": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_21 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=27s", "89": "Built: 22 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "90": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_22 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=28s", "91": "Built: 23 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "92": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_23 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=29s", "93": "Built: 24 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "94": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_24 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=10s, total=32s", "95": "Built: 25 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "96": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_25 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=17s, total=56s", "97": "Built: 26 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "98": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_26 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=10s, total=35s", "99": "Built: 27 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "100": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_27 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=18s, total=58s", "101": "Built: 28 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "102": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_28 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=14s, total=50s", "103": "Built: 29 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "104": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_29 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=17s, total=57s", "105": "Built: 30 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "106": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_30 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=28s", "107": "Built: 31 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "108": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_31 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=28s", "109": "Built: 32 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "110": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_32 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=32s", "111": "Built: 33 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "112": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_33 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=28s", "113": "Built: 34 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "114": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_34 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=32s", "115": "Built: 35 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "116": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_35 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=27s", "117": "Built: 36 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "118": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_36 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=10s, total=33s", "119": "Built: 37 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "120": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_37 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=10s, total=34s", "121": "Built: 38 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "122": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_38 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=17s, total=55s", "123": "Built: 39 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "124": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_39 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=13s, total=44s", "125": "Built: 40 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "126": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_40 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=29s", "127": "Built: 41 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "128": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_41 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=29s", "129": "Built: 42 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "130": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_42 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=30s", "131": "Built: 43 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "132": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_43 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=14s, total=46s", "133": "Built: 44 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "134": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_44 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=8s, total=29s", "135": "Built: 45 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "136": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_45 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=15s, total=52s", "137": "Built: 46 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "138": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_46 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=30s", "139": "Built: 47 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "140": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_47 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=9s, total=29s", "141": "Built: 48 models for HyperparamSearch : XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "142": "Adding model XGBoost_grid_1_AutoML_13_20221221_00453_model_48 to leaderboard Leaderboard_classification_test_2022-12-21T03.04.51@@went_on_backorder. Training time: model=14s, total=47s", "143": "AutoML: out of time; skipping XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search]", "144": "XGBoost_grid_1_AutoML_13_20221221_00453 [XGBoost Grid Search] complete", "145": "AutoML: out of time; skipping GBM grid_1", "146": "AutoML: out of time; skipping DeepLearning grid_1", "147": "AutoML: out of time; skipping StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)", "148": "AutoML: out of time; skipping StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)", "149": "AutoML: out of time; skipping DeepLearning grid_2", "150": "AutoML: out of time; skipping DeepLearning grid_3", "151": "AutoML: out of time; skipping StackedEnsemble best_of_family_5 (built with AUTO metalearner, using top model from each algorithm type)", "152": "AutoML: out of time; skipping StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)", "153": "AutoML: out of time; skipping XGBoost lr_search", "154": "AutoML: out of time; skipping GBM lr_annealing", "155": "AutoML: out of time; skipping StackedEnsemble monotonic (built with AUTO metalearner, using monotonically constrained AutoML models)", "156": "AutoML: out of time; skipping StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)", "157": "AutoML: out of time; skipping StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)", "158": "AutoML: out of time; skipping StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)", "159": "AutoML: out of time; skipping StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)", "160": "AutoML: out of time; skipping completion resume_best_grids", "161": "AutoML: out of time; skipping StackedEnsemble best_of_family (built with AUTO metalearner, using top model from each algorithm type)", "162": "AutoML: out of time; skipping StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)", "163": "Actual modeling steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w)]}]", "164": "AutoML build stopped: 2022.12.21 00:34:53.658", "165": "AutoML build done: built 51 models", "166": "AutoML duration: 30 min  0.495 sec", "167": "Verifying training frame immutability. . .", "168": "Training frame was not mutated (as expected)."}, "name": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": "creation_epoch", "20": "start_epoch", "21": NaN, "22": "start_XGBoost_def_2", "23": NaN, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": "start_XGBoost_def_1", "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": NaN, "35": NaN, "36": "start_XGBoost_def_3", "37": NaN, "38": NaN, "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": "start_XGBoost_grid_1", "45": NaN, "46": NaN, "47": NaN, "48": NaN, "49": NaN, "50": NaN, "51": NaN, "52": NaN, "53": NaN, "54": NaN, "55": NaN, "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": NaN, "61": NaN, "62": NaN, "63": NaN, "64": NaN, "65": NaN, "66": NaN, "67": NaN, "68": NaN, "69": NaN, "70": NaN, "71": NaN, "72": NaN, "73": NaN, "74": NaN, "75": NaN, "76": NaN, "77": NaN, "78": NaN, "79": NaN, "80": NaN, "81": NaN, "82": NaN, "83": NaN, "84": NaN, "85": NaN, "86": NaN, "87": NaN, "88": NaN, "89": NaN, "90": NaN, "91": NaN, "92": NaN, "93": NaN, "94": NaN, "95": NaN, "96": NaN, "97": NaN, "98": NaN, "99": NaN, "100": NaN, "101": NaN, "102": NaN, "103": NaN, "104": NaN, "105": NaN, "106": NaN, "107": NaN, "108": NaN, "109": NaN, "110": NaN, "111": NaN, "112": NaN, "113": NaN, "114": NaN, "115": NaN, "116": NaN, "117": NaN, "118": NaN, "119": NaN, "120": NaN, "121": NaN, "122": NaN, "123": NaN, "124": NaN, "125": NaN, "126": NaN, "127": NaN, "128": NaN, "129": NaN, "130": NaN, "131": NaN, "132": NaN, "133": NaN, "134": NaN, "135": NaN, "136": NaN, "137": NaN, "138": NaN, "139": NaN, "140": NaN, "141": NaN, "142": NaN, "143": NaN, "144": NaN, "145": NaN, "146": NaN, "147": NaN, "148": NaN, "149": NaN, "150": NaN, "151": NaN, "152": NaN, "153": NaN, "154": NaN, "155": NaN, "156": NaN, "157": NaN, "158": NaN, "159": NaN, "160": NaN, "161": NaN, "162": NaN, "163": NaN, "164": "stop_epoch", "165": NaN, "166": "duration_secs", "167": NaN, "168": NaN}, "value": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": 1671581093.0, "20": 1671581093.0, "21": NaN, "22": 1671581093.0, "23": NaN, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": 1671581120.0, "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": NaN, "35": NaN, "36": 1671581148.0, "37": NaN, "38": NaN, "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": 1671581180.0, "45": NaN, "46": NaN, "47": NaN, "48": NaN, "49": NaN, "50": NaN, "51": NaN, "52": NaN, "53": NaN, "54": NaN, "55": NaN, "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": NaN, "61": NaN, "62": NaN, "63": NaN, "64": NaN, "65": NaN, "66": NaN, "67": NaN, "68": NaN, "69": NaN, "70": NaN, "71": NaN, "72": NaN, "73": NaN, "74": NaN, "75": NaN, "76": NaN, "77": NaN, "78": NaN, "79": NaN, "80": NaN, "81": NaN, "82": NaN, "83": NaN, "84": NaN, "85": NaN, "86": NaN, "87": NaN, "88": NaN, "89": NaN, "90": NaN, "91": NaN, "92": NaN, "93": NaN, "94": NaN, "95": NaN, "96": NaN, "97": NaN, "98": NaN, "99": NaN, "100": NaN, "101": NaN, "102": NaN, "103": NaN, "104": NaN, "105": NaN, "106": NaN, "107": NaN, "108": NaN, "109": NaN, "110": NaN, "111": NaN, "112": NaN, "113": NaN, "114": NaN, "115": NaN, "116": NaN, "117": NaN, "118": NaN, "119": NaN, "120": NaN, "121": NaN, "122": NaN, "123": NaN, "124": NaN, "125": NaN, "126": NaN, "127": NaN, "128": NaN, "129": NaN, "130": NaN, "131": NaN, "132": NaN, "133": NaN, "134": NaN, "135": NaN, "136": NaN, "137": NaN, "138": NaN, "139": NaN, "140": NaN, "141": NaN, "142": NaN, "143": NaN, "144": NaN, "145": NaN, "146": NaN, "147": NaN, "148": NaN, "149": NaN, "150": NaN, "151": NaN, "152": NaN, "153": NaN, "154": NaN, "155": NaN, "156": NaN, "157": NaN, "158": NaN, "159": NaN, "160": NaN, "161": NaN, "162": NaN, "163": NaN, "164": 1671582894.0, "165": NaN, "166": 1800.0, "167": NaN, "168": NaN}}}, {"experiment": "classification_1", "max_runtime_secs": 1800, "max_models": null, "include_algos": ["GBM"], "start_time": "2022-12-21 03:35:00.315645", "end_time": "2022-12-21 04:05:06.256539", "elapsed_time": "0:30:05.940894", "leaderboard": {"model_id": {"0": "GBM_grid_1_AutoML_14_20221221_03501_model_23", "1": "GBM_grid_1_AutoML_14_20221221_03501_model_45", "2": "GBM_grid_1_AutoML_14_20221221_03501_model_5", "3": "GBM_grid_1_AutoML_14_20221221_03501_model_22", "4": "GBM_grid_1_AutoML_14_20221221_03501_model_28", "5": "GBM_4_AutoML_14_20221221_03501", "6": "GBM_grid_1_AutoML_14_20221221_03501_model_19", "7": "GBM_grid_1_AutoML_14_20221221_03501_model_1", "8": "GBM_grid_1_AutoML_14_20221221_03501_model_32", "9": "GBM_grid_1_AutoML_14_20221221_03501_model_43", "10": "GBM_grid_1_AutoML_14_20221221_03501_model_48", "11": "GBM_grid_1_AutoML_14_20221221_03501_model_10", "12": "GBM_grid_1_AutoML_14_20221221_03501_model_3", "13": "GBM_grid_1_AutoML_14_20221221_03501_model_46", "14": "GBM_grid_1_AutoML_14_20221221_03501_model_47", "15": "GBM_1_AutoML_14_20221221_03501", "16": "GBM_grid_1_AutoML_14_20221221_03501_model_20", "17": "GBM_grid_1_AutoML_14_20221221_03501_model_7", "18": "GBM_grid_1_AutoML_14_20221221_03501_model_61", "19": "GBM_grid_1_AutoML_14_20221221_03501_model_57", "20": "GBM_3_AutoML_14_20221221_03501", "21": "GBM_grid_1_AutoML_14_20221221_03501_model_39", "22": "GBM_grid_1_AutoML_14_20221221_03501_model_44", "23": "GBM_grid_1_AutoML_14_20221221_03501_model_40", "24": "GBM_grid_1_AutoML_14_20221221_03501_model_42", "25": "GBM_grid_1_AutoML_14_20221221_03501_model_2", "26": "GBM_grid_1_AutoML_14_20221221_03501_model_59", "27": "GBM_grid_1_AutoML_14_20221221_03501_model_17", "28": "GBM_grid_1_AutoML_14_20221221_03501_model_52", "29": "GBM_grid_1_AutoML_14_20221221_03501_model_38", "30": "GBM_2_AutoML_14_20221221_03501", "31": "GBM_grid_1_AutoML_14_20221221_03501_model_30", "32": "GBM_grid_1_AutoML_14_20221221_03501_model_13", "33": "GBM_grid_1_AutoML_14_20221221_03501_model_11", "34": "GBM_grid_1_AutoML_14_20221221_03501_model_27", "35": "GBM_grid_1_AutoML_14_20221221_03501_model_12", "36": "GBM_grid_1_AutoML_14_20221221_03501_model_49", "37": "GBM_grid_1_AutoML_14_20221221_03501_model_35", "38": "GBM_grid_1_AutoML_14_20221221_03501_model_4", "39": "GBM_grid_1_AutoML_14_20221221_03501_model_14", "40": "GBM_grid_1_AutoML_14_20221221_03501_model_51", "41": "GBM_grid_1_AutoML_14_20221221_03501_model_62", "42": "GBM_grid_1_AutoML_14_20221221_03501_model_21", "43": "GBM_grid_1_AutoML_14_20221221_03501_model_18", "44": "GBM_grid_1_AutoML_14_20221221_03501_model_31", "45": "GBM_5_AutoML_14_20221221_03501", "46": "GBM_grid_1_AutoML_14_20221221_03501_model_50", "47": "GBM_grid_1_AutoML_14_20221221_03501_model_6", "48": "GBM_grid_1_AutoML_14_20221221_03501_model_25", "49": "GBM_grid_1_AutoML_14_20221221_03501_model_9", "50": "GBM_grid_1_AutoML_14_20221221_03501_model_54", "51": "GBM_grid_1_AutoML_14_20221221_03501_model_55", "52": "GBM_grid_1_AutoML_14_20221221_03501_model_58", "53": "GBM_grid_1_AutoML_14_20221221_03501_model_36", "54": "GBM_grid_1_AutoML_14_20221221_03501_model_34", "55": "GBM_grid_1_AutoML_14_20221221_03501_model_53", "56": "GBM_grid_1_AutoML_14_20221221_03501_model_8", "57": "GBM_grid_1_AutoML_14_20221221_03501_model_37", "58": "GBM_grid_1_AutoML_14_20221221_03501_model_24", "59": "GBM_grid_1_AutoML_14_20221221_03501_model_56", "60": "GBM_grid_1_AutoML_14_20221221_03501_model_15", "61": "GBM_grid_1_AutoML_14_20221221_03501_model_60", "62": "GBM_grid_1_AutoML_14_20221221_03501_model_33", "63": "GBM_grid_1_AutoML_14_20221221_03501_model_16", "64": "GBM_grid_1_AutoML_14_20221221_03501_model_26", "65": "GBM_grid_1_AutoML_14_20221221_03501_model_63", "66": "GBM_grid_1_AutoML_14_20221221_03501_model_29", "67": "GBM_grid_1_AutoML_14_20221221_03501_model_41"}, "auc": {"0": 0.9508297225540864, "1": 0.9499807068166426, "2": 0.9497818600542564, "3": 0.9495703421999256, "4": 0.9493828521008592, "5": 0.9492896459670622, "6": 0.9489208698720394, "7": 0.9486295793444588, "8": 0.9484489242742422, "9": 0.948289339494884, "10": 0.948233121382594, "11": 0.9480033329703758, "12": 0.947501891594234, "13": 0.9472973007787568, "14": 0.947185350892768, "15": 0.9470653435593076, "16": 0.9468399716272696, "17": 0.9466113924893864, "18": 0.9464848261570876, "19": 0.9463592325019712, "20": 0.9460495005407822, "21": 0.9459423746078468, "22": 0.9458508377984036, "23": 0.9452045463877898, "24": 0.9451611570988794, "25": 0.9451086982524568, "26": 0.944999771552305, "27": 0.9448873090391522, "28": 0.9444533898614756, "29": 0.9444487236398568, "30": 0.9444325561677696, "31": 0.9442087089729364, "32": 0.9440111372063164, "33": 0.943961478092865, "34": 0.943936898277578, "35": 0.9436170977931216, "36": 0.943597539095182, "37": 0.943114657451225, "38": 0.9429512082517096, "39": 0.942797183505435, "40": 0.9427511390707022, "41": 0.9422205962448036, "42": 0.9420767846089452, "43": 0.9420709222572776, "44": 0.9415891841662244, "45": 0.9411890852370683, "46": 0.9411326173833396, "47": 0.9409506873173568, "48": 0.940927540229271, "49": 0.9395984688694142, "50": 0.938573950621964, "51": 0.9375459228500852, "52": 0.9371953253029456, "53": 0.9355353071038924, "54": 0.9346761176888916, "55": 0.933963303045568, "56": 0.9338982914057768, "57": 0.9330740132150552, "58": 0.9328081963142264, "59": 0.9315026400824704, "60": 0.9299954767882158, "61": 0.929792555297092, "62": 0.9294491739631038, "63": 0.9243812629566516, "64": 0.9232507228963108, "65": 0.922139859832486, "66": 0.9048232353756276, "67": 0.9026865790685864}, "logloss": {"0": 0.1716116123765725, "1": 0.1723522446705608, "2": 0.1727256143854854, "3": 0.1731066945476853, "4": 0.1726806977141481, "5": 0.1734649896563452, "6": 0.1734930185516319, "7": 0.1730141902749342, "8": 0.1741872656326209, "9": 0.1752185175693359, "10": 0.1753143275400051, "11": 0.1743178200922161, "12": 0.1771535923735759, "13": 0.1758310976450361, "14": 0.1758011236265053, "15": 0.1760565644367709, "16": 0.1801144695056807, "17": 0.1779703095656539, "18": 0.1770045888618291, "19": 0.177732187680461, "20": 0.1786166997605289, "21": 0.1809597858341017, "22": 0.1769948638085846, "23": 0.1782957984550892, "24": 0.1809173211435958, "25": 0.1807877409739132, "26": 0.1796755225277861, "27": 0.1831579513757423, "28": 0.1796930220851938, "29": 0.1784715647335722, "30": 0.1803583035684965, "31": 0.1818634468298739, "32": 0.1789757120280426, "33": 0.1822036758281354, "34": 0.18345537953818, "35": 0.1849865447166311, "36": 0.1866579777619222, "37": 0.1796436462106461, "38": 0.185048627107705, "39": 0.1840110218483525, "40": 0.1877345374288736, "41": 0.1844534303783899, "42": 0.1856986667083345, "43": 0.1853478921827117, "44": 0.1839124723228391, "45": 0.184433108529181, "46": 0.1868312277984991, "47": 0.1900301251592255, "48": 0.1912148687767819, "49": 0.1935799044701, "50": 0.1883051026083221, "51": 0.1901455652211574, "52": 0.1922894314806938, "53": 0.2008562597349433, "54": 0.1955669844061621, "55": 0.2043652211328473, "56": 0.1961175840506989, "57": 0.1989316924017673, "58": 0.1976572941361024, "59": 0.2121613194495825, "60": 0.2110677312079012, "61": 0.2161465384426109, "62": 0.2019574651206598, "63": 0.2199763148330134, "64": 0.2251291587046745, "65": 0.2477537855049608, "66": 0.2434665203939674, "67": 0.2390623950450784}, "aucpr": {"0": 0.7397104476344969, "1": 0.7455467298291167, "2": 0.7374960006488898, "3": 0.7407885351100256, "4": 0.7449096952819981, "5": 0.7425432453037697, "6": 0.7378118975905165, "7": 0.7431272100217664, "8": 0.7372988444146561, "9": 0.7306171650193086, "10": 0.7355489443315801, "11": 0.7404886456658413, "12": 0.7353082670680635, "13": 0.7343208469271532, "14": 0.7380151258345061, "15": 0.7325650067294889, "16": 0.7321086380355288, "17": 0.7325103949453855, "18": 0.7333060445794722, "19": 0.7345531802927727, "20": 0.727223199378316, "21": 0.7266778912463977, "22": 0.736167613288531, "23": 0.757224974185413, "24": 0.7257355679451968, "25": 0.7305196902440457, "26": 0.7340283756894089, "27": 0.7276643696142695, "28": 0.7283741944985215, "29": 0.7486180457516517, "30": 0.7243809105159792, "31": 0.7296000296655683, "32": 0.731022464758211, "33": 0.7261744602638683, "34": 0.7250479977980553, "35": 0.7234951950223394, "36": 0.7164356903587915, "37": 0.7285858056205871, "38": 0.7178054220226684, "39": 0.7218324178469434, "40": 0.7147891558301039, "41": 0.7193147487577753, "42": 0.7165826347611719, "43": 0.7158722025306729, "44": 0.7251541870165542, "45": 0.7221785639029833, "46": 0.7159487831206586, "47": 0.7145327064806796, "48": 0.7191248401525796, "49": 0.7057389269336929, "50": 0.7126482280156163, "51": 0.7090162730144158, "52": 0.7009665751012522, "53": 0.6890823331027675, "54": 0.6978219762244204, "55": 0.6964649803809846, "56": 0.6930781718204281, "57": 0.6913740501613758, "58": 0.6896875861141654, "59": 0.6759723773813284, "60": 0.6722488911033735, "61": 0.6661245726366509, "62": 0.6787836970375811, "63": 0.6503228013804857, "64": 0.643060874829333, "65": 0.6098651810051328, "66": 0.5938076937310846, "67": 0.5885334596287787}, "mean_per_class_error": {"0": 0.1516797267418558, "1": 0.1453822991996023, "2": 0.1533081855096231, "3": 0.1539999298620885, "4": 0.1475918537181847, "5": 0.1507186953969919, "6": 0.1519368552694733, "7": 0.1474617778614572, "8": 0.1523210364679809, "9": 0.1530388985172246, "10": 0.1467189548126253, "11": 0.159613525912199, "12": 0.147121984917615, "13": 0.1651432351274635, "14": 0.1482538131180082, "15": 0.147442928954975, "16": 0.1458023117224267, "17": 0.1544102287573744, "18": 0.1535209257825753, "19": 0.1505077558912559, "20": 0.1642174567583214, "21": 0.1580774451881949, "22": 0.143530742461318, "23": 0.1641263011331794, "24": 0.1704036573503295, "25": 0.1402269918338755, "26": 0.1509910055752278, "27": 0.1376046935827649, "28": 0.1657662742957015, "29": 0.1523903200008033, "30": 0.1570513759149672, "31": 0.1584561583636226, "32": 0.1468065089033348, "33": 0.158809910539462, "34": 0.1494938450828092, "35": 0.1482689947686266, "36": 0.164390698451093, "37": 0.1576239804568649, "38": 0.157177206167236, "39": 0.1691125466891619, "40": 0.1738636015312778, "41": 0.1735997825619591, "42": 0.1487443315922762, "43": 0.1527386041535629, "44": 0.1671430725589312, "45": 0.154534836591022, "46": 0.1708656132905769, "47": 0.1603854898436466, "48": 0.1479456058940241, "49": 0.1702012090535109, "50": 0.1609921249426449, "51": 0.1721354302080198, "52": 0.175093275798514, "53": 0.1740361991540232, "54": 0.1698480352262665, "55": 0.1625154031318417, "56": 0.1743097317508804, "57": 0.1686134712845453, "58": 0.1622260448143398, "59": 0.1714552002503092, "60": 0.1851083543979283, "61": 0.1753376017913243, "62": 0.1686882228404476, "63": 0.1754409158812473, "64": 0.1838877496882043, "65": 0.1738713829487376, "66": 0.2104882886775486, "67": 0.2121428651420942}, "rmse": {"0": 0.2267072955330294, "1": 0.2253413107969729, "2": 0.2266431724286436, "3": 0.2267458603426226, "4": 0.2269347036600499, "5": 0.22653854308141, "6": 0.227259303149187, "7": 0.2262711676565394, "8": 0.2264163928580105, "9": 0.2275970890641169, "10": 0.2287184132049666, "11": 0.2264545665397164, "12": 0.228112687396377, "13": 0.2275997398687405, "14": 0.2274535986980472, "15": 0.2289899151187496, "16": 0.230231198565728, "17": 0.2292740644152265, "18": 0.2292422841094087, "19": 0.2287982820121512, "20": 0.2296279094548878, "21": 0.2315489992276963, "22": 0.2278763296798147, "23": 0.2264937145134608, "24": 0.2307252145926049, "25": 0.2307549298832597, "26": 0.2307854624675114, "27": 0.2328771176934238, "28": 0.230557905861849, "29": 0.2276513753668094, "30": 0.2304881176204626, "31": 0.2303298073948999, "32": 0.2279688762128422, "33": 0.2323843692993703, "34": 0.2321220212562337, "35": 0.2330398410484211, "36": 0.2341034885242839, "37": 0.2309365781443785, "38": 0.2328970241723275, "39": 0.2329546417604053, "40": 0.234006897351397, "41": 0.232718760400574, "42": 0.2339975992865289, "43": 0.2329499873221663, "44": 0.2328660541855461, "45": 0.2322325286264959, "46": 0.2347764221968674, "47": 0.2353143576373896, "48": 0.2362455192000574, "49": 0.2386583901051754, "50": 0.235187199723759, "51": 0.2366416978268394, "52": 0.2386024729811197, "53": 0.2431707709957275, "54": 0.2396434369418908, "55": 0.2446338415229262, "56": 0.2406274541623905, "57": 0.2418631659829576, "58": 0.2416895152629057, "59": 0.2496263655565328, "60": 0.2495203068462783, "61": 0.2519666916311891, "62": 0.2443347138192746, "63": 0.2546953660067476, "64": 0.2573040751365512, "65": 0.270740217158384, "66": 0.2678953368175731, "67": 0.2660296239041657}, "mse": {"0": 0.0513961978479003, "1": 0.0507787063516979, "2": 0.0513671276085198, "3": 0.0514136851825161, "4": 0.0514993597252746, "5": 0.0513197115014478, "6": 0.051646790867854, "7": 0.0511986413126537, "8": 0.0512643829548329, "9": 0.0518004349504595, "10": 0.0523121125389978, "11": 0.0512816707066908, "12": 0.0520353981511972, "13": 0.0518016415883183, "14": 0.0517351395606923, "15": 0.0524363812260921, "16": 0.0530064047930117, "17": 0.0525665966134774, "18": 0.0525520248236988, "19": 0.0523486538517118, "20": 0.0527289768006221, "21": 0.0536149390433477, "22": 0.0519276216283436, "23": 0.0512994027141051, "24": 0.0532341246488036, "25": 0.0532478376654281, "26": 0.0532619296863431, "27": 0.0542317519451967, "28": 0.0531569479554012, "29": 0.0518251487063999, "30": 0.0531247723642242, "31": 0.0530518201745717, "32": 0.0519698085217461, "33": 0.0540024950946661, "34": 0.0538806327520794, "35": 0.0543075675158733, "36": 0.0548044433392395, "37": 0.0533317031250346, "38": 0.0542410238683256, "39": 0.0542678651177187, "40": 0.0547592280080272, "41": 0.0541580214423797, "42": 0.0547548764718589, "43": 0.0542656965933974, "44": 0.0542265991919457, "45": 0.0539319473522562, "46": 0.0551199684195617, "47": 0.0553728469102973, "48": 0.0558119453421047, "49": 0.056957827167594, "50": 0.0553130189139033, "51": 0.0559992931503691, "52": 0.0569311401127059, "53": 0.0591320238666565, "54": 0.057428976869322, "55": 0.0598457164182641, "56": 0.0579015716966733, "57": 0.0584977910592997, "58": 0.0584138217880183, "59": 0.0623133223809637, "60": 0.0622603835286608, "61": 0.0634872136915667, "62": 0.0596994523771468, "63": 0.0648697294653111, "64": 0.066205387081876, "65": 0.0733002651869689, "66": 0.0717679114886009, "67": 0.0707717607945918}}, "event_log": {"timestamp": {"0": "00:35:01.672", "1": "00:35:01.673", "2": "00:35:01.673", "3": "00:35:01.673", "4": "00:35:01.673", "5": "00:35:01.673", "6": "00:35:01.673", "7": "00:35:01.673", "8": "00:35:01.673", "9": "00:35:01.673", "10": "00:35:01.673", "11": "00:35:01.674", "12": "00:35:01.675", "13": "00:35:01.675", "14": "00:35:01.675", "15": "00:35:01.675", "16": "00:35:01.675", "17": "00:35:01.675", "18": "00:35:01.675", "19": "00:35:01.675", "20": "00:35:01.679", "21": "00:35:01.681", "22": "00:35:01.682", "23": "00:35:01.686", "24": "00:35:39.102", "25": "00:35:39.102", "26": "00:35:39.109", "27": "00:35:39.111", "28": "00:35:39.114", "29": "00:35:39.114", "30": "00:35:39.119", "31": "00:36:08.572", "32": "00:36:08.572", "33": "00:36:08.580", "34": "00:36:08.580", "35": "00:36:08.585", "36": "00:36:35.317", "37": "00:36:35.317", "38": "00:36:35.328", "39": "00:36:35.328", "40": "00:36:35.332", "41": "00:37:03.262", "42": "00:37:03.262", "43": "00:37:03.271", "44": "00:37:03.273", "45": "00:37:03.273", "46": "00:37:03.276", "47": "00:37:03.276", "48": "00:37:03.281", "49": "00:37:33.449", "50": "00:37:33.449", "51": "00:37:33.461", "52": "00:37:33.461", "53": "00:37:33.465", "54": "00:37:33.465", "55": "00:37:33.470", "56": "00:38:01.476", "57": "00:38:01.476", "58": "00:38:20.494", "59": "00:38:20.494", "60": "00:38:39.513", "61": "00:38:39.516", "62": "00:38:59.533", "63": "00:38:59.533", "64": "00:39:29.554", "65": "00:39:29.554", "66": "00:39:29.572", "67": "00:39:46.576", "68": "00:39:46.576", "69": "00:40:09.603", "70": "00:40:09.603", "71": "00:40:45.632", "72": "00:40:45.632", "73": "00:41:12.661", "74": "00:41:12.661", "75": "00:41:41.693", "76": "00:41:41.693", "77": "00:42:06.728", "78": "00:42:06.728", "79": "00:42:26.767", "80": "00:42:26.768", "81": "00:42:53.803", "82": "00:42:53.803", "83": "00:43:18.840", "84": "00:43:18.845", "85": "00:43:38.884", "86": "00:43:38.884", "87": "00:43:58.936", "88": "00:43:58.936", "89": "00:44:33.969", "90": "00:44:33.969", "91": "00:44:54.10", "92": "00:44:54.11", "93": "00:45:24.72", "94": "00:45:24.73", "95": "00:45:50.123", "96": "00:45:50.123", "97": "00:46:11.163", "98": "00:46:11.163", "99": "00:46:37.212", "100": "00:46:37.213", "101": "00:47:11.280", "102": "00:47:11.280", "103": "00:47:11.321", "104": "00:47:45.326", "105": "00:47:45.327", "106": "00:48:02.387", "107": "00:48:02.388", "108": "00:48:23.445", "109": "00:48:23.446", "110": "00:48:43.504", "111": "00:48:43.505", "112": "00:49:13.571", "113": "00:49:13.571", "114": "00:49:42.630", "115": "00:49:42.630", "116": "00:50:03.706", "117": "00:50:03.706", "118": "00:50:36.772", "119": "00:50:36.773", "120": "00:51:09.849", "121": "00:51:09.850", "122": "00:51:44.930", "123": "00:51:44.930", "124": "00:52:04.6", "125": "00:52:04.6", "126": "00:52:38.76", "127": "00:52:38.77", "128": "00:53:05.160", "129": "00:53:05.160", "130": "00:53:38.258", "131": "00:53:38.258", "132": "00:54:19.330", "133": "00:54:19.331", "134": "00:54:42.424", "135": "00:54:42.424", "136": "00:55:33.498", "137": "00:55:33.498", "138": "00:55:56.583", "139": "00:55:56.583", "140": "00:56:17.681", "141": "00:56:17.681", "142": "00:56:42.772", "143": "00:56:42.772", "144": "00:57:08.856", "145": "00:57:08.856", "146": "00:57:37.182", "147": "00:57:37.182", "148": "00:58:05.276", "149": "00:58:05.276", "150": "00:58:27.381", "151": "00:58:27.381", "152": "00:58:59.489", "153": "00:58:59.489", "154": "00:59:16.583", "155": "00:59:16.583", "156": "00:59:45.689", "157": "00:59:45.690", "158": "01:00:02.800", "159": "01:00:02.800", "160": "01:00:35.922", "161": "01:00:35.922", "162": "01:00:55.46", "163": "01:00:55.47", "164": "01:01:25.193", "165": "01:01:25.193", "166": "01:01:57.332", "167": "01:01:57.333", "168": "01:02:17.436", "169": "01:02:17.437", "170": "01:02:38.542", "171": "01:02:38.543", "172": "01:03:14.669", "173": "01:03:14.669", "174": "01:03:51.784", "175": "01:03:51.785", "176": "01:04:10.922", "177": "01:04:10.923", "178": "01:04:34.46", "179": "01:04:34.47", "180": "01:04:57.161", "181": "01:04:57.161", "182": "01:05:02.293", "183": "01:05:02.294", "184": "01:05:02.306", "185": "01:05:02.376", "186": "01:05:02.377", "187": "01:05:02.377", "188": "01:05:02.377", "189": "01:05:02.377", "190": "01:05:02.377", "191": "01:05:02.377", "192": "01:05:02.377", "193": "01:05:02.377", "194": "01:05:02.377", "195": "01:05:02.377", "196": "01:05:02.377", "197": "01:05:02.377", "198": "01:05:02.377", "199": "01:05:02.377", "200": "01:05:02.377", "201": "01:05:02.377", "202": "01:05:02.377", "203": "01:05:02.377", "204": "01:05:02.377", "205": "01:05:02.377", "206": "01:05:02.377", "207": "01:05:02.400", "208": "01:05:02.400"}, "level": {"0": "INFO", "1": "INFO", "2": "INFO", "3": "INFO", "4": "INFO", "5": "INFO", "6": "INFO", "7": "INFO", "8": "INFO", "9": "INFO", "10": "INFO", "11": "INFO", "12": "INFO", "13": "INFO", "14": "INFO", "15": "INFO", "16": "INFO", "17": "DEBUG", "18": "DEBUG", "19": "INFO", "20": "INFO", "21": "DEBUG", "22": "INFO", "23": "DEBUG", "24": "DEBUG", "25": "DEBUG", "26": "INFO", "27": "INFO", "28": "DEBUG", "29": "INFO", "30": "DEBUG", "31": "DEBUG", "32": "DEBUG", "33": "DEBUG", "34": "INFO", "35": "DEBUG", "36": "DEBUG", "37": "DEBUG", "38": "DEBUG", "39": "INFO", "40": "DEBUG", "41": "DEBUG", "42": "DEBUG", "43": "INFO", "44": "INFO", "45": "INFO", "46": "DEBUG", "47": "INFO", "48": "DEBUG", "49": "DEBUG", "50": "DEBUG", "51": "INFO", "52": "INFO", "53": "DEBUG", "54": "INFO", "55": "DEBUG", "56": "DEBUG", "57": "DEBUG", "58": "DEBUG", "59": "DEBUG", "60": "DEBUG", "61": "DEBUG", "62": "DEBUG", "63": "DEBUG", "64": "DEBUG", "65": "DEBUG", "66": "INFO", "67": "DEBUG", "68": "DEBUG", "69": "DEBUG", "70": "DEBUG", "71": "DEBUG", "72": "DEBUG", "73": "DEBUG", "74": "DEBUG", "75": "DEBUG", "76": "DEBUG", "77": "DEBUG", "78": "DEBUG", "79": "DEBUG", "80": "DEBUG", "81": "DEBUG", "82": "DEBUG", "83": "DEBUG", "84": "DEBUG", "85": "DEBUG", "86": "DEBUG", "87": "DEBUG", "88": "DEBUG", "89": "DEBUG", "90": "DEBUG", "91": "DEBUG", "92": "DEBUG", "93": "DEBUG", "94": "DEBUG", "95": "DEBUG", "96": "DEBUG", "97": "DEBUG", "98": "DEBUG", "99": "DEBUG", "100": "DEBUG", "101": "DEBUG", "102": "DEBUG", "103": "INFO", "104": "DEBUG", "105": "DEBUG", "106": "DEBUG", "107": "DEBUG", "108": "DEBUG", "109": "DEBUG", "110": "DEBUG", "111": "DEBUG", "112": "DEBUG", "113": "DEBUG", "114": "DEBUG", "115": "DEBUG", "116": "DEBUG", "117": "DEBUG", "118": "DEBUG", "119": "DEBUG", "120": "DEBUG", "121": "DEBUG", "122": "DEBUG", "123": "DEBUG", "124": "DEBUG", "125": "DEBUG", "126": "DEBUG", "127": "DEBUG", "128": "DEBUG", "129": "DEBUG", "130": "DEBUG", "131": "DEBUG", "132": "DEBUG", "133": "DEBUG", "134": "DEBUG", "135": "DEBUG", "136": "DEBUG", "137": "DEBUG", "138": "DEBUG", "139": "DEBUG", "140": "DEBUG", "141": "DEBUG", "142": "DEBUG", "143": "DEBUG", "144": "DEBUG", "145": "DEBUG", "146": "DEBUG", "147": "DEBUG", "148": "DEBUG", "149": "DEBUG", "150": "DEBUG", "151": "DEBUG", "152": "DEBUG", "153": "DEBUG", "154": "DEBUG", "155": "DEBUG", "156": "DEBUG", "157": "DEBUG", "158": "DEBUG", "159": "DEBUG", "160": "DEBUG", "161": "DEBUG", "162": "DEBUG", "163": "DEBUG", "164": "DEBUG", "165": "DEBUG", "166": "DEBUG", "167": "DEBUG", "168": "DEBUG", "169": "DEBUG", "170": "DEBUG", "171": "DEBUG", "172": "DEBUG", "173": "DEBUG", "174": "DEBUG", "175": "DEBUG", "176": "DEBUG", "177": "DEBUG", "178": "DEBUG", "179": "DEBUG", "180": "DEBUG", "181": "DEBUG", "182": "DEBUG", "183": "DEBUG", "184": "DEBUG", "185": "DEBUG", "186": "DEBUG", "187": "DEBUG", "188": "DEBUG", "189": "DEBUG", "190": "DEBUG", "191": "DEBUG", "192": "DEBUG", "193": "DEBUG", "194": "DEBUG", "195": "DEBUG", "196": "DEBUG", "197": "DEBUG", "198": "DEBUG", "199": "DEBUG", "200": "DEBUG", "201": "DEBUG", "202": "DEBUG", "203": "INFO", "204": "INFO", "205": "INFO", "206": "INFO", "207": "DEBUG", "208": "DEBUG"}, "stage": {"0": "Workflow", "1": "Validation", "2": "Validation", "3": "Validation", "4": "DataImport", "5": "DataImport", "6": "DataImport", "7": "DataImport", "8": "DataImport", "9": "DataImport", "10": "DataImport", "11": "Workflow", "12": "Workflow", "13": "Workflow", "14": "Workflow", "15": "Workflow", "16": "Workflow", "17": "Workflow", "18": "Workflow", "19": "Workflow", "20": "Workflow", "21": "ModelTraining", "22": "ModelTraining", "23": "ModelTraining", "24": "ModelTraining", "25": "ModelTraining", "26": "ModelTraining", "27": "ModelTraining", "28": "ModelTraining", "29": "ModelTraining", "30": "ModelTraining", "31": "ModelTraining", "32": "ModelTraining", "33": "ModelTraining", "34": "ModelTraining", "35": "ModelTraining", "36": "ModelTraining", "37": "ModelTraining", "38": "ModelTraining", "39": "ModelTraining", "40": "ModelTraining", "41": "ModelTraining", "42": "ModelTraining", "43": "ModelTraining", "44": "ModelTraining", "45": "ModelTraining", "46": "ModelTraining", "47": "ModelTraining", "48": "ModelTraining", "49": "ModelTraining", "50": "ModelTraining", "51": "ModelTraining", "52": "ModelTraining", "53": "ModelTraining", "54": "ModelTraining", "55": "ModelTraining", "56": "ModelTraining", "57": "ModelTraining", "58": "ModelTraining", "59": "ModelTraining", "60": "ModelTraining", "61": "ModelTraining", "62": "ModelTraining", "63": "ModelTraining", "64": "ModelTraining", "65": "ModelTraining", "66": "ModelTraining", "67": "ModelTraining", "68": "ModelTraining", "69": "ModelTraining", "70": "ModelTraining", "71": "ModelTraining", "72": "ModelTraining", "73": "ModelTraining", "74": "ModelTraining", "75": "ModelTraining", "76": "ModelTraining", "77": "ModelTraining", "78": "ModelTraining", "79": "ModelTraining", "80": "ModelTraining", "81": "ModelTraining", "82": "ModelTraining", "83": "ModelTraining", "84": "ModelTraining", "85": "ModelTraining", "86": "ModelTraining", "87": "ModelTraining", "88": "ModelTraining", "89": "ModelTraining", "90": "ModelTraining", "91": "ModelTraining", "92": "ModelTraining", "93": "ModelTraining", "94": "ModelTraining", "95": "ModelTraining", "96": "ModelTraining", "97": "ModelTraining", "98": "ModelTraining", "99": "ModelTraining", "100": "ModelTraining", "101": "ModelTraining", "102": "ModelTraining", "103": "ModelTraining", "104": "ModelTraining", "105": "ModelTraining", "106": "ModelTraining", "107": "ModelTraining", "108": "ModelTraining", "109": "ModelTraining", "110": "ModelTraining", "111": "ModelTraining", "112": "ModelTraining", "113": "ModelTraining", "114": "ModelTraining", "115": "ModelTraining", "116": "ModelTraining", "117": "ModelTraining", "118": "ModelTraining", "119": "ModelTraining", "120": "ModelTraining", "121": "ModelTraining", "122": "ModelTraining", "123": "ModelTraining", "124": "ModelTraining", "125": "ModelTraining", "126": "ModelTraining", "127": "ModelTraining", "128": "ModelTraining", "129": "ModelTraining", "130": "ModelTraining", "131": "ModelTraining", "132": "ModelTraining", "133": "ModelTraining", "134": "ModelTraining", "135": "ModelTraining", "136": "ModelTraining", "137": "ModelTraining", "138": "ModelTraining", "139": "ModelTraining", "140": "ModelTraining", "141": "ModelTraining", "142": "ModelTraining", "143": "ModelTraining", "144": "ModelTraining", "145": "ModelTraining", "146": "ModelTraining", "147": "ModelTraining", "148": "ModelTraining", "149": "ModelTraining", "150": "ModelTraining", "151": "ModelTraining", "152": "ModelTraining", "153": "ModelTraining", "154": "ModelTraining", "155": "ModelTraining", "156": "ModelTraining", "157": "ModelTraining", "158": "ModelTraining", "159": "ModelTraining", "160": "ModelTraining", "161": "ModelTraining", "162": "ModelTraining", "163": "ModelTraining", "164": "ModelTraining", "165": "ModelTraining", "166": "ModelTraining", "167": "ModelTraining", "168": "ModelTraining", "169": "ModelTraining", "170": "ModelTraining", "171": "ModelTraining", "172": "ModelTraining", "173": "ModelTraining", "174": "ModelTraining", "175": "ModelTraining", "176": "ModelTraining", "177": "ModelTraining", "178": "ModelTraining", "179": "ModelTraining", "180": "ModelTraining", "181": "ModelTraining", "182": "ModelTraining", "183": "ModelTraining", "184": "ModelTraining", "185": "ModelTraining", "186": "ModelTraining", "187": "ModelTraining", "188": "ModelTraining", "189": "ModelTraining", "190": "ModelTraining", "191": "ModelTraining", "192": "ModelTraining", "193": "ModelTraining", "194": "ModelTraining", "195": "ModelTraining", "196": "ModelTraining", "197": "ModelTraining", "198": "ModelTraining", "199": "ModelTraining", "200": "ModelTraining", "201": "ModelTraining", "202": "ModelTraining", "203": "Workflow", "204": "Workflow", "205": "Workflow", "206": "Workflow", "207": "Workflow", "208": "Workflow"}, "message": {"0": "Project: classification_test_2022-12-21T03.35.00", "1": "5-fold cross-validation will be used.", "2": "Setting stopping tolerance adaptively based on the training frame: 0.00724466513640519", "3": "Build control seed: -1 (random)", "4": "training frame: Frame key: AutoML_14_20221221_03501_training_product_backorders7.hex    cols: 23    rows: 19053  chunks: 48    size: 896711  checksum: 340006888695133344", "5": "validation frame: NULL", "6": "leaderboard frame: NULL", "7": "blending frame: NULL", "8": "response column: went_on_backorder", "9": "fold column: null", "10": "weights column: null", "11": "Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]", "12": "Disabling Algo: StackedEnsemble as requested by the user.", "13": "Disabling Algo: DeepLearning as requested by the user.", "14": "Disabling Algo: GLM as requested by the user.", "15": "Disabling Algo: DRF as requested by the user.", "16": "Disabling Algo: XGBoost as requested by the user.", "17": "Defined work allocations: [Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "18": "Actual work allocations: [Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "19": "AutoML job created: 2022.12.21 00:35:01.671", "20": "AutoML build started: 2022.12.21 00:35:01.679", "21": "Time assigned for GBM_1_AutoML_14_20221221_03501: 1799.998s", "22": "AutoML: starting GBM_1_AutoML_14_20221221_03501 model training", "23": "GBM_1_AutoML_14_20221221_03501 [GBM def_5] started", "24": "GBM_1_AutoML_14_20221221_03501 [GBM def_5] complete", "25": "Adding model GBM_1_AutoML_14_20221221_03501 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=9s, total=37s", "26": "New leader: GBM_1_AutoML_14_20221221_03501, auc: 0.9470653435593076", "27": "Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.", "28": "Time assigned for GBM_2_AutoML_14_20221221_03501: 587.5216875s", "29": "AutoML: starting GBM_2_AutoML_14_20221221_03501 model training", "30": "GBM_2_AutoML_14_20221221_03501 [GBM def_2] started", "31": "GBM_2_AutoML_14_20221221_03501 [GBM def_2] complete", "32": "Adding model GBM_2_AutoML_14_20221221_03501 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=29s", "33": "Time assigned for GBM_3_AutoML_14_20221221_03501: 866.5495s", "34": "AutoML: starting GBM_3_AutoML_14_20221221_03501 model training", "35": "GBM_3_AutoML_14_20221221_03501 [GBM def_3] started", "36": "GBM_3_AutoML_14_20221221_03501 [GBM def_3] complete", "37": "Adding model GBM_3_AutoML_14_20221221_03501 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=27s", "38": "Time assigned for GBM_4_AutoML_14_20221221_03501: 1706.351s", "39": "AutoML: starting GBM_4_AutoML_14_20221221_03501 model training", "40": "GBM_4_AutoML_14_20221221_03501 [GBM def_4] started", "41": "GBM_4_AutoML_14_20221221_03501 [GBM def_4] complete", "42": "Adding model GBM_4_AutoML_14_20221221_03501 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=28s", "43": "New leader: GBM_4_AutoML_14_20221221_03501, auc: 0.9492896459670622", "44": "Skipping StackedEnsemble 'best_of_family_2' due to the exclude_algos option or it is already trained.", "45": "Skipping StackedEnsemble 'all_2' due to the exclude_algos option or it is already trained.", "46": "Time assigned for GBM_5_AutoML_14_20221221_03501: 1678.403s", "47": "AutoML: starting GBM_5_AutoML_14_20221221_03501 model training", "48": "GBM_5_AutoML_14_20221221_03501 [GBM def_1] started", "49": "GBM_5_AutoML_14_20221221_03501 [GBM def_1] complete", "50": "Adding model GBM_5_AutoML_14_20221221_03501 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=30s", "51": "Skipping StackedEnsemble 'best_of_family_3' due to the exclude_algos option or it is already trained.", "52": "Skipping StackedEnsemble 'all_3' due to the exclude_algos option or it is already trained.", "53": "Time assigned for GBM_grid_1_AutoML_14_20221221_03501: 1648.215s", "54": "AutoML: starting GBM_grid_1_AutoML_14_20221221_03501 hyperparameter search", "55": "GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search] started", "56": "Built: 1 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "57": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_1 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=27s", "58": "Built: 2 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "59": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_2 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=19s", "60": "Built: 3 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "61": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_3 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=19s", "62": "Built: 4 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "63": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_4 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=20s", "64": "Built: 5 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "65": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_5 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=30s", "66": "New leader: GBM_grid_1_AutoML_14_20221221_03501_model_5, auc: 0.9497818600542565", "67": "Built: 6 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "68": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_6 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=4s, total=17s", "69": "Built: 7 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "70": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_7 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=23s", "71": "Built: 8 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "72": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_8 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=9s, total=35s", "73": "Built: 9 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "74": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_9 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=27s", "75": "Built: 10 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "76": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_10 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=29s", "77": "Built: 11 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "78": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_11 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=25s", "79": "Built: 12 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "80": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_12 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=4s, total=20s", "81": "Built: 13 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "82": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_13 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=27s", "83": "Built: 14 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "84": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_14 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=26s", "85": "Built: 15 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "86": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_15 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=4s, total=20s", "87": "Built: 16 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "88": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_16 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=21s", "89": "Built: 17 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "90": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_17 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=9s, total=35s", "91": "Built: 18 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "92": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_18 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=19s", "93": "Built: 19 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "94": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_19 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=30s", "95": "Built: 20 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "96": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_20 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=26s", "97": "Built: 21 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "98": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_21 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=22s", "99": "Built: 22 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "100": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_22 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=26s", "101": "Built: 23 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "102": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_23 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=34s", "103": "New leader: GBM_grid_1_AutoML_14_20221221_03501_model_23, auc: 0.9508297225540863", "104": "Built: 24 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "105": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_24 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=33s", "106": "Built: 25 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "107": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_25 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=4s, total=17s", "108": "Built: 26 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "109": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_26 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=21s", "110": "Built: 27 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "111": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_27 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=19s", "112": "Built: 28 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "113": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_28 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=30s", "114": "Built: 29 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "115": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_29 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=30s", "116": "Built: 30 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "117": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_30 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=20s", "118": "Built: 31 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "119": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_31 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=33s", "120": "Built: 32 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "121": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_32 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=33s", "122": "Built: 33 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "123": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_33 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=35s", "124": "Built: 34 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "125": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_34 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=19s", "126": "Built: 35 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "127": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_35 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=33s", "128": "Built: 36 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "129": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_36 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=27s", "130": "Built: 37 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "131": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_37 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=34s", "132": "Built: 38 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "133": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_38 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=10s, total=41s", "134": "Built: 39 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "135": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_39 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=24s", "136": "Built: 40 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "137": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_40 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=13s, total=50s", "138": "Built: 41 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "139": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_41 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=23s", "140": "Built: 42 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "141": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_42 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=22s", "142": "Built: 43 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "143": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_43 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=25s", "144": "Built: 44 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "145": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_44 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=27s", "146": "Built: 45 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "147": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_45 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=28s", "148": "Built: 46 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "149": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_46 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=28s", "150": "Built: 47 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "151": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_47 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=22s", "152": "Built: 48 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "153": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_48 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=32s", "154": "Built: 49 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "155": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_49 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=4s, total=17s", "156": "Built: 50 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "157": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_50 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=29s", "158": "Built: 51 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "159": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_51 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=4s, total=17s", "160": "Built: 52 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "161": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_52 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=32s", "162": "Built: 53 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "163": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_53 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=20s", "164": "Built: 54 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "165": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_54 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=30s", "166": "Built: 55 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "167": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_55 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=7s, total=31s", "168": "Built: 56 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "169": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_56 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=4s, total=21s", "170": "Built: 57 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "171": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_57 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=21s", "172": "Built: 58 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "173": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_58 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=8s, total=36s", "174": "Built: 59 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "175": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_59 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=9s, total=36s", "176": "Built: 60 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "177": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_60 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=4s, total=19s", "178": "Built: 61 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "179": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_61 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=6s, total=24s", "180": "Built: 62 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "181": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_62 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=5s, total=22s", "182": "AutoML: out of time; skipping GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "183": "Built: 63 models for HyperparamSearch : GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search]", "184": "Adding model GBM_grid_1_AutoML_14_20221221_03501_model_63 to leaderboard Leaderboard_classification_test_2022-12-21T03.35.00@@went_on_backorder. Training time: model=1s, total=6s", "185": "GBM_grid_1_AutoML_14_20221221_03501 [GBM Grid Search] complete", "186": "AutoML: out of time; skipping DeepLearning grid_1", "187": "AutoML: out of time; skipping StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)", "188": "AutoML: out of time; skipping StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)", "189": "AutoML: out of time; skipping DeepLearning grid_2", "190": "AutoML: out of time; skipping DeepLearning grid_3", "191": "AutoML: out of time; skipping StackedEnsemble best_of_family_5 (built with AUTO metalearner, using top model from each algorithm type)", "192": "AutoML: out of time; skipping StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)", "193": "AutoML: out of time; skipping XGBoost lr_search", "194": "AutoML: out of time; skipping GBM lr_annealing", "195": "AutoML: out of time; skipping StackedEnsemble monotonic (built with AUTO metalearner, using monotonically constrained AutoML models)", "196": "AutoML: out of time; skipping StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)", "197": "AutoML: out of time; skipping StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)", "198": "AutoML: out of time; skipping StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)", "199": "AutoML: out of time; skipping StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)", "200": "AutoML: out of time; skipping completion resume_best_grids", "201": "AutoML: out of time; skipping StackedEnsemble best_of_family (built with AUTO metalearner, using top model from each algorithm type)", "202": "AutoML: out of time; skipping StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)", "203": "Actual modeling steps: [{GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w)]}]", "204": "AutoML build stopped: 2022.12.21 01:05:02.377", "205": "AutoML build done: built 68 models", "206": "AutoML duration: 30 min  0.698 sec", "207": "Verifying training frame immutability. . .", "208": "Training frame was not mutated (as expected)."}, "name": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": "creation_epoch", "20": "start_epoch", "21": NaN, "22": "start_GBM_def_5", "23": NaN, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": "start_GBM_def_2", "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": "start_GBM_def_3", "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": "start_GBM_def_4", "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": NaN, "45": NaN, "46": NaN, "47": "start_GBM_def_1", "48": NaN, "49": NaN, "50": NaN, "51": NaN, "52": NaN, "53": NaN, "54": "start_GBM_grid_1", "55": NaN, "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": NaN, "61": NaN, "62": NaN, "63": NaN, "64": NaN, "65": NaN, "66": NaN, "67": NaN, "68": NaN, "69": NaN, "70": NaN, "71": NaN, "72": NaN, "73": NaN, "74": NaN, "75": NaN, "76": NaN, "77": NaN, "78": NaN, "79": NaN, "80": NaN, "81": NaN, "82": NaN, "83": NaN, "84": NaN, "85": NaN, "86": NaN, "87": NaN, "88": NaN, "89": NaN, "90": NaN, "91": NaN, "92": NaN, "93": NaN, "94": NaN, "95": NaN, "96": NaN, "97": NaN, "98": NaN, "99": NaN, "100": NaN, "101": NaN, "102": NaN, "103": NaN, "104": NaN, "105": NaN, "106": NaN, "107": NaN, "108": NaN, "109": NaN, "110": NaN, "111": NaN, "112": NaN, "113": NaN, "114": NaN, "115": NaN, "116": NaN, "117": NaN, "118": NaN, "119": NaN, "120": NaN, "121": NaN, "122": NaN, "123": NaN, "124": NaN, "125": NaN, "126": NaN, "127": NaN, "128": NaN, "129": NaN, "130": NaN, "131": NaN, "132": NaN, "133": NaN, "134": NaN, "135": NaN, "136": NaN, "137": NaN, "138": NaN, "139": NaN, "140": NaN, "141": NaN, "142": NaN, "143": NaN, "144": NaN, "145": NaN, "146": NaN, "147": NaN, "148": NaN, "149": NaN, "150": NaN, "151": NaN, "152": NaN, "153": NaN, "154": NaN, "155": NaN, "156": NaN, "157": NaN, "158": NaN, "159": NaN, "160": NaN, "161": NaN, "162": NaN, "163": NaN, "164": NaN, "165": NaN, "166": NaN, "167": NaN, "168": NaN, "169": NaN, "170": NaN, "171": NaN, "172": NaN, "173": NaN, "174": NaN, "175": NaN, "176": NaN, "177": NaN, "178": NaN, "179": NaN, "180": NaN, "181": NaN, "182": NaN, "183": NaN, "184": NaN, "185": NaN, "186": NaN, "187": NaN, "188": NaN, "189": NaN, "190": NaN, "191": NaN, "192": NaN, "193": NaN, "194": NaN, "195": NaN, "196": NaN, "197": NaN, "198": NaN, "199": NaN, "200": NaN, "201": NaN, "202": NaN, "203": NaN, "204": "stop_epoch", "205": NaN, "206": "duration_secs", "207": NaN, "208": NaN}, "value": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": 1671582902.0, "20": 1671582902.0, "21": NaN, "22": 1671582902.0, "23": NaN, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": 1671582939.0, "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": 1671582969.0, "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": 1671582995.0, "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": NaN, "45": NaN, "46": NaN, "47": 1671583023.0, "48": NaN, "49": NaN, "50": NaN, "51": NaN, "52": NaN, "53": NaN, "54": 1671583053.0, "55": NaN, "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": NaN, "61": NaN, "62": NaN, "63": NaN, "64": NaN, "65": NaN, "66": NaN, "67": NaN, "68": NaN, "69": NaN, "70": NaN, "71": NaN, "72": NaN, "73": NaN, "74": NaN, "75": NaN, "76": NaN, "77": NaN, "78": NaN, "79": NaN, "80": NaN, "81": NaN, "82": NaN, "83": NaN, "84": NaN, "85": NaN, "86": NaN, "87": NaN, "88": NaN, "89": NaN, "90": NaN, "91": NaN, "92": NaN, "93": NaN, "94": NaN, "95": NaN, "96": NaN, "97": NaN, "98": NaN, "99": NaN, "100": NaN, "101": NaN, "102": NaN, "103": NaN, "104": NaN, "105": NaN, "106": NaN, "107": NaN, "108": NaN, "109": NaN, "110": NaN, "111": NaN, "112": NaN, "113": NaN, "114": NaN, "115": NaN, "116": NaN, "117": NaN, "118": NaN, "119": NaN, "120": NaN, "121": NaN, "122": NaN, "123": NaN, "124": NaN, "125": NaN, "126": NaN, "127": NaN, "128": NaN, "129": NaN, "130": NaN, "131": NaN, "132": NaN, "133": NaN, "134": NaN, "135": NaN, "136": NaN, "137": NaN, "138": NaN, "139": NaN, "140": NaN, "141": NaN, "142": NaN, "143": NaN, "144": NaN, "145": NaN, "146": NaN, "147": NaN, "148": NaN, "149": NaN, "150": NaN, "151": NaN, "152": NaN, "153": NaN, "154": NaN, "155": NaN, "156": NaN, "157": NaN, "158": NaN, "159": NaN, "160": NaN, "161": NaN, "162": NaN, "163": NaN, "164": NaN, "165": NaN, "166": NaN, "167": NaN, "168": NaN, "169": NaN, "170": NaN, "171": NaN, "172": NaN, "173": NaN, "174": NaN, "175": NaN, "176": NaN, "177": NaN, "178": NaN, "179": NaN, "180": NaN, "181": NaN, "182": NaN, "183": NaN, "184": NaN, "185": NaN, "186": NaN, "187": NaN, "188": NaN, "189": NaN, "190": NaN, "191": NaN, "192": NaN, "193": NaN, "194": NaN, "195": NaN, "196": NaN, "197": NaN, "198": NaN, "199": NaN, "200": NaN, "201": NaN, "202": NaN, "203": NaN, "204": 1671584702.0, "205": NaN, "206": 1801.0, "207": NaN, "208": NaN}}}, {"experiment": "classification_1", "max_runtime_secs": 1800, "max_models": null, "include_algos": ["DeepLearning"], "start_time": "2022-12-21 04:05:09.540195", "end_time": "2022-12-21 04:35:14.064851", "elapsed_time": "0:30:04.524656", "leaderboard": {"model_id": {"0": "DeepLearning_grid_1_AutoML_15_20221221_10510_model_3", "1": "DeepLearning_grid_1_AutoML_15_20221221_10510_model_1", "2": "DeepLearning_grid_1_AutoML_15_20221221_10510_model_2", "3": "DeepLearning_grid_1_AutoML_15_20221221_10510_model_6", "4": "DeepLearning_grid_1_AutoML_15_20221221_10510_model_5", "5": "DeepLearning_grid_1_AutoML_15_20221221_10510_model_4", "6": "DeepLearning_1_AutoML_15_20221221_10510"}, "auc": {"0": 0.640151806516527, "1": 0.6006323006323295, "2": 0.584448647928768, "3": 0.5828611993340999, "4": 0.5749119687716996, "5": 0.5702670803296229, "6": 0.5312324934537511}, "logloss": {"0": 1.3049835794617637, "1": 0.5951904910519891, "2": 0.7304945598654938, "3": 1.0527812481312608, "4": 2.24798884146166, "5": 2.3837249214060305, "6": 0.6622556156747464}, "aucpr": {"0": 0.200588346464083, "1": 0.2039585559841235, "2": 0.1903068918300445, "3": 0.1840219646803419, "4": 0.1418803421442045, "5": 0.1885400895145805, "6": 0.1447577591455309}, "mean_per_class_error": {"0": 0.3888015991443805, "1": 0.4093834746142559, "2": 0.4215234979616629, "3": 0.423918768100668, "4": 0.4120556028545393, "5": 0.4338107373150671, "6": 0.4799982870366159}, "rmse": {"0": 0.4840357075931033, "1": 0.3542025777068942, "2": 0.3696347181259276, "3": 0.481294100805773, "4": 0.5126861574865917, "5": 0.7021142102590958, "6": 0.3377338587157158}, "mse": {"0": 0.2342905662251562, "1": 0.1254594660542084, "2": 0.136629824844034, "3": 0.2316440114704376, "4": 0.2628470960783663, "5": 0.4929643642477538, "6": 0.114064159323007}}, "event_log": {"timestamp": {"0": "01:05:10.889", "1": "01:05:10.889", "2": "01:05:10.889", "3": "01:05:10.889", "4": "01:05:10.889", "5": "01:05:10.889", "6": "01:05:10.889", "7": "01:05:10.889", "8": "01:05:10.889", "9": "01:05:10.889", "10": "01:05:10.889", "11": "01:05:10.891", "12": "01:05:10.891", "13": "01:05:10.891", "14": "01:05:10.891", "15": "01:05:10.891", "16": "01:05:10.891", "17": "01:05:10.891", "18": "01:05:10.891", "19": "01:05:10.891", "20": "01:05:10.895", "21": "01:05:10.895", "22": "01:05:10.895", "23": "01:05:10.895", "24": "01:05:10.898", "25": "01:05:10.898", "26": "01:05:10.902", "27": "01:05:16.263", "28": "01:05:16.263", "29": "01:05:16.269", "30": "01:05:16.270", "31": "01:05:16.270", "32": "01:05:16.272", "33": "01:05:16.272", "34": "01:05:16.277", "35": "01:16:42.693", "36": "01:16:42.693", "37": "01:16:42.701", "38": "01:25:17.747", "39": "01:25:17.747", "40": "01:30:05.828", "41": "01:30:05.828", "42": "01:30:05.840", "43": "01:32:56.940", "44": "01:32:56.940", "45": "01:34:24.969", "46": "01:34:24.969", "47": "01:35:07.998", "48": "01:35:07.998", "49": "01:35:11.16", "50": "01:35:11.95", "51": "01:35:11.95", "52": "01:35:11.95", "53": "01:35:11.95", "54": "01:35:11.95", "55": "01:35:11.95", "56": "01:35:11.95", "57": "01:35:11.95", "58": "01:35:11.95", "59": "01:35:11.95", "60": "01:35:11.95", "61": "01:35:11.95", "62": "01:35:11.95", "63": "01:35:11.95", "64": "01:35:11.95", "65": "01:35:11.95", "66": "01:35:11.95", "67": "01:35:11.95", "68": "01:35:11.95", "69": "01:35:11.95", "70": "01:35:11.95", "71": "01:35:11.101", "72": "01:35:11.101"}, "level": {"0": "INFO", "1": "INFO", "2": "INFO", "3": "INFO", "4": "INFO", "5": "INFO", "6": "INFO", "7": "INFO", "8": "INFO", "9": "INFO", "10": "INFO", "11": "INFO", "12": "INFO", "13": "INFO", "14": "INFO", "15": "INFO", "16": "INFO", "17": "DEBUG", "18": "DEBUG", "19": "INFO", "20": "INFO", "21": "INFO", "22": "INFO", "23": "INFO", "24": "DEBUG", "25": "INFO", "26": "DEBUG", "27": "DEBUG", "28": "DEBUG", "29": "INFO", "30": "INFO", "31": "INFO", "32": "DEBUG", "33": "INFO", "34": "DEBUG", "35": "DEBUG", "36": "DEBUG", "37": "INFO", "38": "DEBUG", "39": "DEBUG", "40": "DEBUG", "41": "DEBUG", "42": "INFO", "43": "DEBUG", "44": "DEBUG", "45": "DEBUG", "46": "DEBUG", "47": "DEBUG", "48": "DEBUG", "49": "DEBUG", "50": "DEBUG", "51": "DEBUG", "52": "DEBUG", "53": "DEBUG", "54": "DEBUG", "55": "DEBUG", "56": "DEBUG", "57": "DEBUG", "58": "DEBUG", "59": "DEBUG", "60": "DEBUG", "61": "DEBUG", "62": "DEBUG", "63": "DEBUG", "64": "DEBUG", "65": "DEBUG", "66": "DEBUG", "67": "INFO", "68": "INFO", "69": "INFO", "70": "INFO", "71": "DEBUG", "72": "DEBUG"}, "stage": {"0": "Workflow", "1": "Validation", "2": "Validation", "3": "Validation", "4": "DataImport", "5": "DataImport", "6": "DataImport", "7": "DataImport", "8": "DataImport", "9": "DataImport", "10": "DataImport", "11": "Workflow", "12": "Workflow", "13": "Workflow", "14": "Workflow", "15": "Workflow", "16": "Workflow", "17": "Workflow", "18": "Workflow", "19": "Workflow", "20": "Workflow", "21": "ModelTraining", "22": "ModelTraining", "23": "ModelTraining", "24": "ModelTraining", "25": "ModelTraining", "26": "ModelTraining", "27": "ModelTraining", "28": "ModelTraining", "29": "ModelTraining", "30": "ModelTraining", "31": "ModelTraining", "32": "ModelTraining", "33": "ModelTraining", "34": "ModelTraining", "35": "ModelTraining", "36": "ModelTraining", "37": "ModelTraining", "38": "ModelTraining", "39": "ModelTraining", "40": "ModelTraining", "41": "ModelTraining", "42": "ModelTraining", "43": "ModelTraining", "44": "ModelTraining", "45": "ModelTraining", "46": "ModelTraining", "47": "ModelTraining", "48": "ModelTraining", "49": "ModelTraining", "50": "ModelTraining", "51": "ModelTraining", "52": "ModelTraining", "53": "ModelTraining", "54": "ModelTraining", "55": "ModelTraining", "56": "ModelTraining", "57": "ModelTraining", "58": "ModelTraining", "59": "ModelTraining", "60": "ModelTraining", "61": "ModelTraining", "62": "ModelTraining", "63": "ModelTraining", "64": "ModelTraining", "65": "ModelTraining", "66": "ModelTraining", "67": "Workflow", "68": "Workflow", "69": "Workflow", "70": "Workflow", "71": "Workflow", "72": "Workflow"}, "message": {"0": "Project: classification_test_2022-12-21T04.05.09", "1": "5-fold cross-validation will be used.", "2": "Setting stopping tolerance adaptively based on the training frame: 0.00724466513640519", "3": "Build control seed: -1 (random)", "4": "training frame: Frame key: AutoML_15_20221221_10510_training_product_backorders8.hex    cols: 23    rows: 19053  chunks: 48    size: 896711  checksum: 340006888695133344", "5": "validation frame: NULL", "6": "leaderboard frame: NULL", "7": "blending frame: NULL", "8": "response column: went_on_backorder", "9": "fold column: null", "10": "weights column: null", "11": "Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]", "12": "Disabling Algo: StackedEnsemble as requested by the user.", "13": "Disabling Algo: GLM as requested by the user.", "14": "Disabling Algo: DRF as requested by the user.", "15": "Disabling Algo: GBM as requested by the user.", "16": "Disabling Algo: XGBoost as requested by the user.", "17": "Defined work allocations: [Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "18": "Actual work allocations: [Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}]", "19": "AutoML job created: 2022.12.21 01:05:10.886", "20": "AutoML build started: 2022.12.21 01:05:10.894", "21": "Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.", "22": "Skipping StackedEnsemble 'best_of_family_2' due to the exclude_algos option or it is already trained.", "23": "Skipping StackedEnsemble 'all_2' due to the exclude_algos option or it is already trained.", "24": "Time assigned for DeepLearning_1_AutoML_15_20221221_10510: 1799.996s", "25": "AutoML: starting DeepLearning_1_AutoML_15_20221221_10510 model training", "26": "DeepLearning_1_AutoML_15_20221221_10510 [DeepLearning def_1] started", "27": "DeepLearning_1_AutoML_15_20221221_10510 [DeepLearning def_1] complete", "28": "Adding model DeepLearning_1_AutoML_15_20221221_10510 to leaderboard Leaderboard_classification_test_2022-12-21T04.05.09@@went_on_backorder. Training time: model=1s, total=5s", "29": "New leader: DeepLearning_1_AutoML_15_20221221_10510, auc: 0.5312324934537511", "30": "Skipping StackedEnsemble 'best_of_family_3' due to the exclude_algos option or it is already trained.", "31": "Skipping StackedEnsemble 'all_3' due to the exclude_algos option or it is already trained.", "32": "Time assigned for DeepLearning_grid_1_AutoML_15_20221221_10510: 1794.622s", "33": "AutoML: starting DeepLearning_grid_1_AutoML_15_20221221_10510 hyperparameter search", "34": "DeepLearning_grid_1_AutoML_15_20221221_10510 [DeepLearning Grid Search] started", "35": "Built: 1 models for HyperparamSearch : DeepLearning_grid_1_AutoML_15_20221221_10510 [DeepLearning Grid Search]", "36": "Adding model DeepLearning_grid_1_AutoML_15_20221221_10510_model_1 to leaderboard Leaderboard_classification_test_2022-12-21T04.05.09@@went_on_backorder. Training time: model=139s, total=685s", "37": "New leader: DeepLearning_grid_1_AutoML_15_20221221_10510_model_1, auc: 0.6006323006323295", "38": "Built: 2 models for HyperparamSearch : DeepLearning_grid_1_AutoML_15_20221221_10510 [DeepLearning Grid Search]", "39": "Adding model DeepLearning_grid_1_AutoML_15_20221221_10510_model_2 to leaderboard Leaderboard_classification_test_2022-12-21T04.05.09@@went_on_backorder. Training time: model=103s, total=516s", "40": "Built: 3 models for HyperparamSearch : DeepLearning_grid_1_AutoML_15_20221221_10510 [DeepLearning Grid Search]", "41": "Adding model DeepLearning_grid_1_AutoML_15_20221221_10510_model_3 to leaderboard Leaderboard_classification_test_2022-12-21T04.05.09@@went_on_backorder. Training time: model=38s, total=288s", "42": "New leader: DeepLearning_grid_1_AutoML_15_20221221_10510_model_3, auc: 0.640151806516527", "43": "Built: 4 models for HyperparamSearch : DeepLearning_grid_1_AutoML_15_20221221_10510 [DeepLearning Grid Search]", "44": "Adding model DeepLearning_grid_1_AutoML_15_20221221_10510_model_4 to leaderboard Leaderboard_classification_test_2022-12-21T04.05.09@@went_on_backorder. Training time: model=18s, total=171s", "45": "Built: 5 models for HyperparamSearch : DeepLearning_grid_1_AutoML_15_20221221_10510 [DeepLearning Grid Search]", "46": "Adding model DeepLearning_grid_1_AutoML_15_20221221_10510_model_5 to leaderboard Leaderboard_classification_test_2022-12-21T04.05.09@@went_on_backorder. Training time: model=13s, total=88s", "47": "Built: 6 models for HyperparamSearch : DeepLearning_grid_1_AutoML_15_20221221_10510 [DeepLearning Grid Search]", "48": "Adding model DeepLearning_grid_1_AutoML_15_20221221_10510_model_6 to leaderboard Leaderboard_classification_test_2022-12-21T04.05.09@@went_on_backorder. Training time: model=9s, total=44s", "49": "AutoML: out of time; skipping DeepLearning_grid_1_AutoML_15_20221221_10510 [DeepLearning Grid Search]", "50": "DeepLearning_grid_1_AutoML_15_20221221_10510 [DeepLearning Grid Search] complete", "51": "AutoML: out of time; skipping StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)", "52": "AutoML: out of time; skipping StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)", "53": "AutoML: out of time; skipping DeepLearning grid_2", "54": "AutoML: out of time; skipping DeepLearning grid_3", "55": "AutoML: out of time; skipping StackedEnsemble best_of_family_5 (built with AUTO metalearner, using top model from each algorithm type)", "56": "AutoML: out of time; skipping StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)", "57": "AutoML: out of time; skipping XGBoost lr_search", "58": "AutoML: out of time; skipping GBM lr_annealing", "59": "AutoML: out of time; skipping StackedEnsemble monotonic (built with AUTO metalearner, using monotonically constrained AutoML models)", "60": "AutoML: out of time; skipping StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)", "61": "AutoML: out of time; skipping StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)", "62": "AutoML: out of time; skipping StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)", "63": "AutoML: out of time; skipping StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)", "64": "AutoML: out of time; skipping completion resume_best_grids", "65": "AutoML: out of time; skipping StackedEnsemble best_of_family (built with AUTO metalearner, using top model from each algorithm type)", "66": "AutoML: out of time; skipping StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)", "67": "Actual modeling steps: [{DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w)]}]", "68": "AutoML build stopped: 2022.12.21 01:35:11.95", "69": "AutoML build done: built 7 models", "70": "AutoML duration: 30 min  0.201 sec", "71": "Verifying training frame immutability. . .", "72": "Training frame was not mutated (as expected)."}, "name": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": "creation_epoch", "20": "start_epoch", "21": NaN, "22": NaN, "23": NaN, "24": NaN, "25": "start_DeepLearning_def_1", "26": NaN, "27": NaN, "28": NaN, "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": "start_DeepLearning_grid_1", "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": NaN, "45": NaN, "46": NaN, "47": NaN, "48": NaN, "49": NaN, "50": NaN, "51": NaN, "52": NaN, "53": NaN, "54": NaN, "55": NaN, "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": NaN, "61": NaN, "62": NaN, "63": NaN, "64": NaN, "65": NaN, "66": NaN, "67": NaN, "68": "stop_epoch", "69": NaN, "70": "duration_secs", "71": NaN, "72": NaN}, "value": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": 1671584711.0, "20": 1671584711.0, "21": NaN, "22": NaN, "23": NaN, "24": NaN, "25": 1671584711.0, "26": NaN, "27": NaN, "28": NaN, "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": 1671584716.0, "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": NaN, "39": NaN, "40": NaN, "41": NaN, "42": NaN, "43": NaN, "44": NaN, "45": NaN, "46": NaN, "47": NaN, "48": NaN, "49": NaN, "50": NaN, "51": NaN, "52": NaN, "53": NaN, "54": NaN, "55": NaN, "56": NaN, "57": NaN, "58": NaN, "59": NaN, "60": NaN, "61": NaN, "62": NaN, "63": NaN, "64": NaN, "65": NaN, "66": NaN, "67": NaN, "68": 1671586511.0, "69": NaN, "70": 1800.0, "71": NaN, "72": NaN}}}, {"experiment": "classification_1", "max_runtime_secs": 1800, "max_models": null, "include_algos": ["StackedEnsemble"], "start_time": "2022-12-21 04:35:16.721930", "end_time": "2022-12-21 04:35:19.774583", "elapsed_time": "0:00:03.052653", "leaderboard": {"model_id": {}}, "event_log": {"timestamp": {"0": "01:35:18.77", "1": "01:35:18.77", "2": "01:35:18.77", "3": "01:35:18.77", "4": "01:35:18.78", "5": "01:35:18.78", "6": "01:35:18.78", "7": "01:35:18.78", "8": "01:35:18.78", "9": "01:35:18.78", "10": "01:35:18.78", "11": "01:35:18.79", "12": "01:35:18.80", "13": "01:35:18.80", "14": "01:35:18.80", "15": "01:35:18.80", "16": "01:35:18.80", "17": "01:35:18.80", "18": "01:35:18.80", "19": "01:35:18.80", "20": "01:35:18.83", "21": "01:35:18.83", "22": "01:35:18.84", "23": "01:35:18.84", "24": "01:35:18.84", "25": "01:35:18.84", "26": "01:35:18.84", "27": "01:35:18.84", "28": "01:35:18.85", "29": "01:35:18.85", "30": "01:35:18.85", "31": "01:35:18.85", "32": "01:35:18.85", "33": "01:35:18.85", "34": "01:35:18.85", "35": "01:35:18.86", "36": "01:35:18.86", "37": "01:35:18.86", "38": "01:35:18.86", "39": "01:35:18.86", "40": "01:35:18.86", "41": "01:35:18.89", "42": "01:35:18.90", "43": "01:35:18.90"}, "level": {"0": "INFO", "1": "INFO", "2": "INFO", "3": "INFO", "4": "INFO", "5": "INFO", "6": "INFO", "7": "INFO", "8": "INFO", "9": "INFO", "10": "INFO", "11": "INFO", "12": "INFO", "13": "INFO", "14": "INFO", "15": "INFO", "16": "INFO", "17": "DEBUG", "18": "DEBUG", "19": "INFO", "20": "INFO", "21": "INFO", "22": "INFO", "23": "INFO", "24": "INFO", "25": "INFO", "26": "INFO", "27": "INFO", "28": "INFO", "29": "INFO", "30": "INFO", "31": "INFO", "32": "INFO", "33": "INFO", "34": "INFO", "35": "INFO", "36": "INFO", "37": "INFO", "38": "INFO", "39": "INFO", "40": "INFO", "41": "WARN", "42": "DEBUG", "43": "DEBUG"}, "stage": {"0": "Workflow", "1": "Validation", "2": "Validation", "3": "Validation", "4": "DataImport", "5": "DataImport", "6": "DataImport", "7": "DataImport", "8": "DataImport", "9": "DataImport", "10": "DataImport", "11": "Workflow", "12": "Workflow", "13": "Workflow", "14": "Workflow", "15": "Workflow", "16": "Workflow", "17": "Workflow", "18": "Workflow", "19": "Workflow", "20": "Workflow", "21": "ModelTraining", "22": "ModelTraining", "23": "ModelTraining", "24": "ModelTraining", "25": "ModelTraining", "26": "ModelTraining", "27": "ModelTraining", "28": "ModelTraining", "29": "ModelTraining", "30": "ModelTraining", "31": "ModelTraining", "32": "ModelTraining", "33": "ModelTraining", "34": "ModelTraining", "35": "ModelTraining", "36": "ModelTraining", "37": "Workflow", "38": "Workflow", "39": "Workflow", "40": "Workflow", "41": "Workflow", "42": "Workflow", "43": "Workflow"}, "message": {"0": "Project: classification_test_2022-12-21T04.35.16", "1": "5-fold cross-validation will be used.", "2": "Setting stopping tolerance adaptively based on the training frame: 0.00724466513640519", "3": "Build control seed: -1 (random)", "4": "training frame: Frame key: AutoML_16_20221221_13518_training_product_backorders9.hex    cols: 23    rows: 19053  chunks: 48    size: 896711  checksum: 340006888695133344", "5": "validation frame: NULL", "6": "leaderboard frame: NULL", "7": "blending frame: NULL", "8": "response column: went_on_backorder", "9": "fold column: null", "10": "weights column: null", "11": "Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]", "12": "Disabling Algo: DeepLearning as requested by the user.", "13": "Disabling Algo: GLM as requested by the user.", "14": "Disabling Algo: DRF as requested by the user.", "15": "Disabling Algo: GBM as requested by the user.", "16": "Disabling Algo: XGBoost as requested by the user.", "17": "Defined work allocations: [Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]", "18": "Actual work allocations: [Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]", "19": "AutoML job created: 2022.12.21 01:35:18.75", "20": "AutoML build started: 2022.12.21 01:35:18.83", "21": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'best_of_family_1'.", "22": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'best_of_family_2'.", "23": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'all_2'.", "24": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'best_of_family_3'.", "25": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'all_3'.", "26": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'best_of_family_4'.", "27": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'all_4'.", "28": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'best_of_family_5'.", "29": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'all_5'.", "30": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.", "31": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'best_of_family_gbm'.", "32": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'all_gbm'.", "33": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'best_of_family_xglm'.", "34": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'all_xglm'.", "35": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'best_of_family'.", "36": "No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'best_N'.", "37": "Actual modeling steps: []", "38": "AutoML build stopped: 2022.12.21 01:35:18.86", "39": "AutoML build done: built 0 models", "40": "AutoML duration:  0.003 sec", "41": "Empty leaderboard.\r\nAutoML was not able to build any model within a max runtime constraint of 1800 seconds, you may want to increase this value before retrying.", "42": "Verifying training frame immutability. . .", "43": "Training frame was not mutated (as expected)."}, "name": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": "creation_epoch", "20": "start_epoch", "21": NaN, "22": NaN, "23": NaN, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": "stop_epoch", "39": NaN, "40": "duration_secs", "41": NaN, "42": NaN, "43": NaN}, "value": {"0": NaN, "1": NaN, "2": NaN, "3": NaN, "4": NaN, "5": NaN, "6": NaN, "7": NaN, "8": NaN, "9": NaN, "10": NaN, "11": NaN, "12": NaN, "13": NaN, "14": NaN, "15": NaN, "16": NaN, "17": NaN, "18": NaN, "19": 1671586518.0, "20": 1671586518.0, "21": NaN, "22": NaN, "23": NaN, "24": NaN, "25": NaN, "26": NaN, "27": NaN, "28": NaN, "29": NaN, "30": NaN, "31": NaN, "32": NaN, "33": NaN, "34": NaN, "35": NaN, "36": NaN, "37": NaN, "38": 1671586518.0, "39": NaN, "40": 0.0, "41": NaN, "42": NaN, "43": NaN}}}]